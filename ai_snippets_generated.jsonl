{"id": "AI_0", "text": "def safe_divide_0(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_1", "text": "def validate_payload_1(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_2():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3", "text": "def count_tokens_3(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_4(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_5", "text": "def extract_numeric_5(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_6", "text": "def compute_stats_6(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_7", "text": "def extract_numeric_7(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_8", "text": "def compute_stats_8(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_9", "text": "import statistics\n\ndef stats_9(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_10", "text": "def validate_payload_10(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_11", "text": "from collections import Counter\n\ndef word_freq_11(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_12", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_12(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_12(n-1) + fib_12(n-2)", "label": "1", "lang": "python"}
{"id": "AI_13", "text": "from collections import Counter\n\ndef word_freq_13(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_14", "text": "def safe_reduce_14(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_15", "text": "def count_characters_15(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_16", "text": "def pipeline_process_16(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_17", "text": "def compute_average_17(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_18", "text": "def safe_division_18(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_19", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_19(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_20", "text": "from typing import Dict, Any\n\ndef validate_payload_20(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_21", "text": "def compute_avg_21(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_22", "text": "class Processor_22:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_23", "text": "def is_prime_23(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_24", "text": "def safe_division_24(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_25", "text": "def meta_process_25(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_26", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_26(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_26(n - 1) + fib_26(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_27", "text": "class ExecutionNode_27:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_27():\n    import math\n\n    root = ExecutionNode_27(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_27(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_27(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_28", "text": "def validate_28(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_28(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_28(seq):\n    clean = convert_28(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_29", "text": "import re\n\ndef clean_texts_29(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_30", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_30(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_31", "text": "def safe_division_31(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_32", "text": "import statistics\n\ndef stats_32(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_33", "text": "def extract_numeric_33(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_34", "text": "def generate_report_34(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_35", "text": "def validate_payload_35(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_36", "text": "class Processor_36:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_37", "text": "def safe_reduce_37(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_38", "text": "import numpy as np\n\ndef minmax_norm_38(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_39", "text": "class Processor_39:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_40", "text": "def nested_analysis_40(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_41", "text": "def analyze_series_41(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_42", "text": "def meta_process_42(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_43", "text": "import numpy as np\n\ndef normalize_features_43(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_44", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_44:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_44:\n    tasks: List[Task_44] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_44(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_45", "text": "class DataNormalizer_45:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_46", "text": "import json\n\ndef load_and_filter_46(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_47", "text": "def nested_analysis_47(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_48", "text": "import numpy as np\n\ndef minmax_norm_48(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_49", "text": "def analyze_series_49(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_50", "text": "def pipeline_process_50(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_51", "text": "import numpy as np\n\ndef minmax_norm_51(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_52", "text": "def compute_average_52(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_53", "text": "def nested_analysis_53(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_54", "text": "def compute_stats_54(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_55", "text": "def is_prime_55(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_56", "text": "def flatten_list_56(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_57", "text": "def pipeline_process_57(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_58", "text": "from typing import Dict, Any\n\ndef validate_payload_58(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_59", "text": "def generate_report_59(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_60", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_60(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_61", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_61():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_62", "text": "def nested_analysis_62(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_63", "text": "import numpy as np\n\ndef validate_and_predict_63(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_64", "text": "def compute_stats_64(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_65", "text": "import json\n\ndef load_and_filter_65(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_66", "text": "def compute_avg_66(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_67", "text": "def safe_division_67(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_68", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_68:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_68:\n    tasks: List[Task_68] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_68(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_69", "text": "import numpy as np\n\ndef minmax_norm_69(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_70", "text": "def safe_reduce_70(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_71", "text": "def count_tokens_71(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_72", "text": "def structured_sum_72(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_73", "text": "import json\n\ndef load_and_filter_73(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_74", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_74(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_75", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_75(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_76", "text": "def generate_report_76(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_77", "text": "def count_tokens_77(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_78", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_78(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_79", "text": "def validate_payload_79(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_80", "text": "def validate_payload_80(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_81", "text": "def safe_division_81(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_82", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_82(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_82(n-1) + fib_82(n-2)", "label": "1", "lang": "python"}
{"id": "AI_83", "text": "import numpy as np\n\ndef minmax_norm_83(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_84", "text": "def analyze_series_84(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_85", "text": "class ExecutionNode_85:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_85():\n    import math\n\n    root = ExecutionNode_85(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_85(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_85(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_86", "text": "def safe_division_86(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_87", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_87(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_87(n-1) + fib_87(n-2)", "label": "1", "lang": "python"}
{"id": "AI_88", "text": "def validate_payload_88(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_89", "text": "def safe_division_89(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_90", "text": "def generate_report_90(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_91", "text": "class Processor_91:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_92", "text": "import numpy as np\n\ndef normalize_features_92(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_93", "text": "def compute_sum_93(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_94", "text": "def is_prime_94(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_95", "text": "def safe_divide_95(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_96", "text": "def nested_analysis_96(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_97", "text": "import numpy as np\n\ndef validate_and_predict_97(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_98", "text": "def structured_sum_98(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_99", "text": "import re\n\ndef clean_texts_99(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_100", "text": "import numpy as np\n\ndef minmax_norm_100(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_101", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_101(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_102", "text": "def structured_sum_102(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_103", "text": "from typing import Dict, Any\n\ndef validate_payload_103(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_104", "text": "def extract_numeric_104(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_105", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_105(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_106", "text": "def compute_sum_106(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_107", "text": "def nested_analysis_107(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_108", "text": "def safe_reduce_108(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_109", "text": "from typing import Dict, Any\n\ndef validate_payload_109(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_110", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_110:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_110:\n    tasks: List[Task_110] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_110(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_111", "text": "def pipeline_process_111(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_112", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_112(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_112(n - 1) + fib_112(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_113", "text": "def compute_average_113(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_114", "text": "def pipeline_process_114(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_115", "text": "def safe_reduce_115(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_116", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_116:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_116:\n    tasks: List[Task_116] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_116(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_117", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_117(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_118", "text": "def compute_sum_118(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_119", "text": "def validate_payload_119(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_120", "text": "def compute_stats_120(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_121", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_121():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_122", "text": "def validate_payload_122(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_123", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_123(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_124", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_124(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_125", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_125(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_125(n-1) + fib_125(n-2)", "label": "1", "lang": "python"}
{"id": "AI_126", "text": "def meta_process_126(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_127", "text": "def safe_reduce_127(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_128", "text": "import statistics\n\ndef stats_128(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_129", "text": "def safe_reduce_129(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_130", "text": "def validate_payload_130(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_131", "text": "def compute_average_131(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_132", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_132(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_133", "text": "from collections import Counter\n\ndef word_freq_133(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_134", "text": "def safe_reduce_134(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_135", "text": "def compute_average_135(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_136", "text": "class ExecutionNode_136:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_136():\n    import math\n\n    root = ExecutionNode_136(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_136(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_136(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_137", "text": "import numpy as np\n\ndef normalize_features_137(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_138", "text": "import statistics\n\ndef stats_138(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_139", "text": "def analyze_series_139(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_140", "text": "from typing import Dict, Any\n\ndef validate_payload_140(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_141", "text": "def compute_average_141(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_142", "text": "def structured_sum_142(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_143", "text": "import statistics\n\ndef stats_143(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_144", "text": "import numpy as np\n\ndef minmax_norm_144(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_145", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_145(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_146", "text": "import re\n\ndef clean_texts_146(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_147", "text": "import json\n\ndef load_and_filter_147(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_148", "text": "import re\n\ndef clean_texts_148(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_149", "text": "def count_characters_149(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_150", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_150(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_150(n - 1) + fib_150(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_151", "text": "def safe_division_151(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_152", "text": "def extract_numeric_152(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_153", "text": "def count_characters_153(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_154", "text": "def safe_divide_154(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_155", "text": "def analyze_series_155(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_156", "text": "def flatten_list_156(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_157", "text": "def meta_process_157(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_158", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_158(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_158(n - 1) + fib_158(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_159", "text": "def validate_payload_159(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_160", "text": "def structured_sum_160(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_161", "text": "def validate_161(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_161(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_161(seq):\n    clean = convert_161(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_162", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_162(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_162(n - 1) + fib_162(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_163", "text": "def validate_payload_163(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_164", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_164(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_165", "text": "def generate_report_165(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_166", "text": "def is_prime_166(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_167", "text": "def extract_numeric_167(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_168", "text": "def compute_avg_168(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_169", "text": "class Processor_169:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_170", "text": "def extract_numeric_170(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_171", "text": "def safe_division_171(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_172", "text": "def safe_division_172(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_173", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_173(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_173(n-1) + fib_173(n-2)", "label": "1", "lang": "python"}
{"id": "AI_174", "text": "class Config_174:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_175", "text": "class DataNormalizer_175:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_176", "text": "def safe_division_176(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_177", "text": "class ExecutionNode_177:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_177():\n    import math\n\n    root = ExecutionNode_177(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_177(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_177(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_178", "text": "def flatten_list_178(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_179", "text": "def validate_payload_179(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_180", "text": "class Processor_180:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_181", "text": "def compute_sum_181(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_182", "text": "def generate_report_182(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_183", "text": "def generate_report_183(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_184", "text": "class Config_184:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_185", "text": "import statistics\n\ndef stats_185(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_186", "text": "from typing import Dict, Any\n\ndef validate_payload_186(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_187", "text": "def analyze_series_187(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_188", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_188:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_188:\n    tasks: List[Task_188] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_188(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_189", "text": "def flatten_list_189(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_190", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_190(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_190(n - 1) + fib_190(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_191", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_191:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_191:\n    tasks: List[Task_191] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_191(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_192", "text": "def compute_stats_192(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_193", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_193():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_194", "text": "def safe_division_194(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_195", "text": "from typing import Dict, Any\n\ndef validate_payload_195(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_196", "text": "def analyze_series_196(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_197", "text": "from typing import Dict, Any\n\ndef validate_payload_197(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_198", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_198(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_198(n - 1) + fib_198(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_199", "text": "import json\n\ndef load_and_filter_199(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_200", "text": "import json\n\ndef load_and_filter_200(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_201", "text": "def compute_stats_201(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_202", "text": "import numpy as np\n\ndef normalize_features_202(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_203", "text": "from typing import Dict, Any\n\ndef validate_payload_203(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_204", "text": "def structured_sum_204(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_205", "text": "def safe_division_205(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_206", "text": "def meta_process_206(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_207", "text": "def structured_sum_207(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_208", "text": "def analyze_series_208(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_209", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_209(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_210", "text": "import statistics\n\ndef stats_210(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_211", "text": "def safe_divide_211(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_212", "text": "def compute_sum_212(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_213", "text": "def compute_stats_213(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_214", "text": "def pipeline_process_214(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_215", "text": "def flatten_list_215(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_216", "text": "def safe_division_216(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_217", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_217(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_218", "text": "from typing import Dict, Any\n\ndef validate_payload_218(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_219", "text": "def is_prime_219(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_220", "text": "def validate_payload_220(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_221", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_221(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_222", "text": "def pipeline_process_222(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_223", "text": "def compute_avg_223(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_224", "text": "def meta_process_224(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_225", "text": "import numpy as np\n\ndef normalize_features_225(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_226", "text": "from typing import Dict, Any\n\ndef validate_payload_226(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_227", "text": "def extract_numeric_227(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_228", "text": "def flatten_list_228(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_229", "text": "def compute_sum_229(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_230", "text": "class Config_230:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_231", "text": "def compute_average_231(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_232", "text": "def analyze_series_232(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_233", "text": "import numpy as np\n\ndef minmax_norm_233(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_234", "text": "def validate_payload_234(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_235", "text": "class Config_235:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_236", "text": "def safe_division_236(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_237", "text": "def compute_sum_237(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_238", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_238(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_238(n-1) + fib_238(n-2)", "label": "1", "lang": "python"}
{"id": "AI_239", "text": "def structured_sum_239(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_240", "text": "def compute_average_240(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_241", "text": "import json\n\ndef load_and_filter_241(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_242", "text": "def compute_sum_242(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_243", "text": "def flatten_list_243(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_244", "text": "def validate_244(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_244(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_244(seq):\n    clean = convert_244(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_245", "text": "def nested_analysis_245(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_246", "text": "from typing import Dict, Any\n\ndef validate_payload_246(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_247", "text": "class ExecutionNode_247:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_247():\n    import math\n\n    root = ExecutionNode_247(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_247(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_247(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_248", "text": "def safe_division_248(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_249", "text": "class DataNormalizer_249:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_250", "text": "def analyze_series_250(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_251", "text": "import re\n\ndef clean_texts_251(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_252", "text": "def analyze_series_252(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_253", "text": "class Processor_253:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_254", "text": "class Processor_254:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_255", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_255(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_256", "text": "def safe_division_256(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_257", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_257(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_257(n-1) + fib_257(n-2)", "label": "1", "lang": "python"}
{"id": "AI_258", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_258(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_259", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_259(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_260", "text": "def is_prime_260(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_261", "text": "def meta_process_261(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_262", "text": "def validate_payload_262(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_263", "text": "import numpy as np\n\ndef normalize_features_263(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_264", "text": "def compute_stats_264(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_265", "text": "def count_characters_265(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_266", "text": "def analyze_series_266(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_267", "text": "import statistics\n\ndef stats_267(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_268", "text": "from typing import Dict, Any\n\ndef validate_payload_268(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_269", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_269(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_270", "text": "import numpy as np\n\ndef minmax_norm_270(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_271", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_271(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_272", "text": "def analyze_series_272(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_273", "text": "def generate_report_273(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_274", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_274(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_275", "text": "def safe_division_275(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_276", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_276(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_277", "text": "import numpy as np\n\ndef minmax_norm_277(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_278", "text": "def nested_analysis_278(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_279", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_279(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_280", "text": "class TextProcessor_280:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_281", "text": "def count_characters_281(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_282", "text": "from collections import Counter\n\ndef word_freq_282(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_283", "text": "import statistics\n\ndef stats_283(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_284", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_284:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_284:\n    tasks: List[Task_284] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_284(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_285", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_285(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_286", "text": "def safe_divide_286(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_287", "text": "def safe_reduce_287(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_288", "text": "def safe_divide_288(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_289", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_289(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_289(n-1) + fib_289(n-2)", "label": "1", "lang": "python"}
{"id": "AI_290", "text": "class TextProcessor_290:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_291", "text": "def compute_average_291(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_292", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_292():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_293", "text": "class ExecutionNode_293:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_293():\n    import math\n\n    root = ExecutionNode_293(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_293(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_293(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_294", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_294(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_294(n-1) + fib_294(n-2)", "label": "1", "lang": "python"}
{"id": "AI_295", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_295:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_295:\n    tasks: List[Task_295] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_295(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_296", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_296(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_297", "text": "class ExecutionNode_297:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_297():\n    import math\n\n    root = ExecutionNode_297(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_297(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_297(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_298", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_298(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_298(n-1) + fib_298(n-2)", "label": "1", "lang": "python"}
{"id": "AI_299", "text": "def safe_division_299(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_300", "text": "def flatten_list_300(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_301", "text": "def flatten_list_301(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_302", "text": "from typing import Dict, Any\n\ndef validate_payload_302(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_303", "text": "def nested_analysis_303(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_304", "text": "class Config_304:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_305", "text": "import numpy as np\n\ndef normalize_features_305(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_306", "text": "def compute_stats_306(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_307", "text": "def count_characters_307(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_308", "text": "from collections import Counter\n\ndef word_freq_308(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_309", "text": "import numpy as np\n\ndef validate_and_predict_309(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_310", "text": "class TextProcessor_310:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_311", "text": "def count_tokens_311(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_312", "text": "def nested_analysis_312(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_313", "text": "def validate_payload_313(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_314", "text": "def safe_divide_314(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_315", "text": "def validate_315(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_315(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_315(seq):\n    clean = convert_315(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_316", "text": "import re\n\ndef clean_texts_316(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_317", "text": "def extract_numeric_317(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_318", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_318(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_319", "text": "class DataNormalizer_319:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_320", "text": "import statistics\n\ndef stats_320(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_321", "text": "def compute_avg_321(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_322", "text": "def compute_average_322(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_323", "text": "def safe_reduce_323(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_324", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_324(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_325", "text": "def nested_analysis_325(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_326", "text": "from typing import Dict, Any\n\ndef validate_payload_326(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_327", "text": "import numpy as np\n\ndef normalize_features_327(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_328", "text": "def is_prime_328(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_329", "text": "def compute_average_329(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_330", "text": "import numpy as np\n\ndef validate_and_predict_330(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_331", "text": "def extract_numeric_331(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_332", "text": "def compute_average_332(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_333", "text": "import re\n\ndef clean_texts_333(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_334", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_334(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_335", "text": "class ExecutionNode_335:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_335():\n    import math\n\n    root = ExecutionNode_335(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_335(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_335(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_336", "text": "import json\n\ndef load_and_filter_336(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_337", "text": "def compute_sum_337(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_338", "text": "import json\n\ndef load_and_filter_338(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_339", "text": "def nested_analysis_339(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_340", "text": "class DataNormalizer_340:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_341", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_341(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_342", "text": "def validate_342(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_342(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_342(seq):\n    clean = convert_342(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_343", "text": "def safe_division_343(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_344", "text": "def safe_reduce_344(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_345", "text": "import numpy as np\n\ndef minmax_norm_345(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_346", "text": "def compute_sum_346(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_347", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_347(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_348", "text": "def compute_stats_348(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_349", "text": "def structured_sum_349(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_350", "text": "def validate_payload_350(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_351", "text": "def safe_reduce_351(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_352", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_352(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_352(n-1) + fib_352(n-2)", "label": "1", "lang": "python"}
{"id": "AI_353", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_353(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_354", "text": "def nested_analysis_354(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_355", "text": "def compute_stats_355(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_356", "text": "def safe_division_356(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_357", "text": "class Processor_357:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_358", "text": "import numpy as np\n\ndef validate_and_predict_358(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_359", "text": "def compute_stats_359(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_360", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_360(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_361", "text": "class TextProcessor_361:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_362", "text": "def meta_process_362(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_363", "text": "def analyze_series_363(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_364", "text": "def nested_analysis_364(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_365", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_365(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_365(n - 1) + fib_365(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_366", "text": "from collections import Counter\n\ndef word_freq_366(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_367", "text": "def is_prime_367(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_368", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_368(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_368(n - 1) + fib_368(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_369", "text": "import numpy as np\n\ndef validate_and_predict_369(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_370", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_370(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_371", "text": "def safe_division_371(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_372", "text": "def compute_stats_372(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_373", "text": "def meta_process_373(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_374", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_374(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_374(n - 1) + fib_374(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_375", "text": "def safe_division_375(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_376", "text": "def compute_sum_376(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_377", "text": "class Processor_377:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_378", "text": "def safe_division_378(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_379", "text": "import numpy as np\n\ndef normalize_features_379(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_380", "text": "def meta_process_380(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_381", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_381(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_381(n-1) + fib_381(n-2)", "label": "1", "lang": "python"}
{"id": "AI_382", "text": "def analyze_series_382(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_383", "text": "def structured_sum_383(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_384", "text": "def extract_numeric_384(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_385", "text": "def pipeline_process_385(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_386", "text": "import numpy as np\n\ndef normalize_features_386(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_387", "text": "import numpy as np\n\ndef validate_and_predict_387(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_388", "text": "class Config_388:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_389", "text": "def safe_division_389(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_390", "text": "import numpy as np\n\ndef normalize_features_390(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_391", "text": "def nested_analysis_391(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_392", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_392():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_393", "text": "class Config_393:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_394", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_394(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_395", "text": "def meta_process_395(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_396", "text": "def count_characters_396(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_397", "text": "def pipeline_process_397(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_398", "text": "def validate_payload_398(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_399", "text": "class DataNormalizer_399:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_400", "text": "def structured_sum_400(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_401", "text": "class TextProcessor_401:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_402", "text": "from collections import Counter\n\ndef word_freq_402(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_403", "text": "import numpy as np\n\ndef normalize_features_403(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_404", "text": "import numpy as np\n\ndef validate_and_predict_404(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_405", "text": "class Processor_405:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_406", "text": "def count_characters_406(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_407", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_407(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_407(n - 1) + fib_407(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_408", "text": "def safe_division_408(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_409", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_409(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_410", "text": "def extract_numeric_410(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_411", "text": "def is_prime_411(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_412", "text": "def safe_division_412(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_413", "text": "def analyze_series_413(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_414", "text": "def compute_sum_414(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_415", "text": "def nested_analysis_415(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_416", "text": "import numpy as np\n\ndef minmax_norm_416(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_417", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_417(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_418", "text": "import statistics\n\ndef stats_418(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_419", "text": "def compute_average_419(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_420", "text": "def safe_reduce_420(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_421", "text": "def pipeline_process_421(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_422", "text": "def meta_process_422(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_423", "text": "class Processor_423:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_424", "text": "class TextProcessor_424:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_425", "text": "class Config_425:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_426", "text": "def pipeline_process_426(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_427", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_427(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_428", "text": "def pipeline_process_428(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_429", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_429:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_429:\n    tasks: List[Task_429] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_429(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_430", "text": "def validate_payload_430(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_431", "text": "def validate_payload_431(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_432", "text": "def compute_average_432(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_433", "text": "import statistics\n\ndef stats_433(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_434", "text": "import numpy as np\n\ndef validate_and_predict_434(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_435", "text": "def compute_avg_435(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_436", "text": "import statistics\n\ndef stats_436(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_437", "text": "from collections import Counter\n\ndef word_freq_437(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_438", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_438(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_439", "text": "import re\n\ndef clean_texts_439(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_440", "text": "import numpy as np\n\ndef minmax_norm_440(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_441", "text": "def compute_avg_441(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_442", "text": "import numpy as np\n\ndef validate_and_predict_442(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_443", "text": "def meta_process_443(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_444", "text": "def pipeline_process_444(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_445", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_445(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_446", "text": "import numpy as np\n\ndef validate_and_predict_446(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_447", "text": "def compute_stats_447(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_448", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_448(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_449", "text": "class ExecutionNode_449:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_449():\n    import math\n\n    root = ExecutionNode_449(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_449(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_449(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_450", "text": "def compute_sum_450(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_451", "text": "def compute_sum_451(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_452", "text": "def safe_division_452(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_453", "text": "import numpy as np\n\ndef minmax_norm_453(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_454", "text": "def validate_payload_454(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_455", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_455(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_456", "text": "def extract_numeric_456(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_457", "text": "def meta_process_457(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_458", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_458(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_459", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_459(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_459(n-1) + fib_459(n-2)", "label": "1", "lang": "python"}
{"id": "AI_460", "text": "import numpy as np\n\ndef minmax_norm_460(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_461", "text": "def generate_report_461(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_462", "text": "import numpy as np\n\ndef validate_and_predict_462(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_463", "text": "def safe_reduce_463(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_464", "text": "class ExecutionNode_464:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_464():\n    import math\n\n    root = ExecutionNode_464(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_464(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_464(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_465", "text": "def compute_avg_465(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_466", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_466(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_467", "text": "def validate_payload_467(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_468", "text": "import re\n\ndef clean_texts_468(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_469", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_469(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_470", "text": "def count_tokens_470(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_471", "text": "def safe_divide_471(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_472", "text": "from typing import Dict, Any\n\ndef validate_payload_472(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_473", "text": "def compute_avg_473(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_474", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_474(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_475", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_475(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_476", "text": "def compute_sum_476(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_477", "text": "from collections import Counter\n\ndef word_freq_477(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_478", "text": "class Processor_478:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_479", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_479():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_480", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_480():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_481", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_481(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_481(n - 1) + fib_481(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_482", "text": "import re\n\ndef clean_texts_482(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_483", "text": "import re\n\ndef clean_texts_483(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_484", "text": "def compute_average_484(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_485", "text": "def safe_divide_485(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_486", "text": "import statistics\n\ndef stats_486(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_487", "text": "def flatten_list_487(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_488", "text": "import json\n\ndef load_and_filter_488(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_489", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_489(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_490", "text": "import numpy as np\n\ndef normalize_features_490(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_491", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_491(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_491(n-1) + fib_491(n-2)", "label": "1", "lang": "python"}
{"id": "AI_492", "text": "from collections import Counter\n\ndef word_freq_492(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_493", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_493(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_494", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_494(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_494(n-1) + fib_494(n-2)", "label": "1", "lang": "python"}
{"id": "AI_495", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_495():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_496", "text": "class DataNormalizer_496:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_497", "text": "class Processor_497:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_498", "text": "import statistics\n\ndef stats_498(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_499", "text": "def validate_payload_499(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_500", "text": "class Config_500:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_501", "text": "def analyze_series_501(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_502", "text": "def compute_avg_502(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_503", "text": "def generate_report_503(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_504", "text": "def safe_divide_504(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_505", "text": "def validate_payload_505(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_506", "text": "import re\n\ndef clean_texts_506(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_507", "text": "import statistics\n\ndef stats_507(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_508", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_508(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_509", "text": "def extract_numeric_509(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_510", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_510(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_511", "text": "def compute_stats_511(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_512", "text": "def extract_numeric_512(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_513", "text": "def flatten_list_513(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_514", "text": "def generate_report_514(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_515", "text": "def safe_divide_515(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_516", "text": "class DataNormalizer_516:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_517", "text": "def compute_sum_517(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_518", "text": "def pipeline_process_518(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_519", "text": "class Config_519:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_520", "text": "def compute_sum_520(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_521", "text": "def safe_divide_521(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_522", "text": "def generate_report_522(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_523", "text": "import re\n\ndef clean_texts_523(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_524", "text": "class TextProcessor_524:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_525", "text": "from collections import Counter\n\ndef word_freq_525(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_526", "text": "def safe_division_526(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_527", "text": "def compute_avg_527(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_528", "text": "def flatten_list_528(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_529", "text": "def flatten_list_529(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_530", "text": "class TextProcessor_530:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_531", "text": "def generate_report_531(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_532", "text": "def is_prime_532(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_533", "text": "def safe_division_533(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_534", "text": "def pipeline_process_534(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_535", "text": "def is_prime_535(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_536", "text": "def compute_avg_536(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_537", "text": "def meta_process_537(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_538", "text": "def structured_sum_538(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_539", "text": "def validate_payload_539(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_540", "text": "import numpy as np\n\ndef validate_and_predict_540(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_541", "text": "def meta_process_541(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_542", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_542():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_543", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_543:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_543:\n    tasks: List[Task_543] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_543(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_544", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_544(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_545", "text": "def safe_division_545(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_546", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_546(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_547", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_547:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_547:\n    tasks: List[Task_547] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_547(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_548", "text": "def safe_divide_548(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_549", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_549():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_550", "text": "def validate_550(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_550(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_550(seq):\n    clean = convert_550(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_551", "text": "import numpy as np\n\ndef validate_and_predict_551(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_552", "text": "import re\n\ndef clean_texts_552(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_553", "text": "class Config_553:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_554", "text": "def count_characters_554(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_555", "text": "def safe_division_555(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_556", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_556(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_557", "text": "import re\n\ndef clean_texts_557(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_558", "text": "class Config_558:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_559", "text": "import re\n\ndef clean_texts_559(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_560", "text": "def is_prime_560(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_561", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_561:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_561:\n    tasks: List[Task_561] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_561(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_562", "text": "def nested_analysis_562(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_563", "text": "def validate_payload_563(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_564", "text": "def pipeline_process_564(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_565", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_565(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_566", "text": "import numpy as np\n\ndef normalize_features_566(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_567", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_567:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_567:\n    tasks: List[Task_567] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_567(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_568", "text": "import numpy as np\n\ndef minmax_norm_568(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_569", "text": "import numpy as np\n\ndef minmax_norm_569(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_570", "text": "class Processor_570:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_571", "text": "class ExecutionNode_571:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_571():\n    import math\n\n    root = ExecutionNode_571(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_571(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_571(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_572", "text": "import json\n\ndef load_and_filter_572(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_573", "text": "class Config_573:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_574", "text": "def analyze_series_574(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_575", "text": "def compute_average_575(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_576", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_576(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_577", "text": "def generate_report_577(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_578", "text": "def pipeline_process_578(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_579", "text": "def safe_divide_579(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_580", "text": "import re\n\ndef clean_texts_580(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_581", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_581(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_582", "text": "import re\n\ndef clean_texts_582(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_583", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_583:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_583:\n    tasks: List[Task_583] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_583(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_584", "text": "def validate_584(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_584(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_584(seq):\n    clean = convert_584(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_585", "text": "class ExecutionNode_585:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_585():\n    import math\n\n    root = ExecutionNode_585(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_585(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_585(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_586", "text": "class TextProcessor_586:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_587", "text": "from collections import Counter\n\ndef word_freq_587(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_588", "text": "def structured_sum_588(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_589", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_589:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_589:\n    tasks: List[Task_589] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_589(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_590", "text": "def analyze_series_590(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_591", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_591():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_592", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_592(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_593", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_593(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_594", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_594():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_595", "text": "def extract_numeric_595(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_596", "text": "def safe_divide_596(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_597", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_597(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_598", "text": "def nested_analysis_598(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_599", "text": "def count_characters_599(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_600", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_600(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_600(n - 1) + fib_600(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_601", "text": "def structured_sum_601(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_602", "text": "def nested_analysis_602(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_603", "text": "def pipeline_process_603(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_604", "text": "def structured_sum_604(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_605", "text": "def structured_sum_605(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_606", "text": "class ExecutionNode_606:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_606():\n    import math\n\n    root = ExecutionNode_606(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_606(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_606(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_607", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_607(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_608", "text": "def compute_stats_608(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_609", "text": "def analyze_series_609(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_610", "text": "def validate_payload_610(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_611", "text": "import numpy as np\n\ndef validate_and_predict_611(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_612", "text": "def compute_average_612(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_613", "text": "def validate_613(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_613(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_613(seq):\n    clean = convert_613(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_614", "text": "from typing import Dict, Any\n\ndef validate_payload_614(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_615", "text": "import numpy as np\n\ndef minmax_norm_615(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_616", "text": "import numpy as np\n\ndef normalize_features_616(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_617", "text": "import numpy as np\n\ndef minmax_norm_617(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_618", "text": "import numpy as np\n\ndef minmax_norm_618(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_619", "text": "def nested_analysis_619(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_620", "text": "def compute_avg_620(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_621", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_621(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_622", "text": "class ExecutionNode_622:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_622():\n    import math\n\n    root = ExecutionNode_622(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_622(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_622(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_623", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_623():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_624", "text": "def validate_payload_624(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_625", "text": "def validate_payload_625(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_626", "text": "class Processor_626:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_627", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_627(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_627(n-1) + fib_627(n-2)", "label": "1", "lang": "python"}
{"id": "AI_628", "text": "from collections import Counter\n\ndef word_freq_628(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_629", "text": "def pipeline_process_629(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_630", "text": "def safe_division_630(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_631", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_631(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_632", "text": "import numpy as np\n\ndef minmax_norm_632(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_633", "text": "import statistics\n\ndef stats_633(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_634", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_634:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_634:\n    tasks: List[Task_634] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_634(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_635", "text": "def validate_payload_635(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_636", "text": "def meta_process_636(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_637", "text": "def compute_stats_637(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_638", "text": "class DataNormalizer_638:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_639", "text": "def validate_payload_639(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_640", "text": "def compute_sum_640(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_641", "text": "import numpy as np\n\ndef minmax_norm_641(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_642", "text": "def safe_reduce_642(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_643", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_643(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_644", "text": "import json\n\ndef load_and_filter_644(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_645", "text": "import numpy as np\n\ndef minmax_norm_645(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_646", "text": "def compute_stats_646(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_647", "text": "def validate_payload_647(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_648", "text": "def count_characters_648(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_649", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_649(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_650", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_650(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_651", "text": "def structured_sum_651(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_652", "text": "def compute_average_652(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_653", "text": "class TextProcessor_653:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_654", "text": "def count_characters_654(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_655", "text": "def count_tokens_655(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_656", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_656(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_656(n - 1) + fib_656(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_657", "text": "def compute_avg_657(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_658", "text": "def validate_payload_658(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_659", "text": "import json\n\ndef load_and_filter_659(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_660", "text": "def count_characters_660(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_661", "text": "def validate_661(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_661(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_661(seq):\n    clean = convert_661(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_662", "text": "from collections import Counter\n\ndef word_freq_662(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_663", "text": "def analyze_series_663(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_664", "text": "class ExecutionNode_664:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_664():\n    import math\n\n    root = ExecutionNode_664(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_664(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_664(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_665", "text": "def validate_665(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_665(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_665(seq):\n    clean = convert_665(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_666", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_666(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_667", "text": "def is_prime_667(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_668", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_668(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_668(n-1) + fib_668(n-2)", "label": "1", "lang": "python"}
{"id": "AI_669", "text": "def pipeline_process_669(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_670", "text": "class ExecutionNode_670:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_670():\n    import math\n\n    root = ExecutionNode_670(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_670(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_670(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_671", "text": "def safe_divide_671(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_672", "text": "def generate_report_672(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_673", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_673(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_673(n - 1) + fib_673(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_674", "text": "import json\n\ndef load_and_filter_674(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_675", "text": "def validate_payload_675(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_676", "text": "def safe_division_676(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_677", "text": "def is_prime_677(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_678", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_678(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_679", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_679():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_680", "text": "def safe_divide_680(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_681", "text": "class ExecutionNode_681:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_681():\n    import math\n\n    root = ExecutionNode_681(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_681(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_681(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_682", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_682(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_683", "text": "def flatten_list_683(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_684", "text": "def structured_sum_684(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_685", "text": "def validate_payload_685(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_686", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_686(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_687", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_687(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_687(n - 1) + fib_687(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_688", "text": "import statistics\n\ndef stats_688(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_689", "text": "def compute_sum_689(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_690", "text": "import numpy as np\n\ndef minmax_norm_690(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_691", "text": "def compute_avg_691(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_692", "text": "def meta_process_692(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_693", "text": "def extract_numeric_693(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_694", "text": "def flatten_list_694(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_695", "text": "def compute_sum_695(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_696", "text": "from typing import Dict, Any\n\ndef validate_payload_696(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_697", "text": "def compute_average_697(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_698", "text": "class Config_698:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_699", "text": "def compute_average_699(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_700", "text": "import json\n\ndef load_and_filter_700(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_701", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_701():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_702", "text": "def is_prime_702(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_703", "text": "class Config_703:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_704", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_704(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_705", "text": "def safe_division_705(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_706", "text": "def compute_average_706(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_707", "text": "def safe_divide_707(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_708", "text": "def compute_average_708(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_709", "text": "import numpy as np\n\ndef validate_and_predict_709(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_710", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_710(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_710(n - 1) + fib_710(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_711", "text": "def safe_reduce_711(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_712", "text": "def is_prime_712(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_713", "text": "class ExecutionNode_713:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_713():\n    import math\n\n    root = ExecutionNode_713(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_713(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_713(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_714", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_714(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_715", "text": "def validate_715(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_715(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_715(seq):\n    clean = convert_715(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_716", "text": "def meta_process_716(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_717", "text": "def count_tokens_717(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_718", "text": "def is_prime_718(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_719", "text": "from typing import Dict, Any\n\ndef validate_payload_719(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_720", "text": "def safe_reduce_720(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_721", "text": "def validate_payload_721(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_722", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_722(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_723", "text": "import numpy as np\n\ndef minmax_norm_723(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_724", "text": "def compute_average_724(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_725", "text": "import numpy as np\n\ndef validate_and_predict_725(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_726", "text": "class Processor_726:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_727", "text": "import numpy as np\n\ndef validate_and_predict_727(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_728", "text": "import statistics\n\ndef stats_728(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_729", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_729:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_729:\n    tasks: List[Task_729] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_729(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_730", "text": "def compute_stats_730(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_731", "text": "import numpy as np\n\ndef minmax_norm_731(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_732", "text": "def safe_division_732(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_733", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_733:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_733:\n    tasks: List[Task_733] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_733(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_734", "text": "def safe_reduce_734(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_735", "text": "from typing import Dict, Any\n\ndef validate_payload_735(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_736", "text": "def generate_report_736(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_737", "text": "def compute_stats_737(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_738", "text": "def count_characters_738(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_739", "text": "def validate_739(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_739(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_739(seq):\n    clean = convert_739(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_740", "text": "import numpy as np\n\ndef minmax_norm_740(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_741", "text": "import numpy as np\n\ndef normalize_features_741(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_742", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_742(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_743", "text": "def validate_743(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_743(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_743(seq):\n    clean = convert_743(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_744", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_744(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_745", "text": "def generate_report_745(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_746", "text": "def safe_divide_746(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_747", "text": "from typing import Dict, Any\n\ndef validate_payload_747(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_748", "text": "def validate_payload_748(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_749", "text": "import json\n\ndef load_and_filter_749(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_750", "text": "def generate_report_750(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_751", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_751(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_751(n - 1) + fib_751(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_752", "text": "class DataNormalizer_752:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_753", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_753(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_754", "text": "def validate_payload_754(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_755", "text": "import statistics\n\ndef stats_755(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_756", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_756(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_757", "text": "def pipeline_process_757(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_758", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_758(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_758(n - 1) + fib_758(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_759", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_759(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_760", "text": "import numpy as np\n\ndef minmax_norm_760(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_761", "text": "from typing import Dict, Any\n\ndef validate_payload_761(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_762", "text": "import numpy as np\n\ndef validate_and_predict_762(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_763", "text": "def compute_sum_763(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_764", "text": "def compute_stats_764(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_765", "text": "from collections import Counter\n\ndef word_freq_765(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_766", "text": "class ExecutionNode_766:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_766():\n    import math\n\n    root = ExecutionNode_766(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_766(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_766(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_767", "text": "def safe_division_767(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_768", "text": "def pipeline_process_768(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_769", "text": "def meta_process_769(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_770", "text": "import numpy as np\n\ndef normalize_features_770(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_771", "text": "class DataNormalizer_771:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_772", "text": "def compute_stats_772(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_773", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_773(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_774", "text": "def extract_numeric_774(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_775", "text": "def validate_payload_775(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_776", "text": "def safe_divide_776(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_777", "text": "def validate_777(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_777(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_777(seq):\n    clean = convert_777(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_778", "text": "def generate_report_778(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_779", "text": "import numpy as np\n\ndef minmax_norm_779(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_780", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_780(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_780(n - 1) + fib_780(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_781", "text": "def nested_analysis_781(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_782", "text": "class Processor_782:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_783", "text": "def count_characters_783(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_784", "text": "def validate_payload_784(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_785", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_785(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_785(n - 1) + fib_785(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_786", "text": "from typing import Dict, Any\n\ndef validate_payload_786(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_787", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_787(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_788", "text": "def pipeline_process_788(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_789", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_789():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_790", "text": "def analyze_series_790(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_791", "text": "def safe_division_791(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_792", "text": "class Processor_792:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_793", "text": "import numpy as np\n\ndef validate_and_predict_793(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_794", "text": "import re\n\ndef clean_texts_794(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_795", "text": "from collections import Counter\n\ndef word_freq_795(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_796", "text": "def compute_average_796(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_797", "text": "class DataNormalizer_797:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_798", "text": "def compute_stats_798(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_799", "text": "def structured_sum_799(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_800", "text": "def compute_avg_800(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_801", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_801:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_801:\n    tasks: List[Task_801] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_801(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_802", "text": "import re\n\ndef clean_texts_802(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_803", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_803:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_803:\n    tasks: List[Task_803] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_803(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_804", "text": "class Config_804:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_805", "text": "from collections import Counter\n\ndef word_freq_805(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_806", "text": "def structured_sum_806(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_807", "text": "class TextProcessor_807:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_808", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_808(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_808(n-1) + fib_808(n-2)", "label": "1", "lang": "python"}
{"id": "AI_809", "text": "def compute_sum_809(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_810", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_810(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_810(n - 1) + fib_810(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_811", "text": "import re\n\ndef clean_texts_811(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_812", "text": "def flatten_list_812(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_813", "text": "def nested_analysis_813(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_814", "text": "def meta_process_814(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_815", "text": "def validate_payload_815(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_816", "text": "def count_tokens_816(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_817", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_817:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_817:\n    tasks: List[Task_817] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_817(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_818", "text": "import numpy as np\n\ndef normalize_features_818(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_819", "text": "import statistics\n\ndef stats_819(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_820", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_820(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_821", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_821(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_822", "text": "def compute_average_822(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_823", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_823():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_824", "text": "import numpy as np\n\ndef normalize_features_824(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_825", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_825(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_826", "text": "def count_tokens_826(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_827", "text": "from collections import Counter\n\ndef word_freq_827(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_828", "text": "def validate_payload_828(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_829", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_829(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_830", "text": "class Config_830:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_831", "text": "from typing import Dict, Any\n\ndef validate_payload_831(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_832", "text": "def count_tokens_832(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_833", "text": "def count_characters_833(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_834", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_834(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_834(n-1) + fib_834(n-2)", "label": "1", "lang": "python"}
{"id": "AI_835", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_835(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_836", "text": "class Config_836:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_837", "text": "def safe_reduce_837(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_838", "text": "import numpy as np\n\ndef minmax_norm_838(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_839", "text": "class TextProcessor_839:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_840", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_840(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_841", "text": "class Config_841:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_842", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_842:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_842:\n    tasks: List[Task_842] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_842(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_843", "text": "def safe_division_843(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_844", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_844(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_845", "text": "class DataNormalizer_845:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_846", "text": "def compute_average_846(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_847", "text": "def analyze_series_847(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_848", "text": "def count_tokens_848(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_849", "text": "def compute_stats_849(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_850", "text": "import statistics\n\ndef stats_850(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_851", "text": "def compute_average_851(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_852", "text": "def compute_stats_852(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_853", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_853():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_854", "text": "import json\n\ndef load_and_filter_854(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_855", "text": "import statistics\n\ndef stats_855(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_856", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_856(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_857", "text": "from collections import Counter\n\ndef word_freq_857(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_858", "text": "def extract_numeric_858(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_859", "text": "def validate_859(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_859(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_859(seq):\n    clean = convert_859(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_860", "text": "def count_tokens_860(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_861", "text": "def extract_numeric_861(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_862", "text": "import numpy as np\n\ndef minmax_norm_862(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_863", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_863(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_864", "text": "def count_characters_864(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_865", "text": "def extract_numeric_865(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_866", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_866(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_867", "text": "import json\n\ndef load_and_filter_867(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_868", "text": "class Processor_868:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_869", "text": "import numpy as np\n\ndef normalize_features_869(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_870", "text": "def compute_stats_870(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_871", "text": "def flatten_list_871(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_872", "text": "def extract_numeric_872(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_873", "text": "class TextProcessor_873:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_874", "text": "import re\n\ndef clean_texts_874(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_875", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_875:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_875:\n    tasks: List[Task_875] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_875(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_876", "text": "def structured_sum_876(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_877", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_877(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_878", "text": "def compute_average_878(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_879", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_879():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_880", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_880(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_881", "text": "def flatten_list_881(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_882", "text": "import json\n\ndef load_and_filter_882(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_883", "text": "def safe_divide_883(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_884", "text": "class ExecutionNode_884:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_884():\n    import math\n\n    root = ExecutionNode_884(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_884(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_884(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_885", "text": "import re\n\ndef clean_texts_885(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_886", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_886(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_886(n - 1) + fib_886(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_887", "text": "import statistics\n\ndef stats_887(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_888", "text": "def flatten_list_888(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_889", "text": "def meta_process_889(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_890", "text": "def nested_analysis_890(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_891", "text": "import numpy as np\n\ndef normalize_features_891(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_892", "text": "def compute_avg_892(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_893", "text": "import numpy as np\n\ndef validate_and_predict_893(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_894", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_894(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_895", "text": "def compute_stats_895(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_896", "text": "from collections import Counter\n\ndef word_freq_896(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_897", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_897(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_898", "text": "def safe_divide_898(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_899", "text": "def pipeline_process_899(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_900", "text": "import numpy as np\n\ndef minmax_norm_900(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_901", "text": "from collections import Counter\n\ndef word_freq_901(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_902", "text": "def compute_avg_902(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_903", "text": "def compute_average_903(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_904", "text": "class ExecutionNode_904:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_904():\n    import math\n\n    root = ExecutionNode_904(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_904(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_904(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_905", "text": "import numpy as np\n\ndef normalize_features_905(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_906", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_906(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_906(n - 1) + fib_906(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_907", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_907():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_908", "text": "class ExecutionNode_908:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_908():\n    import math\n\n    root = ExecutionNode_908(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_908(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_908(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_909", "text": "class DataNormalizer_909:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_910", "text": "def validate_payload_910(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_911", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_911(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_911(n - 1) + fib_911(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_912", "text": "import numpy as np\n\ndef validate_and_predict_912(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_913", "text": "class Processor_913:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_914", "text": "def meta_process_914(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_915", "text": "def is_prime_915(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_916", "text": "def nested_analysis_916(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_917", "text": "def structured_sum_917(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_918", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_918(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_918(n-1) + fib_918(n-2)", "label": "1", "lang": "python"}
{"id": "AI_919", "text": "def extract_numeric_919(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_920", "text": "from collections import Counter\n\ndef word_freq_920(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_921", "text": "def validate_payload_921(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_922", "text": "def flatten_list_922(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_923", "text": "import statistics\n\ndef stats_923(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_924", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_924(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_925", "text": "import numpy as np\n\ndef validate_and_predict_925(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_926", "text": "class TextProcessor_926:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_927", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_927:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_927:\n    tasks: List[Task_927] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_927(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_928", "text": "import json\n\ndef load_and_filter_928(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_929", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_929(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_930", "text": "def analyze_series_930(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_931", "text": "class ExecutionNode_931:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_931():\n    import math\n\n    root = ExecutionNode_931(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_931(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_931(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_932", "text": "def compute_stats_932(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_933", "text": "class ExecutionNode_933:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_933():\n    import math\n\n    root = ExecutionNode_933(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_933(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_933(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_934", "text": "def count_tokens_934(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_935", "text": "import numpy as np\n\ndef validate_and_predict_935(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_936", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_936(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_937", "text": "import re\n\ndef clean_texts_937(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_938", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_938:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_938:\n    tasks: List[Task_938] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_938(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_939", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_939(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_940", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_940(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_941", "text": "def safe_divide_941(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_942", "text": "def flatten_list_942(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_943", "text": "def compute_sum_943(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_944", "text": "def compute_average_944(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_945", "text": "def generate_report_945(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_946", "text": "class Processor_946:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_947", "text": "from collections import Counter\n\ndef word_freq_947(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_948", "text": "from typing import Dict, Any\n\ndef validate_payload_948(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_949", "text": "def structured_sum_949(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_950", "text": "def safe_division_950(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_951", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_951(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_952", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_952(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_953", "text": "def safe_divide_953(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_954", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_954(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_955", "text": "def validate_955(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_955(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_955(seq):\n    clean = convert_955(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_956", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_956(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_957", "text": "def structured_sum_957(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_958", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_958(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_958(n - 1) + fib_958(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_959", "text": "def count_characters_959(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_960", "text": "def flatten_list_960(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_961", "text": "from typing import Dict, Any\n\ndef validate_payload_961(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_962", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_962(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_963", "text": "def nested_analysis_963(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_964", "text": "import numpy as np\n\ndef validate_and_predict_964(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_965", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_965(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_965(n-1) + fib_965(n-2)", "label": "1", "lang": "python"}
{"id": "AI_966", "text": "def extract_numeric_966(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_967", "text": "class TextProcessor_967:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_968", "text": "def count_tokens_968(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_969", "text": "def meta_process_969(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_970", "text": "import json\n\ndef load_and_filter_970(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_971", "text": "import re\n\ndef clean_texts_971(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_972", "text": "class Config_972:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_973", "text": "import json\n\ndef load_and_filter_973(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_974", "text": "class ExecutionNode_974:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_974():\n    import math\n\n    root = ExecutionNode_974(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_974(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_974(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_975", "text": "def flatten_list_975(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_976", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_976(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_977", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_977(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_977(n-1) + fib_977(n-2)", "label": "1", "lang": "python"}
{"id": "AI_978", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_978(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_979", "text": "def validate_979(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_979(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_979(seq):\n    clean = convert_979(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_980", "text": "def analyze_series_980(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_981", "text": "def validate_payload_981(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_982", "text": "def safe_division_982(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_983", "text": "import statistics\n\ndef stats_983(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_984", "text": "def count_characters_984(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_985", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_985(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_986", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_986(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_987", "text": "class Config_987:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_988", "text": "def compute_stats_988(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_989", "text": "import json\n\ndef load_and_filter_989(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_990", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_990(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_991", "text": "def validate_payload_991(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_992", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_992:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_992:\n    tasks: List[Task_992] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_992(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_993", "text": "def validate_payload_993(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_994", "text": "def compute_average_994(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_995", "text": "def meta_process_995(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_996", "text": "def compute_average_996(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_997", "text": "def safe_division_997(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_998", "text": "class Config_998:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_999", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_999:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_999:\n    tasks: List[Task_999] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_999(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_1000", "text": "def count_characters_1000(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_1001", "text": "def generate_report_1001(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1002", "text": "def safe_reduce_1002(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1003", "text": "import statistics\n\ndef stats_1003(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1004", "text": "def count_characters_1004(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_1005", "text": "def meta_process_1005(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1006", "text": "class Processor_1006:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1007", "text": "def safe_divide_1007(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_1008", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_1008:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_1008:\n    tasks: List[Task_1008] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_1008(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_1009", "text": "class Processor_1009:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1010", "text": "import numpy as np\n\ndef normalize_features_1010(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1011", "text": "def compute_avg_1011(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1012", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1012(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1013", "text": "def nested_analysis_1013(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1014", "text": "def safe_division_1014(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1015", "text": "def pipeline_process_1015(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1016", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_1016:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_1016:\n    tasks: List[Task_1016] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_1016(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_1017", "text": "def compute_avg_1017(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1018", "text": "def pipeline_process_1018(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1019", "text": "class Config_1019:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_1020", "text": "def nested_analysis_1020(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1021", "text": "def validate_payload_1021(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1022", "text": "class TextProcessor_1022:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1023", "text": "class Processor_1023:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1024", "text": "def meta_process_1024(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1025", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1025(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1026", "text": "def count_characters_1026(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_1027", "text": "def flatten_list_1027(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1028", "text": "def validate_1028(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_1028(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_1028(seq):\n    clean = convert_1028(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1029", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_1029(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_1030", "text": "import statistics\n\ndef stats_1030(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1031", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_1031():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1032", "text": "def analyze_series_1032(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1033", "text": "def meta_process_1033(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1034", "text": "def compute_average_1034(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_1035", "text": "class TextProcessor_1035:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1036", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1036(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1036(n-1) + fib_1036(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1037", "text": "def safe_division_1037(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1038", "text": "def count_tokens_1038(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1039", "text": "def extract_numeric_1039(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1040", "text": "def compute_average_1040(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_1041", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1041(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1041(n-1) + fib_1041(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1042", "text": "def flatten_list_1042(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1043", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1043(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1044", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_1044(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_1045", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1045(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1045(n-1) + fib_1045(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1046", "text": "def nested_analysis_1046(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1047", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_1047(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_1048", "text": "def validate_payload_1048(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1049", "text": "def compute_stats_1049(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1050", "text": "def compute_stats_1050(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1051", "text": "def validate_payload_1051(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1052", "text": "class Config_1052:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_1053", "text": "def nested_analysis_1053(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1054", "text": "def validate_1054(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_1054(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_1054(seq):\n    clean = convert_1054(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1055", "text": "class Processor_1055:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1056", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1056(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1057", "text": "def is_prime_1057(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1058", "text": "def safe_reduce_1058(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1059", "text": "class ExecutionNode_1059:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1059():\n    import math\n\n    root = ExecutionNode_1059(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1059(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1059(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1060", "text": "def count_tokens_1060(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1061", "text": "def is_prime_1061(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1062", "text": "class TextProcessor_1062:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1063", "text": "def safe_division_1063(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1064", "text": "def safe_division_1064(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1065", "text": "def count_tokens_1065(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1066", "text": "import numpy as np\n\ndef validate_and_predict_1066(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_1067", "text": "def safe_divide_1067(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_1068", "text": "def validate_payload_1068(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_1069", "text": "def is_prime_1069(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1070", "text": "def generate_report_1070(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1071", "text": "def generate_report_1071(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1072", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1072(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1072(n-1) + fib_1072(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1073", "text": "def safe_reduce_1073(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1074", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_1074():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1075", "text": "import json\n\ndef load_and_filter_1075(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1076", "text": "class DataNormalizer_1076:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1077", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_1077(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_1078", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_1078(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_1079", "text": "def extract_numeric_1079(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1080", "text": "def safe_division_1080(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1081", "text": "def validate_payload_1081(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_1082", "text": "class ExecutionNode_1082:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1082():\n    import math\n\n    root = ExecutionNode_1082(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1082(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1082(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1083", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1083(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1083(n - 1) + fib_1083(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1084", "text": "def generate_report_1084(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1085", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1085(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1085(n - 1) + fib_1085(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1086", "text": "import numpy as np\n\ndef minmax_norm_1086(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1087", "text": "def analyze_series_1087(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1088", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_1088(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_1089", "text": "def compute_avg_1089(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1090", "text": "def safe_division_1090(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1091", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1091(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1091(n - 1) + fib_1091(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1092", "text": "class DataNormalizer_1092:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1093", "text": "import numpy as np\n\ndef normalize_features_1093(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1094", "text": "def count_tokens_1094(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1095", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_1095():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1096", "text": "def safe_reduce_1096(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1097", "text": "def safe_divide_1097(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_1098", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1098(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1098(n-1) + fib_1098(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1099", "text": "def compute_avg_1099(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1100", "text": "def nested_analysis_1100(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1101", "text": "import numpy as np\n\ndef normalize_features_1101(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1102", "text": "def safe_division_1102(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1103", "text": "def structured_sum_1103(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1104", "text": "import numpy as np\n\ndef validate_and_predict_1104(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_1105", "text": "def analyze_series_1105(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1106", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_1106(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1107", "text": "def is_prime_1107(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1108", "text": "def count_tokens_1108(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1109", "text": "import re\n\ndef clean_texts_1109(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1110", "text": "import re\n\ndef clean_texts_1110(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1111", "text": "def pipeline_process_1111(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1112", "text": "def count_tokens_1112(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1113", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_1113(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1114", "text": "import re\n\ndef clean_texts_1114(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1115", "text": "def pipeline_process_1115(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1116", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1116(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1116(n - 1) + fib_1116(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1117", "text": "def safe_reduce_1117(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1118", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1118(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1118(n-1) + fib_1118(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1119", "text": "def compute_avg_1119(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1120", "text": "import json\n\ndef load_and_filter_1120(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1121", "text": "def analyze_series_1121(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1122", "text": "def flatten_list_1122(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1123", "text": "def pipeline_process_1123(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1124", "text": "def count_tokens_1124(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1125", "text": "def pipeline_process_1125(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1126", "text": "def validate_payload_1126(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_1127", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_1127(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_1128", "text": "import json\n\ndef load_and_filter_1128(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1129", "text": "def nested_analysis_1129(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1130", "text": "def flatten_list_1130(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1131", "text": "from typing import Dict, Any\n\ndef validate_payload_1131(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1132", "text": "import numpy as np\n\ndef minmax_norm_1132(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1133", "text": "def compute_stats_1133(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1134", "text": "from typing import Dict, Any\n\ndef validate_payload_1134(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1135", "text": "def compute_sum_1135(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1136", "text": "def compute_avg_1136(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1137", "text": "def validate_payload_1137(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1138", "text": "def meta_process_1138(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1139", "text": "def validate_1139(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_1139(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_1139(seq):\n    clean = convert_1139(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1140", "text": "import numpy as np\n\ndef normalize_features_1140(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1141", "text": "def safe_reduce_1141(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1142", "text": "def meta_process_1142(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1143", "text": "def is_prime_1143(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1144", "text": "def compute_average_1144(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_1145", "text": "def count_tokens_1145(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1146", "text": "from typing import Dict, Any\n\ndef validate_payload_1146(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1147", "text": "def generate_report_1147(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1148", "text": "from typing import Dict, Any\n\ndef validate_payload_1148(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1149", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_1149():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1150", "text": "def analyze_series_1150(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1151", "text": "def pipeline_process_1151(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1152", "text": "import json\n\ndef load_and_filter_1152(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1153", "text": "def validate_payload_1153(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1154", "text": "def structured_sum_1154(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1155", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_1155:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_1155:\n    tasks: List[Task_1155] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_1155(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_1156", "text": "class ExecutionNode_1156:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1156():\n    import math\n\n    root = ExecutionNode_1156(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1156(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1156(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1157", "text": "class ExecutionNode_1157:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1157():\n    import math\n\n    root = ExecutionNode_1157(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1157(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1157(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1158", "text": "def safe_reduce_1158(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1159", "text": "def count_tokens_1159(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1160", "text": "from typing import Dict, Any\n\ndef validate_payload_1160(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1161", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1161(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1162", "text": "import statistics\n\ndef stats_1162(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1163", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_1163(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1164", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1164(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1164(n - 1) + fib_1164(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1165", "text": "def safe_division_1165(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1166", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1166(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1166(n - 1) + fib_1166(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1167", "text": "class DataNormalizer_1167:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1168", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1168(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1169", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_1169(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1170", "text": "def compute_sum_1170(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1171", "text": "def extract_numeric_1171(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1172", "text": "from collections import Counter\n\ndef word_freq_1172(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1173", "text": "def flatten_list_1173(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1174", "text": "def is_prime_1174(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1175", "text": "from collections import Counter\n\ndef word_freq_1175(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1176", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_1176(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1177", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1177(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1177(n-1) + fib_1177(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1178", "text": "def generate_report_1178(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1179", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1179(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1180", "text": "def is_prime_1180(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1181", "text": "import numpy as np\n\ndef validate_and_predict_1181(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_1182", "text": "def validate_1182(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_1182(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_1182(seq):\n    clean = convert_1182(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1183", "text": "def count_tokens_1183(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1184", "text": "import json\n\ndef load_and_filter_1184(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1185", "text": "def extract_numeric_1185(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1186", "text": "class Processor_1186:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1187", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_1187(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1188", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_1188(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1189", "text": "import numpy as np\n\ndef minmax_norm_1189(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1190", "text": "def compute_stats_1190(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1191", "text": "def generate_report_1191(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1192", "text": "def compute_avg_1192(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1193", "text": "def analyze_series_1193(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1194", "text": "def validate_payload_1194(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1195", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_1195(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1196", "text": "def safe_divide_1196(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_1197", "text": "def safe_division_1197(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1198", "text": "from typing import Dict, Any\n\ndef validate_payload_1198(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1199", "text": "def structured_sum_1199(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1200", "text": "def compute_sum_1200(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1201", "text": "def nested_analysis_1201(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1202", "text": "def generate_report_1202(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1203", "text": "def is_prime_1203(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1204", "text": "class ExecutionNode_1204:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1204():\n    import math\n\n    root = ExecutionNode_1204(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1204(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1204(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1205", "text": "def generate_report_1205(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1206", "text": "def validate_payload_1206(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_1207", "text": "def count_tokens_1207(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1208", "text": "import json\n\ndef load_and_filter_1208(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1209", "text": "def safe_division_1209(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1210", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1210(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1211", "text": "def compute_sum_1211(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1212", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_1212:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_1212:\n    tasks: List[Task_1212] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_1212(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_1213", "text": "class TextProcessor_1213:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1214", "text": "def validate_1214(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_1214(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_1214(seq):\n    clean = convert_1214(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1215", "text": "from collections import Counter\n\ndef word_freq_1215(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1216", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1216(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1216(n - 1) + fib_1216(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1217", "text": "def pipeline_process_1217(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1218", "text": "def nested_analysis_1218(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1219", "text": "import numpy as np\n\ndef normalize_features_1219(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1220", "text": "def extract_numeric_1220(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1221", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1221(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1221(n - 1) + fib_1221(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1222", "text": "def analyze_series_1222(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1223", "text": "def count_tokens_1223(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1224", "text": "import json\n\ndef load_and_filter_1224(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1225", "text": "class Processor_1225:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1226", "text": "def compute_stats_1226(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1227", "text": "class TextProcessor_1227:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1228", "text": "def nested_analysis_1228(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1229", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_1229(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_1230", "text": "class Processor_1230:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1231", "text": "def extract_numeric_1231(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1232", "text": "from typing import Dict, Any\n\ndef validate_payload_1232(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1233", "text": "def count_characters_1233(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_1234", "text": "def analyze_series_1234(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1235", "text": "def compute_average_1235(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_1236", "text": "def count_characters_1236(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_1237", "text": "def safe_reduce_1237(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1238", "text": "def generate_report_1238(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1239", "text": "def compute_sum_1239(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1240", "text": "def pipeline_process_1240(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1241", "text": "from typing import Dict, Any\n\ndef validate_payload_1241(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1242", "text": "import numpy as np\n\ndef normalize_features_1242(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1243", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1243(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1243(n - 1) + fib_1243(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1244", "text": "from collections import Counter\n\ndef word_freq_1244(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1245", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1245(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1246", "text": "def analyze_series_1246(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1247", "text": "def structured_sum_1247(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1248", "text": "import numpy as np\n\ndef validate_and_predict_1248(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_1249", "text": "def generate_report_1249(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1250", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_1250:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_1250:\n    tasks: List[Task_1250] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_1250(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_1251", "text": "def meta_process_1251(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1252", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1252(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1252(n - 1) + fib_1252(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1253", "text": "def safe_division_1253(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1254", "text": "def pipeline_process_1254(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1255", "text": "def compute_sum_1255(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1256", "text": "def meta_process_1256(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1257", "text": "def nested_analysis_1257(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1258", "text": "class Config_1258:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_1259", "text": "def validate_payload_1259(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_1260", "text": "def validate_payload_1260(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_1261", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_1261(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_1262", "text": "import statistics\n\ndef stats_1262(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1263", "text": "def safe_division_1263(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1264", "text": "class DataNormalizer_1264:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1265", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1265(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1266", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_1266:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_1266:\n    tasks: List[Task_1266] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_1266(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_1267", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_1267:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_1267:\n    tasks: List[Task_1267] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_1267(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_1268", "text": "def validate_payload_1268(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_1269", "text": "def compute_average_1269(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_1270", "text": "def structured_sum_1270(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1271", "text": "def structured_sum_1271(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1272", "text": "def pipeline_process_1272(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1273", "text": "def nested_analysis_1273(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1274", "text": "class DataNormalizer_1274:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1275", "text": "def flatten_list_1275(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1276", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1276(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1276(n - 1) + fib_1276(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1277", "text": "import numpy as np\n\ndef minmax_norm_1277(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1278", "text": "def compute_average_1278(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_1279", "text": "def validate_payload_1279(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_1280", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1280(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1281", "text": "import numpy as np\n\ndef validate_and_predict_1281(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_1282", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1282(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1282(n-1) + fib_1282(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1283", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_1283(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_1284", "text": "def compute_average_1284(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_1285", "text": "def compute_avg_1285(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1286", "text": "def compute_sum_1286(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1287", "text": "def compute_sum_1287(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1288", "text": "import numpy as np\n\ndef validate_and_predict_1288(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_1289", "text": "def validate_payload_1289(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_1290", "text": "from collections import Counter\n\ndef word_freq_1290(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1291", "text": "import numpy as np\n\ndef normalize_features_1291(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1292", "text": "def extract_numeric_1292(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1293", "text": "import statistics\n\ndef stats_1293(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1294", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_1294(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_1295", "text": "def compute_average_1295(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_1296", "text": "def safe_division_1296(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1297", "text": "def safe_reduce_1297(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1298", "text": "import numpy as np\n\ndef minmax_norm_1298(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1299", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1299(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1299(n - 1) + fib_1299(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1300", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_1300:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_1300:\n    tasks: List[Task_1300] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_1300(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_1301", "text": "def safe_division_1301(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1302", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_1302(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1303", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1303(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1304", "text": "import statistics\n\ndef stats_1304(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1305", "text": "def count_tokens_1305(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1306", "text": "class Processor_1306:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1307", "text": "import json\n\ndef load_and_filter_1307(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1308", "text": "def validate_payload_1308(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1309", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_1309():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1310", "text": "def validate_payload_1310(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1311", "text": "def analyze_series_1311(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1312", "text": "import numpy as np\n\ndef minmax_norm_1312(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1313", "text": "import numpy as np\n\ndef minmax_norm_1313(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1314", "text": "class ExecutionNode_1314:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1314():\n    import math\n\n    root = ExecutionNode_1314(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1314(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1314(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1315", "text": "class Processor_1315:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1316", "text": "class ExecutionNode_1316:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1316():\n    import math\n\n    root = ExecutionNode_1316(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1316(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1316(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1317", "text": "class ExecutionNode_1317:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1317():\n    import math\n\n    root = ExecutionNode_1317(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1317(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1317(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1318", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1318(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1319", "text": "import numpy as np\n\ndef normalize_features_1319(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1320", "text": "def extract_numeric_1320(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1321", "text": "def compute_avg_1321(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1322", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1322(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1323", "text": "def meta_process_1323(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1324", "text": "def structured_sum_1324(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1325", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1325(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1326", "text": "def safe_reduce_1326(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1327", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_1327(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1328", "text": "def compute_sum_1328(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1329", "text": "def flatten_list_1329(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1330", "text": "def compute_sum_1330(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1331", "text": "def validate_1331(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_1331(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_1331(seq):\n    clean = convert_1331(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1332", "text": "def pipeline_process_1332(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1333", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1333(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1333(n - 1) + fib_1333(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1334", "text": "def generate_report_1334(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1335", "text": "import json\n\ndef load_and_filter_1335(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1336", "text": "def meta_process_1336(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1337", "text": "def count_characters_1337(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_1338", "text": "import re\n\ndef clean_texts_1338(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1339", "text": "class Processor_1339:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1340", "text": "import json\n\ndef load_and_filter_1340(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1341", "text": "def compute_average_1341(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_1342", "text": "class Processor_1342:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1343", "text": "class Processor_1343:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1344", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1344(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1345", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_1345:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_1345:\n    tasks: List[Task_1345] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_1345(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_1346", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1346(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1346(n-1) + fib_1346(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1347", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1347(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1348", "text": "class TextProcessor_1348:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1349", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_1349:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_1349:\n    tasks: List[Task_1349] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_1349(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_1350", "text": "class DataNormalizer_1350:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1351", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1351(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1352", "text": "import re\n\ndef clean_texts_1352(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1353", "text": "def nested_analysis_1353(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1354", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1354(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1354(n - 1) + fib_1354(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1355", "text": "import numpy as np\n\ndef normalize_features_1355(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1356", "text": "def nested_analysis_1356(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1357", "text": "def meta_process_1357(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1358", "text": "import re\n\ndef clean_texts_1358(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1359", "text": "def meta_process_1359(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1360", "text": "def safe_division_1360(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1361", "text": "def compute_average_1361(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_1362", "text": "class TextProcessor_1362:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1363", "text": "def count_tokens_1363(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1364", "text": "def count_characters_1364(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_1365", "text": "def count_characters_1365(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_1366", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1366(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1367", "text": "import statistics\n\ndef stats_1367(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1368", "text": "def validate_1368(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_1368(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_1368(seq):\n    clean = convert_1368(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1369", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_1369:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_1369:\n    tasks: List[Task_1369] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_1369(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_1370", "text": "def compute_avg_1370(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1371", "text": "def compute_avg_1371(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1372", "text": "def compute_sum_1372(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1373", "text": "import re\n\ndef clean_texts_1373(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1374", "text": "class Config_1374:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_1375", "text": "def compute_average_1375(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_1376", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1376(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1376(n - 1) + fib_1376(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1377", "text": "class Config_1377:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_1378", "text": "def generate_report_1378(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1379", "text": "from collections import Counter\n\ndef word_freq_1379(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1380", "text": "def is_prime_1380(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1381", "text": "import statistics\n\ndef stats_1381(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1382", "text": "def count_tokens_1382(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1383", "text": "class ExecutionNode_1383:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1383():\n    import math\n\n    root = ExecutionNode_1383(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1383(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1383(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1384", "text": "def safe_division_1384(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1385", "text": "def pipeline_process_1385(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1386", "text": "def generate_report_1386(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1387", "text": "def count_tokens_1387(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1388", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1388(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1388(n-1) + fib_1388(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1389", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_1389():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1390", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_1390(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_1391", "text": "def count_tokens_1391(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1392", "text": "def extract_numeric_1392(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1393", "text": "def compute_stats_1393(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1394", "text": "def compute_stats_1394(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1395", "text": "import numpy as np\n\ndef minmax_norm_1395(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1396", "text": "def is_prime_1396(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1397", "text": "class ExecutionNode_1397:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1397():\n    import math\n\n    root = ExecutionNode_1397(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1397(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1397(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1398", "text": "def compute_avg_1398(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1399", "text": "def compute_avg_1399(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1400", "text": "def compute_stats_1400(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1401", "text": "def safe_division_1401(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1402", "text": "def meta_process_1402(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1403", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1403(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1403(n-1) + fib_1403(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1404", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_1404(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_1405", "text": "def structured_sum_1405(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1406", "text": "from typing import Dict, Any\n\ndef validate_payload_1406(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1407", "text": "class Processor_1407:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1408", "text": "def safe_divide_1408(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_1409", "text": "def flatten_list_1409(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1410", "text": "def count_tokens_1410(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1411", "text": "def safe_division_1411(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1412", "text": "def flatten_list_1412(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1413", "text": "class Config_1413:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_1414", "text": "def count_tokens_1414(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1415", "text": "def extract_numeric_1415(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1416", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_1416(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_1417", "text": "def safe_divide_1417(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_1418", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_1418:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_1418:\n    tasks: List[Task_1418] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_1418(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_1419", "text": "def meta_process_1419(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1420", "text": "def safe_division_1420(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1421", "text": "from typing import Dict, Any\n\ndef validate_payload_1421(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1422", "text": "def safe_division_1422(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1423", "text": "def count_characters_1423(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_1424", "text": "import re\n\ndef clean_texts_1424(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1425", "text": "import json\n\ndef load_and_filter_1425(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1426", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1426(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1427", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_1427():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1428", "text": "def safe_divide_1428(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_1429", "text": "def is_prime_1429(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1430", "text": "from collections import Counter\n\ndef word_freq_1430(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1431", "text": "def nested_analysis_1431(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1432", "text": "class TextProcessor_1432:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1433", "text": "def validate_payload_1433(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1434", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_1434:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_1434:\n    tasks: List[Task_1434] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_1434(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_1435", "text": "from collections import Counter\n\ndef word_freq_1435(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1436", "text": "from collections import Counter\n\ndef word_freq_1436(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1437", "text": "def validate_1437(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_1437(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_1437(seq):\n    clean = convert_1437(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1438", "text": "def compute_sum_1438(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1439", "text": "def analyze_series_1439(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1440", "text": "def count_characters_1440(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_1441", "text": "import json\n\ndef load_and_filter_1441(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1442", "text": "def safe_divide_1442(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_1443", "text": "import json\n\ndef load_and_filter_1443(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1444", "text": "import numpy as np\n\ndef minmax_norm_1444(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1445", "text": "def is_prime_1445(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1446", "text": "def compute_avg_1446(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1447", "text": "class Processor_1447:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1448", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_1448():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1449", "text": "def flatten_list_1449(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1450", "text": "def extract_numeric_1450(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1451", "text": "import statistics\n\ndef stats_1451(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1452", "text": "def safe_divide_1452(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_1453", "text": "def compute_avg_1453(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1454", "text": "def meta_process_1454(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1455", "text": "def analyze_series_1455(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1456", "text": "def validate_payload_1456(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1457", "text": "from collections import Counter\n\ndef word_freq_1457(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1458", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_1458(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1459", "text": "from typing import Dict, Any\n\ndef validate_payload_1459(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1460", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1460(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1461", "text": "def compute_avg_1461(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1462", "text": "from typing import Dict, Any\n\ndef validate_payload_1462(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1463", "text": "import numpy as np\n\ndef normalize_features_1463(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1464", "text": "def safe_division_1464(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1465", "text": "import numpy as np\n\ndef minmax_norm_1465(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1466", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1466(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1467", "text": "class DataNormalizer_1467:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1468", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1468(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1468(n-1) + fib_1468(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1469", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1469(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1470", "text": "class TextProcessor_1470:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1471", "text": "import numpy as np\n\ndef validate_and_predict_1471(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_1472", "text": "def safe_reduce_1472(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1473", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_1473(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_1474", "text": "def count_characters_1474(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_1475", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1475(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1476", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1476(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1476(n-1) + fib_1476(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1477", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1477(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1477(n - 1) + fib_1477(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1478", "text": "class Processor_1478:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1479", "text": "def validate_payload_1479(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_1480", "text": "def pipeline_process_1480(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1481", "text": "def safe_division_1481(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1482", "text": "import json\n\ndef load_and_filter_1482(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1483", "text": "def is_prime_1483(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1484", "text": "def is_prime_1484(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1485", "text": "from typing import Dict, Any\n\ndef validate_payload_1485(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1486", "text": "class DataNormalizer_1486:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1487", "text": "def analyze_series_1487(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1488", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_1488(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1489", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1489(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1489(n - 1) + fib_1489(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1490", "text": "def analyze_series_1490(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1491", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1491(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1492", "text": "import statistics\n\ndef stats_1492(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1493", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_1493(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1494", "text": "def compute_avg_1494(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1495", "text": "def extract_numeric_1495(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1496", "text": "def analyze_series_1496(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1497", "text": "class ExecutionNode_1497:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1497():\n    import math\n\n    root = ExecutionNode_1497(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1497(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1497(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1498", "text": "class Config_1498:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_1499", "text": "class TextProcessor_1499:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1500", "text": "def analyze_series_1500(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1501", "text": "import numpy as np\n\ndef normalize_features_1501(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1502", "text": "class TextProcessor_1502:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1503", "text": "def generate_report_1503(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1504", "text": "def safe_division_1504(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1505", "text": "def extract_numeric_1505(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1506", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1506(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1506(n - 1) + fib_1506(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1507", "text": "import re\n\ndef clean_texts_1507(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1508", "text": "import numpy as np\n\ndef normalize_features_1508(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1509", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1509(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1510", "text": "def structured_sum_1510(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1511", "text": "import re\n\ndef clean_texts_1511(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1512", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1512(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1513", "text": "def compute_sum_1513(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1514", "text": "from collections import Counter\n\ndef word_freq_1514(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1515", "text": "class DataNormalizer_1515:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1516", "text": "def validate_1516(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_1516(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_1516(seq):\n    clean = convert_1516(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1517", "text": "def meta_process_1517(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1518", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1518(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1519", "text": "import numpy as np\n\ndef minmax_norm_1519(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1520", "text": "import numpy as np\n\ndef validate_and_predict_1520(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_1521", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1521(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1522", "text": "def analyze_series_1522(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1523", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_1523(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_1524", "text": "class TextProcessor_1524:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1525", "text": "def extract_numeric_1525(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1526", "text": "def safe_division_1526(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1527", "text": "def extract_numeric_1527(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1528", "text": "def compute_avg_1528(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1529", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_1529:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_1529:\n    tasks: List[Task_1529] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_1529(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_1530", "text": "def validate_payload_1530(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1531", "text": "import numpy as np\n\ndef normalize_features_1531(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1532", "text": "class DataNormalizer_1532:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1533", "text": "def compute_avg_1533(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1534", "text": "class Processor_1534:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1535", "text": "def extract_numeric_1535(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1536", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1536(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1537", "text": "class ExecutionNode_1537:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1537():\n    import math\n\n    root = ExecutionNode_1537(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1537(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1537(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1538", "text": "class Config_1538:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_1539", "text": "import numpy as np\n\ndef normalize_features_1539(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1540", "text": "def validate_1540(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_1540(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_1540(seq):\n    clean = convert_1540(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1541", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1541(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1541(n-1) + fib_1541(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1542", "text": "def compute_stats_1542(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1543", "text": "def compute_sum_1543(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1544", "text": "from collections import Counter\n\ndef word_freq_1544(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1545", "text": "import numpy as np\n\ndef minmax_norm_1545(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1546", "text": "def meta_process_1546(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1547", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1547(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1547(n-1) + fib_1547(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1548", "text": "class TextProcessor_1548:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1549", "text": "def safe_divide_1549(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_1550", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_1550(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_1551", "text": "def compute_sum_1551(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1552", "text": "def safe_division_1552(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1553", "text": "class Processor_1553:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1554", "text": "def analyze_series_1554(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1555", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1555(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1555(n-1) + fib_1555(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1556", "text": "def nested_analysis_1556(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1557", "text": "import numpy as np\n\ndef normalize_features_1557(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1558", "text": "class DataNormalizer_1558:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1559", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1559(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1560", "text": "import numpy as np\n\ndef minmax_norm_1560(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1561", "text": "import numpy as np\n\ndef validate_and_predict_1561(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_1562", "text": "import numpy as np\n\ndef minmax_norm_1562(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1563", "text": "def safe_divide_1563(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_1564", "text": "class ExecutionNode_1564:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1564():\n    import math\n\n    root = ExecutionNode_1564(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1564(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1564(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1565", "text": "def compute_stats_1565(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1566", "text": "import statistics\n\ndef stats_1566(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1567", "text": "import numpy as np\n\ndef normalize_features_1567(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1568", "text": "class Processor_1568:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1569", "text": "import json\n\ndef load_and_filter_1569(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1570", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_1570(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1571", "text": "def extract_numeric_1571(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1572", "text": "def safe_division_1572(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1573", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_1573:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_1573:\n    tasks: List[Task_1573] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_1573(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_1574", "text": "def analyze_series_1574(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1575", "text": "def pipeline_process_1575(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1576", "text": "def safe_reduce_1576(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1577", "text": "def count_tokens_1577(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1578", "text": "import numpy as np\n\ndef normalize_features_1578(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1579", "text": "import numpy as np\n\ndef validate_and_predict_1579(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_1580", "text": "def count_tokens_1580(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1581", "text": "def safe_divide_1581(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_1582", "text": "def validate_1582(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_1582(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_1582(seq):\n    clean = convert_1582(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1583", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1583(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1583(n - 1) + fib_1583(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1584", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1584(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1585", "text": "from collections import Counter\n\ndef word_freq_1585(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1586", "text": "import numpy as np\n\ndef minmax_norm_1586(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1587", "text": "def compute_average_1587(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_1588", "text": "def compute_stats_1588(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1589", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1589(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1590", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_1590(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1591", "text": "def count_tokens_1591(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1592", "text": "def validate_payload_1592(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_1593", "text": "def validate_payload_1593(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1594", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_1594():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1595", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1595(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1596", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_1596(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_1597", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1597(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1597(n-1) + fib_1597(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1598", "text": "from typing import Dict, Any\n\ndef validate_payload_1598(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1599", "text": "def extract_numeric_1599(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1600", "text": "def generate_report_1600(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1601", "text": "def compute_stats_1601(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1602", "text": "import statistics\n\ndef stats_1602(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1603", "text": "def safe_division_1603(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1604", "text": "def safe_division_1604(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1605", "text": "import numpy as np\n\ndef minmax_norm_1605(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1606", "text": "def compute_average_1606(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_1607", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_1607(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_1608", "text": "import json\n\ndef load_and_filter_1608(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1609", "text": "def generate_report_1609(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1610", "text": "import numpy as np\n\ndef normalize_features_1610(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1611", "text": "class DataNormalizer_1611:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1612", "text": "class TextProcessor_1612:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1613", "text": "import re\n\ndef clean_texts_1613(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1614", "text": "def safe_divide_1614(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_1615", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1615(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1616", "text": "def extract_numeric_1616(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1617", "text": "class Config_1617:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_1618", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1618(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1618(n-1) + fib_1618(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1619", "text": "def meta_process_1619(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1620", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_1620:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_1620:\n    tasks: List[Task_1620] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_1620(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_1621", "text": "class Processor_1621:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1622", "text": "def count_tokens_1622(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1623", "text": "def compute_sum_1623(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1624", "text": "def flatten_list_1624(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1625", "text": "class ExecutionNode_1625:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1625():\n    import math\n\n    root = ExecutionNode_1625(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1625(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1625(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1626", "text": "def nested_analysis_1626(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1627", "text": "def flatten_list_1627(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1628", "text": "def count_characters_1628(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_1629", "text": "def validate_payload_1629(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1630", "text": "def structured_sum_1630(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1631", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1631(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1631(n - 1) + fib_1631(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1632", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_1632(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1633", "text": "import statistics\n\ndef stats_1633(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1634", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1634(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1634(n - 1) + fib_1634(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1635", "text": "class DataNormalizer_1635:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1636", "text": "import numpy as np\n\ndef normalize_features_1636(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1637", "text": "def pipeline_process_1637(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1638", "text": "class ExecutionNode_1638:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1638():\n    import math\n\n    root = ExecutionNode_1638(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1638(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1638(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1639", "text": "def extract_numeric_1639(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1640", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_1640(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_1641", "text": "from collections import Counter\n\ndef word_freq_1641(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1642", "text": "from typing import Dict, Any\n\ndef validate_payload_1642(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1643", "text": "import numpy as np\n\ndef minmax_norm_1643(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1644", "text": "def analyze_series_1644(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1645", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1645(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1645(n - 1) + fib_1645(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1646", "text": "def structured_sum_1646(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1647", "text": "import statistics\n\ndef stats_1647(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1648", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_1648(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_1649", "text": "def extract_numeric_1649(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1650", "text": "def structured_sum_1650(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1651", "text": "def nested_analysis_1651(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1652", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_1652(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1653", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1653(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1653(n - 1) + fib_1653(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1654", "text": "def compute_sum_1654(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1655", "text": "def validate_1655(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_1655(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_1655(seq):\n    clean = convert_1655(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1656", "text": "import re\n\ndef clean_texts_1656(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1657", "text": "from typing import Dict, Any\n\ndef validate_payload_1657(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1658", "text": "def validate_payload_1658(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_1659", "text": "def is_prime_1659(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1660", "text": "import numpy as np\n\ndef normalize_features_1660(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1661", "text": "def count_tokens_1661(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1662", "text": "class Config_1662:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_1663", "text": "def count_tokens_1663(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1664", "text": "def is_prime_1664(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1665", "text": "def structured_sum_1665(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1666", "text": "def meta_process_1666(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1667", "text": "class TextProcessor_1667:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1668", "text": "def safe_division_1668(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1669", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_1669:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_1669:\n    tasks: List[Task_1669] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_1669(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_1670", "text": "import re\n\ndef clean_texts_1670(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1671", "text": "def compute_stats_1671(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1672", "text": "def structured_sum_1672(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1673", "text": "def compute_average_1673(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_1674", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1674(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1675", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1675(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1676", "text": "import numpy as np\n\ndef normalize_features_1676(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1677", "text": "def pipeline_process_1677(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1678", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_1678(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1679", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_1679(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_1680", "text": "def nested_analysis_1680(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1681", "text": "def structured_sum_1681(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1682", "text": "from typing import Dict, Any\n\ndef validate_payload_1682(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1683", "text": "class ExecutionNode_1683:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1683():\n    import math\n\n    root = ExecutionNode_1683(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1683(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1683(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1684", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1684(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1684(n - 1) + fib_1684(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1685", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1685(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1685(n-1) + fib_1685(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1686", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1686(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1687", "text": "class DataNormalizer_1687:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1688", "text": "import numpy as np\n\ndef validate_and_predict_1688(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_1689", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_1689():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1690", "text": "class Processor_1690:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1691", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_1691():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1692", "text": "def nested_analysis_1692(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1693", "text": "def count_characters_1693(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_1694", "text": "def is_prime_1694(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1695", "text": "class Config_1695:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_1696", "text": "from collections import Counter\n\ndef word_freq_1696(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1697", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_1697(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_1698", "text": "def analyze_series_1698(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1699", "text": "from typing import Dict, Any\n\ndef validate_payload_1699(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1700", "text": "class Processor_1700:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1701", "text": "class TextProcessor_1701:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1702", "text": "import statistics\n\ndef stats_1702(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1703", "text": "import numpy as np\n\ndef normalize_features_1703(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1704", "text": "def validate_payload_1704(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_1705", "text": "import numpy as np\n\ndef normalize_features_1705(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1706", "text": "import re\n\ndef clean_texts_1706(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1707", "text": "def safe_divide_1707(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_1708", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_1708():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1709", "text": "import statistics\n\ndef stats_1709(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1710", "text": "class ExecutionNode_1710:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1710():\n    import math\n\n    root = ExecutionNode_1710(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1710(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1710(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1711", "text": "from collections import Counter\n\ndef word_freq_1711(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1712", "text": "from typing import Dict, Any\n\ndef validate_payload_1712(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1713", "text": "import re\n\ndef clean_texts_1713(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1714", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1714(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1714(n-1) + fib_1714(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1715", "text": "def structured_sum_1715(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1716", "text": "def is_prime_1716(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1717", "text": "class DataNormalizer_1717:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1718", "text": "def count_characters_1718(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_1719", "text": "def nested_analysis_1719(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1720", "text": "class TextProcessor_1720:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1721", "text": "def generate_report_1721(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1722", "text": "class Processor_1722:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1723", "text": "class Processor_1723:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1724", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_1724():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1725", "text": "class Config_1725:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_1726", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_1726:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_1726:\n    tasks: List[Task_1726] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_1726(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_1727", "text": "import numpy as np\n\ndef normalize_features_1727(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1728", "text": "def validate_1728(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_1728(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_1728(seq):\n    clean = convert_1728(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1729", "text": "class Config_1729:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_1730", "text": "from collections import Counter\n\ndef word_freq_1730(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1731", "text": "def validate_1731(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_1731(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_1731(seq):\n    clean = convert_1731(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1732", "text": "def validate_payload_1732(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_1733", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1733(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1733(n-1) + fib_1733(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1734", "text": "def safe_reduce_1734(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1735", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1735(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1735(n - 1) + fib_1735(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1736", "text": "def nested_analysis_1736(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1737", "text": "import numpy as np\n\ndef minmax_norm_1737(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1738", "text": "def compute_avg_1738(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1739", "text": "import statistics\n\ndef stats_1739(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1740", "text": "def flatten_list_1740(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1741", "text": "def flatten_list_1741(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1742", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1742(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1743", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1743(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1743(n - 1) + fib_1743(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1744", "text": "class Processor_1744:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1745", "text": "from typing import Dict, Any\n\ndef validate_payload_1745(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1746", "text": "import numpy as np\n\ndef minmax_norm_1746(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1747", "text": "import numpy as np\n\ndef validate_and_predict_1747(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_1748", "text": "def safe_reduce_1748(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1749", "text": "class ExecutionNode_1749:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1749():\n    import math\n\n    root = ExecutionNode_1749(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1749(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1749(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1750", "text": "import json\n\ndef load_and_filter_1750(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1751", "text": "def pipeline_process_1751(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1752", "text": "def count_characters_1752(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_1753", "text": "def pipeline_process_1753(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1754", "text": "def flatten_list_1754(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1755", "text": "class TextProcessor_1755:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1756", "text": "import numpy as np\n\ndef minmax_norm_1756(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1757", "text": "import numpy as np\n\ndef minmax_norm_1757(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1758", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_1758():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1759", "text": "class TextProcessor_1759:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1760", "text": "def structured_sum_1760(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1761", "text": "def meta_process_1761(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1762", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_1762(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_1763", "text": "def safe_division_1763(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1764", "text": "from collections import Counter\n\ndef word_freq_1764(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1765", "text": "def is_prime_1765(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1766", "text": "import json\n\ndef load_and_filter_1766(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1767", "text": "def safe_reduce_1767(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1768", "text": "def validate_payload_1768(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1769", "text": "class ExecutionNode_1769:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1769():\n    import math\n\n    root = ExecutionNode_1769(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1769(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1769(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1770", "text": "def pipeline_process_1770(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1771", "text": "class Processor_1771:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1772", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_1772(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_1773", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1773(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1773(n - 1) + fib_1773(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1774", "text": "import json\n\ndef load_and_filter_1774(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1775", "text": "def compute_sum_1775(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1776", "text": "def safe_divide_1776(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_1777", "text": "import numpy as np\n\ndef minmax_norm_1777(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1778", "text": "def count_characters_1778(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_1779", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1779(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1780", "text": "def structured_sum_1780(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1781", "text": "def structured_sum_1781(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1782", "text": "import statistics\n\ndef stats_1782(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1783", "text": "class Config_1783:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_1784", "text": "from collections import Counter\n\ndef word_freq_1784(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1785", "text": "class ExecutionNode_1785:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1785():\n    import math\n\n    root = ExecutionNode_1785(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1785(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1785(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1786", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1786(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1786(n-1) + fib_1786(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1787", "text": "from collections import Counter\n\ndef word_freq_1787(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1788", "text": "def extract_numeric_1788(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1789", "text": "class DataNormalizer_1789:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1790", "text": "def generate_report_1790(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1791", "text": "def count_tokens_1791(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1792", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_1792():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1793", "text": "import statistics\n\ndef stats_1793(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1794", "text": "import numpy as np\n\ndef normalize_features_1794(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1795", "text": "import statistics\n\ndef stats_1795(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1796", "text": "def safe_division_1796(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1797", "text": "def safe_reduce_1797(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1798", "text": "class Config_1798:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_1799", "text": "import numpy as np\n\ndef minmax_norm_1799(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1800", "text": "def analyze_series_1800(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1801", "text": "def safe_division_1801(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1802", "text": "def count_tokens_1802(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1803", "text": "def count_characters_1803(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_1804", "text": "import json\n\ndef load_and_filter_1804(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1805", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_1805(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_1806", "text": "class Config_1806:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_1807", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_1807(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1808", "text": "def compute_avg_1808(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1809", "text": "def safe_reduce_1809(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1810", "text": "def validate_1810(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_1810(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_1810(seq):\n    clean = convert_1810(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1811", "text": "class Processor_1811:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1812", "text": "class TextProcessor_1812:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1813", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1813(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1813(n-1) + fib_1813(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1814", "text": "def compute_stats_1814(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1815", "text": "def nested_analysis_1815(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1816", "text": "import re\n\ndef clean_texts_1816(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1817", "text": "def validate_1817(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_1817(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_1817(seq):\n    clean = convert_1817(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1818", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1818(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1819", "text": "import re\n\ndef clean_texts_1819(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1820", "text": "import statistics\n\ndef stats_1820(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1821", "text": "import re\n\ndef clean_texts_1821(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1822", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1822(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1823", "text": "class TextProcessor_1823:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1824", "text": "def compute_stats_1824(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1825", "text": "import numpy as np\n\ndef minmax_norm_1825(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1826", "text": "class DataNormalizer_1826:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1827", "text": "class Processor_1827:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1828", "text": "class TextProcessor_1828:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1829", "text": "def compute_stats_1829(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1830", "text": "def compute_sum_1830(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1831", "text": "class DataNormalizer_1831:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1832", "text": "class Processor_1832:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1833", "text": "def compute_average_1833(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_1834", "text": "def validate_payload_1834(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_1835", "text": "def validate_payload_1835(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1836", "text": "import numpy as np\n\ndef normalize_features_1836(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1837", "text": "import numpy as np\n\ndef minmax_norm_1837(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1838", "text": "def extract_numeric_1838(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1839", "text": "import json\n\ndef load_and_filter_1839(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1840", "text": "def meta_process_1840(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1841", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_1841():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1842", "text": "def safe_reduce_1842(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1843", "text": "class DataNormalizer_1843:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1844", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_1844(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1845", "text": "class DataNormalizer_1845:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1846", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_1846(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_1847", "text": "def safe_reduce_1847(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1848", "text": "def compute_average_1848(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_1849", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_1849():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1850", "text": "import re\n\ndef clean_texts_1850(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1851", "text": "def extract_numeric_1851(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1852", "text": "import numpy as np\n\ndef minmax_norm_1852(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1853", "text": "def compute_average_1853(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_1854", "text": "def count_tokens_1854(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1855", "text": "def count_tokens_1855(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1856", "text": "import numpy as np\n\ndef normalize_features_1856(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1857", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1857(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1857(n - 1) + fib_1857(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1858", "text": "import numpy as np\n\ndef normalize_features_1858(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1859", "text": "def compute_average_1859(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_1860", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1860(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1860(n-1) + fib_1860(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1861", "text": "def compute_sum_1861(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1862", "text": "from typing import Dict, Any\n\ndef validate_payload_1862(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1863", "text": "class Processor_1863:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1864", "text": "class DataNormalizer_1864:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1865", "text": "def safe_divide_1865(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_1866", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_1866(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_1867", "text": "def safe_divide_1867(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_1868", "text": "class Config_1868:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_1869", "text": "class TextProcessor_1869:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1870", "text": "def validate_payload_1870(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_1871", "text": "class Processor_1871:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1872", "text": "import numpy as np\n\ndef normalize_features_1872(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1873", "text": "import numpy as np\n\ndef validate_and_predict_1873(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_1874", "text": "def generate_report_1874(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1875", "text": "def pipeline_process_1875(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1876", "text": "def meta_process_1876(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1877", "text": "def validate_payload_1877(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1878", "text": "from typing import Dict, Any\n\ndef validate_payload_1878(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1879", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1879(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1879(n - 1) + fib_1879(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1880", "text": "import re\n\ndef clean_texts_1880(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1881", "text": "def analyze_series_1881(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1882", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_1882(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_1883", "text": "class Processor_1883:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1884", "text": "import statistics\n\ndef stats_1884(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1885", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_1885(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_1886", "text": "def nested_analysis_1886(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1887", "text": "from typing import Dict, Any\n\ndef validate_payload_1887(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1888", "text": "def generate_report_1888(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1889", "text": "from typing import Dict, Any\n\ndef validate_payload_1889(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1890", "text": "import statistics\n\ndef stats_1890(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1891", "text": "def count_tokens_1891(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1892", "text": "def compute_stats_1892(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1893", "text": "import json\n\ndef load_and_filter_1893(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1894", "text": "import numpy as np\n\ndef normalize_features_1894(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1895", "text": "def safe_reduce_1895(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1896", "text": "def validate_1896(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_1896(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_1896(seq):\n    clean = convert_1896(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1897", "text": "import numpy as np\n\ndef validate_and_predict_1897(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_1898", "text": "def safe_division_1898(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1899", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_1899():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1900", "text": "from typing import Dict, Any\n\ndef validate_payload_1900(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1901", "text": "def validate_payload_1901(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1902", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_1902(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_1903", "text": "import json\n\ndef load_and_filter_1903(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1904", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1904(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1904(n - 1) + fib_1904(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1905", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_1905(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_1906", "text": "import json\n\ndef load_and_filter_1906(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_1907", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1907(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1907(n-1) + fib_1907(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1908", "text": "def extract_numeric_1908(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1909", "text": "def extract_numeric_1909(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1910", "text": "def pipeline_process_1910(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1911", "text": "def safe_division_1911(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_1912", "text": "import numpy as np\n\ndef normalize_features_1912(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1913", "text": "class DataNormalizer_1913:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1914", "text": "def compute_average_1914(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_1915", "text": "def is_prime_1915(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1916", "text": "def safe_reduce_1916(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1917", "text": "class ExecutionNode_1917:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1917():\n    import math\n\n    root = ExecutionNode_1917(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1917(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1917(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1918", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_1918(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_1918(n-1) + fib_1918(n-2)", "label": "1", "lang": "python"}
{"id": "AI_1919", "text": "def generate_report_1919(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1920", "text": "class Config_1920:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_1921", "text": "def validate_payload_1921(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_1922", "text": "def safe_reduce_1922(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1923", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_1923:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_1923:\n    tasks: List[Task_1923] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_1923(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_1924", "text": "def validate_payload_1924(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1925", "text": "def validate_payload_1925(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_1926", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1926(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1926(n - 1) + fib_1926(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1927", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_1927(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1928", "text": "class Processor_1928:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_1929", "text": "from collections import Counter\n\ndef word_freq_1929(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1930", "text": "def safe_divide_1930(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_1931", "text": "class Config_1931:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_1932", "text": "import numpy as np\n\ndef minmax_norm_1932(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1933", "text": "def meta_process_1933(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1934", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_1934():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1935", "text": "def extract_numeric_1935(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1936", "text": "import statistics\n\ndef stats_1936(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1937", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_1937(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_1938", "text": "from typing import Dict, Any\n\ndef validate_payload_1938(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1939", "text": "class ExecutionNode_1939:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1939():\n    import math\n\n    root = ExecutionNode_1939(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1939(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1939(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1940", "text": "import statistics\n\ndef stats_1940(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1941", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1941(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1942", "text": "def structured_sum_1942(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1943", "text": "def extract_numeric_1943(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1944", "text": "def safe_reduce_1944(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_1945", "text": "import statistics\n\ndef stats_1945(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1946", "text": "def structured_sum_1946(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1947", "text": "def structured_sum_1947(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1948", "text": "def generate_report_1948(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1949", "text": "def analyze_series_1949(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1950", "text": "import re\n\ndef clean_texts_1950(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1951", "text": "def pipeline_process_1951(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1952", "text": "def compute_avg_1952(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_1953", "text": "def flatten_list_1953(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1954", "text": "def analyze_series_1954(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1955", "text": "def safe_divide_1955(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_1956", "text": "import statistics\n\ndef stats_1956(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1957", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_1957():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1958", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_1958():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1959", "text": "def safe_divide_1959(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_1960", "text": "from collections import Counter\n\ndef word_freq_1960(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1961", "text": "def compute_average_1961(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_1962", "text": "def extract_numeric_1962(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1963", "text": "import numpy as np\n\ndef minmax_norm_1963(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_1964", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1964(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1965", "text": "from typing import Dict, Any\n\ndef validate_payload_1965(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_1966", "text": "class TextProcessor_1966:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1967", "text": "from collections import Counter\n\ndef word_freq_1967(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1968", "text": "import re\n\ndef clean_texts_1968(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1969", "text": "def extract_numeric_1969(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1970", "text": "def compute_sum_1970(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1971", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_1971(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_1971(n - 1) + fib_1971(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_1972", "text": "def structured_sum_1972(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1973", "text": "def compute_sum_1973(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1974", "text": "def extract_numeric_1974(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_1975", "text": "def meta_process_1975(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_1976", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_1976(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_1977", "text": "from collections import Counter\n\ndef word_freq_1977(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1978", "text": "def generate_report_1978(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1979", "text": "def generate_report_1979(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1980", "text": "def generate_report_1980(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1981", "text": "def compute_sum_1981(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_1982", "text": "class ExecutionNode_1982:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1982():\n    import math\n\n    root = ExecutionNode_1982(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1982(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1982(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1983", "text": "def compute_average_1983(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_1984", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_1984(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_1985", "text": "from collections import Counter\n\ndef word_freq_1985(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_1986", "text": "def pipeline_process_1986(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1987", "text": "def count_tokens_1987(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_1988", "text": "def structured_sum_1988(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_1989", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_1989:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_1989:\n    tasks: List[Task_1989] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_1989(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_1990", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_1990(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_1991", "text": "def validate_payload_1991(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_1992", "text": "class DataNormalizer_1992:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_1993", "text": "def pipeline_process_1993(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_1994", "text": "class ExecutionNode_1994:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_1994():\n    import math\n\n    root = ExecutionNode_1994(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_1994(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_1994(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_1995", "text": "class TextProcessor_1995:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_1996", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_1996(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_1997", "text": "import re\n\ndef clean_texts_1997(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_1998", "text": "def validate_payload_1998(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_1999", "text": "def compute_avg_1999(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2000", "text": "def count_tokens_2000(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2001", "text": "def is_prime_2001(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2002", "text": "import numpy as np\n\ndef validate_and_predict_2002(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2003", "text": "def flatten_list_2003(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2004", "text": "def compute_stats_2004(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2005", "text": "def meta_process_2005(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_2006", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2006(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2007", "text": "class DataNormalizer_2007:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_2008", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_2008(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_2009", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2009:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2009:\n    tasks: List[Task_2009] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2009(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2010", "text": "from typing import Dict, Any\n\ndef validate_payload_2010(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2011", "text": "class DataNormalizer_2011:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_2012", "text": "def structured_sum_2012(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2013", "text": "def safe_divide_2013(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2014", "text": "import re\n\ndef clean_texts_2014(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2015", "text": "import re\n\ndef clean_texts_2015(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2016", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2016(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2017", "text": "import numpy as np\n\ndef normalize_features_2017(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2018", "text": "def safe_reduce_2018(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_2019", "text": "import numpy as np\n\ndef normalize_features_2019(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2020", "text": "def flatten_list_2020(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2021", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2021:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2021:\n    tasks: List[Task_2021] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2021(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2022", "text": "def structured_sum_2022(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2023", "text": "def count_tokens_2023(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2024", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2024(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2025", "text": "def count_tokens_2025(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2026", "text": "def compute_avg_2026(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2027", "text": "def compute_stats_2027(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2028", "text": "def generate_report_2028(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2029", "text": "class DataNormalizer_2029:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_2030", "text": "import json\n\ndef load_and_filter_2030(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_2031", "text": "def extract_numeric_2031(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_2032", "text": "import numpy as np\n\ndef validate_and_predict_2032(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2033", "text": "def count_characters_2033(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2034", "text": "def compute_average_2034(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2035", "text": "from collections import Counter\n\ndef word_freq_2035(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_2036", "text": "def validate_payload_2036(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2037", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2037(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2037(n - 1) + fib_2037(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2038", "text": "import numpy as np\n\ndef validate_and_predict_2038(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2039", "text": "def validate_payload_2039(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2040", "text": "def compute_average_2040(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2041", "text": "def structured_sum_2041(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2042", "text": "def structured_sum_2042(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2043", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2043(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2044", "text": "def is_prime_2044(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2045", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_2045(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_2046", "text": "class Processor_2046:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_2047", "text": "def structured_sum_2047(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2048", "text": "def validate_payload_2048(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2049", "text": "def analyze_series_2049(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2050", "text": "import re\n\ndef clean_texts_2050(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2051", "text": "class TextProcessor_2051:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_2052", "text": "class Config_2052:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2053", "text": "import re\n\ndef clean_texts_2053(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2054", "text": "from collections import Counter\n\ndef word_freq_2054(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_2055", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2055:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2055:\n    tasks: List[Task_2055] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2055(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2056", "text": "def safe_division_2056(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2057", "text": "import re\n\ndef clean_texts_2057(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2058", "text": "def compute_avg_2058(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2059", "text": "class DataNormalizer_2059:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_2060", "text": "class Processor_2060:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_2061", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2061(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2061(n-1) + fib_2061(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2062", "text": "def analyze_series_2062(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2063", "text": "import statistics\n\ndef stats_2063(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2064", "text": "def analyze_series_2064(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2065", "text": "def safe_reduce_2065(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_2066", "text": "def analyze_series_2066(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2067", "text": "def nested_analysis_2067(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2068", "text": "def flatten_list_2068(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2069", "text": "class Config_2069:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2070", "text": "def count_characters_2070(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2071", "text": "from typing import Dict, Any\n\ndef validate_payload_2071(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2072", "text": "from typing import Dict, Any\n\ndef validate_payload_2072(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2073", "text": "def validate_2073(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_2073(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_2073(seq):\n    clean = convert_2073(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2074", "text": "def extract_numeric_2074(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_2075", "text": "def validate_payload_2075(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2076", "text": "from typing import Dict, Any\n\ndef validate_payload_2076(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2077", "text": "def generate_report_2077(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2078", "text": "def compute_stats_2078(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2079", "text": "class ExecutionNode_2079:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2079():\n    import math\n\n    root = ExecutionNode_2079(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2079(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2079(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2080", "text": "from typing import Dict, Any\n\ndef validate_payload_2080(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2081", "text": "def compute_stats_2081(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2082", "text": "def generate_report_2082(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2083", "text": "def validate_payload_2083(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2084", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2084(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2085", "text": "def count_characters_2085(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2086", "text": "def count_characters_2086(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2087", "text": "def is_prime_2087(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2088", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2088(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2089", "text": "def compute_avg_2089(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2090", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_2090(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_2091", "text": "def generate_report_2091(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2092", "text": "def compute_average_2092(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2093", "text": "def meta_process_2093(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_2094", "text": "import numpy as np\n\ndef normalize_features_2094(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2095", "text": "def is_prime_2095(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2096", "text": "def meta_process_2096(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_2097", "text": "class Processor_2097:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_2098", "text": "import numpy as np\n\ndef validate_and_predict_2098(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2099", "text": "class Processor_2099:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_2100", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2100(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2100(n-1) + fib_2100(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2101", "text": "def compute_average_2101(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2102", "text": "class TextProcessor_2102:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_2103", "text": "def compute_stats_2103(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2104", "text": "def is_prime_2104(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2105", "text": "class ExecutionNode_2105:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2105():\n    import math\n\n    root = ExecutionNode_2105(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2105(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2105(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2106", "text": "def structured_sum_2106(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2107", "text": "def count_tokens_2107(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2108", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2108(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2109", "text": "class DataNormalizer_2109:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_2110", "text": "def compute_avg_2110(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2111", "text": "def validate_payload_2111(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2112", "text": "def count_tokens_2112(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2113", "text": "def validate_2113(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_2113(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_2113(seq):\n    clean = convert_2113(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2114", "text": "def meta_process_2114(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_2115", "text": "def generate_report_2115(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2116", "text": "def validate_2116(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_2116(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_2116(seq):\n    clean = convert_2116(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2117", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_2117():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2118", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2118(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2118(n-1) + fib_2118(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2119", "text": "def count_tokens_2119(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2120", "text": "def safe_division_2120(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2121", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2121(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2121(n - 1) + fib_2121(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2122", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2122(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2122(n-1) + fib_2122(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2123", "text": "def structured_sum_2123(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2124", "text": "class ExecutionNode_2124:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2124():\n    import math\n\n    root = ExecutionNode_2124(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2124(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2124(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2125", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2125(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2125(n-1) + fib_2125(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2126", "text": "def structured_sum_2126(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2127", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2127(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2128", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_2128(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_2129", "text": "def generate_report_2129(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2130", "text": "def analyze_series_2130(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2131", "text": "def generate_report_2131(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2132", "text": "def pipeline_process_2132(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2133", "text": "def safe_reduce_2133(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_2134", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2134(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2134(n - 1) + fib_2134(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2135", "text": "def generate_report_2135(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2136", "text": "import statistics\n\ndef stats_2136(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2137", "text": "def analyze_series_2137(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2138", "text": "def count_characters_2138(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2139", "text": "def nested_analysis_2139(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2140", "text": "import numpy as np\n\ndef validate_and_predict_2140(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2141", "text": "import numpy as np\n\ndef minmax_norm_2141(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2142", "text": "def structured_sum_2142(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2143", "text": "def validate_payload_2143(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2144", "text": "def structured_sum_2144(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2145", "text": "import numpy as np\n\ndef minmax_norm_2145(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2146", "text": "def count_tokens_2146(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2147", "text": "def safe_divide_2147(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2148", "text": "import numpy as np\n\ndef validate_and_predict_2148(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2149", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2149(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2150", "text": "import numpy as np\n\ndef minmax_norm_2150(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2151", "text": "def safe_divide_2151(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2152", "text": "def meta_process_2152(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_2153", "text": "from collections import Counter\n\ndef word_freq_2153(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_2154", "text": "class Processor_2154:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_2155", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_2155(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_2156", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_2156():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2157", "text": "import statistics\n\ndef stats_2157(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2158", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2158(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2159", "text": "class TextProcessor_2159:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_2160", "text": "import numpy as np\n\ndef normalize_features_2160(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2161", "text": "def validate_payload_2161(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2162", "text": "from collections import Counter\n\ndef word_freq_2162(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_2163", "text": "import numpy as np\n\ndef validate_and_predict_2163(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2164", "text": "def safe_division_2164(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2165", "text": "class DataNormalizer_2165:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_2166", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2166(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2167", "text": "def validate_2167(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_2167(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_2167(seq):\n    clean = convert_2167(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2168", "text": "import numpy as np\n\ndef normalize_features_2168(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2169", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2169(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2169(n-1) + fib_2169(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2170", "text": "from typing import Dict, Any\n\ndef validate_payload_2170(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2171", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2171(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2172", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_2172(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_2173", "text": "import numpy as np\n\ndef validate_and_predict_2173(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2174", "text": "def analyze_series_2174(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2175", "text": "def structured_sum_2175(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2176", "text": "def meta_process_2176(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_2177", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2177:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2177:\n    tasks: List[Task_2177] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2177(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2178", "text": "import numpy as np\n\ndef validate_and_predict_2178(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2179", "text": "import re\n\ndef clean_texts_2179(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2180", "text": "import re\n\ndef clean_texts_2180(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2181", "text": "def structured_sum_2181(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2182", "text": "def validate_payload_2182(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2183", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2183(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2184", "text": "import json\n\ndef load_and_filter_2184(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_2185", "text": "def analyze_series_2185(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2186", "text": "def compute_avg_2186(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2187", "text": "class Processor_2187:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_2188", "text": "def pipeline_process_2188(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2189", "text": "def validate_payload_2189(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2190", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2190(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2190(n-1) + fib_2190(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2191", "text": "def validate_payload_2191(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2192", "text": "def is_prime_2192(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2193", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2193(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2193(n-1) + fib_2193(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2194", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_2194(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_2195", "text": "def validate_payload_2195(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2196", "text": "import json\n\ndef load_and_filter_2196(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_2197", "text": "from typing import Dict, Any\n\ndef validate_payload_2197(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2198", "text": "def validate_payload_2198(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2199", "text": "class ExecutionNode_2199:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2199():\n    import math\n\n    root = ExecutionNode_2199(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2199(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2199(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2200", "text": "class ExecutionNode_2200:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2200():\n    import math\n\n    root = ExecutionNode_2200(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2200(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2200(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2201", "text": "def validate_2201(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_2201(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_2201(seq):\n    clean = convert_2201(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2202", "text": "def structured_sum_2202(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2203", "text": "def is_prime_2203(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2204", "text": "import numpy as np\n\ndef normalize_features_2204(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2205", "text": "def compute_stats_2205(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2206", "text": "def generate_report_2206(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2207", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_2207():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2208", "text": "def compute_sum_2208(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_2209", "text": "class Config_2209:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2210", "text": "def compute_stats_2210(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2211", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_2211():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2212", "text": "from typing import Dict, Any\n\ndef validate_payload_2212(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2213", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2213(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2213(n - 1) + fib_2213(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2214", "text": "def is_prime_2214(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2215", "text": "def safe_reduce_2215(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_2216", "text": "def meta_process_2216(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_2217", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2217(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2218", "text": "class Processor_2218:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_2219", "text": "def safe_divide_2219(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2220", "text": "from typing import Dict, Any\n\ndef validate_payload_2220(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2221", "text": "def count_tokens_2221(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2222", "text": "import re\n\ndef clean_texts_2222(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2223", "text": "def flatten_list_2223(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2224", "text": "def safe_division_2224(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2225", "text": "from typing import Dict, Any\n\ndef validate_payload_2225(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2226", "text": "def safe_division_2226(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2227", "text": "def count_characters_2227(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2228", "text": "def compute_sum_2228(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_2229", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2229(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2229(n - 1) + fib_2229(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2230", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2230(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2230(n-1) + fib_2230(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2231", "text": "def safe_division_2231(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2232", "text": "class ExecutionNode_2232:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2232():\n    import math\n\n    root = ExecutionNode_2232(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2232(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2232(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2233", "text": "def nested_analysis_2233(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2234", "text": "import numpy as np\n\ndef minmax_norm_2234(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2235", "text": "def generate_report_2235(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2236", "text": "import numpy as np\n\ndef normalize_features_2236(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2237", "text": "def safe_division_2237(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2238", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_2238(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_2239", "text": "import statistics\n\ndef stats_2239(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2240", "text": "import numpy as np\n\ndef minmax_norm_2240(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2241", "text": "import statistics\n\ndef stats_2241(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2242", "text": "def meta_process_2242(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_2243", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2243(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2244", "text": "def safe_division_2244(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2245", "text": "class Config_2245:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2246", "text": "import numpy as np\n\ndef minmax_norm_2246(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2247", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_2247(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_2248", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2248(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2249", "text": "def meta_process_2249(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_2250", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2250(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2250(n-1) + fib_2250(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2251", "text": "def safe_divide_2251(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2252", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2252(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2253", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2253(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2253(n-1) + fib_2253(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2254", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2254(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2255", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2255(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2256", "text": "import re\n\ndef clean_texts_2256(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2257", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2257(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2257(n - 1) + fib_2257(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2258", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2258(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2259", "text": "def count_characters_2259(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2260", "text": "def safe_division_2260(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2261", "text": "def structured_sum_2261(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2262", "text": "def compute_average_2262(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2263", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_2263(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_2264", "text": "def compute_average_2264(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2265", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2265(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2266", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2266(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2267", "text": "def safe_divide_2267(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2268", "text": "import numpy as np\n\ndef validate_and_predict_2268(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2269", "text": "def count_tokens_2269(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2270", "text": "def generate_report_2270(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2271", "text": "def compute_stats_2271(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2272", "text": "def safe_reduce_2272(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_2273", "text": "def validate_payload_2273(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2274", "text": "def pipeline_process_2274(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2275", "text": "def nested_analysis_2275(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2276", "text": "import json\n\ndef load_and_filter_2276(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_2277", "text": "class TextProcessor_2277:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_2278", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2278(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2279", "text": "def validate_2279(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_2279(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_2279(seq):\n    clean = convert_2279(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2280", "text": "def compute_sum_2280(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_2281", "text": "def flatten_list_2281(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2282", "text": "def count_characters_2282(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2283", "text": "def safe_division_2283(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2284", "text": "def safe_division_2284(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2285", "text": "def meta_process_2285(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_2286", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2286(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2287", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2287(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2287(n - 1) + fib_2287(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2288", "text": "def safe_reduce_2288(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_2289", "text": "def safe_divide_2289(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2290", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2290(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2290(n-1) + fib_2290(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2291", "text": "def extract_numeric_2291(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_2292", "text": "import numpy as np\n\ndef validate_and_predict_2292(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2293", "text": "class TextProcessor_2293:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_2294", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2294:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2294:\n    tasks: List[Task_2294] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2294(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2295", "text": "def compute_stats_2295(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2296", "text": "def count_characters_2296(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2297", "text": "class Config_2297:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2298", "text": "def compute_stats_2298(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2299", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_2299(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_2300", "text": "def is_prime_2300(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2301", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_2301(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_2302", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2302(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2302(n-1) + fib_2302(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2303", "text": "class DataNormalizer_2303:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_2304", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2304(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2305", "text": "import numpy as np\n\ndef validate_and_predict_2305(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2306", "text": "def validate_payload_2306(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2307", "text": "import numpy as np\n\ndef minmax_norm_2307(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2308", "text": "def pipeline_process_2308(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2309", "text": "def count_tokens_2309(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2310", "text": "def validate_2310(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_2310(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_2310(seq):\n    clean = convert_2310(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2311", "text": "def meta_process_2311(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_2312", "text": "import statistics\n\ndef stats_2312(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2313", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_2313():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2314", "text": "def nested_analysis_2314(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2315", "text": "def compute_sum_2315(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_2316", "text": "def compute_stats_2316(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2317", "text": "def flatten_list_2317(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2318", "text": "def count_characters_2318(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2319", "text": "def safe_divide_2319(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2320", "text": "import numpy as np\n\ndef validate_and_predict_2320(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2321", "text": "def safe_reduce_2321(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_2322", "text": "def compute_sum_2322(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_2323", "text": "def safe_division_2323(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2324", "text": "def compute_average_2324(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2325", "text": "class DataNormalizer_2325:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_2326", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2326(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2326(n - 1) + fib_2326(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2327", "text": "def safe_division_2327(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2328", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2328(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2329", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_2329(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_2330", "text": "def pipeline_process_2330(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2331", "text": "import json\n\ndef load_and_filter_2331(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_2332", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2332(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2333", "text": "def compute_sum_2333(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_2334", "text": "def safe_divide_2334(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2335", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_2335():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2336", "text": "def meta_process_2336(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_2337", "text": "import json\n\ndef load_and_filter_2337(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_2338", "text": "class ExecutionNode_2338:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2338():\n    import math\n\n    root = ExecutionNode_2338(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2338(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2338(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2339", "text": "import numpy as np\n\ndef minmax_norm_2339(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2340", "text": "def count_characters_2340(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2341", "text": "from typing import Dict, Any\n\ndef validate_payload_2341(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2342", "text": "def is_prime_2342(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2343", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2343(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2343(n - 1) + fib_2343(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2344", "text": "from collections import Counter\n\ndef word_freq_2344(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_2345", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_2345(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_2346", "text": "import numpy as np\n\ndef validate_and_predict_2346(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2347", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2347(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2348", "text": "def extract_numeric_2348(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_2349", "text": "def compute_average_2349(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2350", "text": "def generate_report_2350(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2351", "text": "def structured_sum_2351(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2352", "text": "def generate_report_2352(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2353", "text": "class Config_2353:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2354", "text": "def extract_numeric_2354(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_2355", "text": "def safe_divide_2355(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2356", "text": "def safe_divide_2356(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2357", "text": "def nested_analysis_2357(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2358", "text": "import statistics\n\ndef stats_2358(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2359", "text": "def is_prime_2359(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2360", "text": "def nested_analysis_2360(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2361", "text": "import numpy as np\n\ndef minmax_norm_2361(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2362", "text": "def compute_stats_2362(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2363", "text": "def flatten_list_2363(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2364", "text": "class Config_2364:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2365", "text": "def nested_analysis_2365(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2366", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_2366(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_2367", "text": "def nested_analysis_2367(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2368", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_2368(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_2369", "text": "def extract_numeric_2369(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_2370", "text": "def compute_stats_2370(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2371", "text": "def count_characters_2371(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2372", "text": "class Config_2372:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2373", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2373(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2373(n-1) + fib_2373(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2374", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_2374(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_2375", "text": "def validate_payload_2375(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2376", "text": "def pipeline_process_2376(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2377", "text": "def count_tokens_2377(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2378", "text": "def structured_sum_2378(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2379", "text": "def pipeline_process_2379(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2380", "text": "import numpy as np\n\ndef validate_and_predict_2380(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2381", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_2381():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2382", "text": "def nested_analysis_2382(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2383", "text": "def compute_average_2383(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2384", "text": "def extract_numeric_2384(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_2385", "text": "def safe_divide_2385(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2386", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2386(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2387", "text": "def safe_division_2387(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2388", "text": "def compute_avg_2388(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2389", "text": "def flatten_list_2389(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2390", "text": "import json\n\ndef load_and_filter_2390(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_2391", "text": "def safe_division_2391(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2392", "text": "def count_characters_2392(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2393", "text": "def generate_report_2393(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2394", "text": "def structured_sum_2394(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2395", "text": "def safe_division_2395(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2396", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2396(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2397", "text": "class TextProcessor_2397:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_2398", "text": "import numpy as np\n\ndef normalize_features_2398(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2399", "text": "def validate_payload_2399(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2400", "text": "class ExecutionNode_2400:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2400():\n    import math\n\n    root = ExecutionNode_2400(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2400(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2400(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2401", "text": "def count_characters_2401(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2402", "text": "def is_prime_2402(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2403", "text": "def is_prime_2403(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2404", "text": "def count_tokens_2404(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2405", "text": "import re\n\ndef clean_texts_2405(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2406", "text": "import statistics\n\ndef stats_2406(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2407", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2407(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2408", "text": "def analyze_series_2408(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2409", "text": "def count_tokens_2409(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2410", "text": "def generate_report_2410(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2411", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2411(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2411(n-1) + fib_2411(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2412", "text": "import json\n\ndef load_and_filter_2412(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_2413", "text": "def count_tokens_2413(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2414", "text": "class Processor_2414:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_2415", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2415(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2416", "text": "def count_characters_2416(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2417", "text": "class Config_2417:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2418", "text": "def pipeline_process_2418(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2419", "text": "from typing import Dict, Any\n\ndef validate_payload_2419(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2420", "text": "import numpy as np\n\ndef minmax_norm_2420(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2421", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2421(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2421(n-1) + fib_2421(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2422", "text": "def compute_average_2422(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2423", "text": "def safe_reduce_2423(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_2424", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_2424(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_2425", "text": "def pipeline_process_2425(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2426", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_2426(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_2427", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2427(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2428", "text": "import json\n\ndef load_and_filter_2428(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_2429", "text": "def count_tokens_2429(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2430", "text": "import numpy as np\n\ndef minmax_norm_2430(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2431", "text": "import statistics\n\ndef stats_2431(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2432", "text": "from collections import Counter\n\ndef word_freq_2432(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_2433", "text": "def is_prime_2433(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2434", "text": "def generate_report_2434(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2435", "text": "def analyze_series_2435(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2436", "text": "import statistics\n\ndef stats_2436(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2437", "text": "def analyze_series_2437(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2438", "text": "def is_prime_2438(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2439", "text": "import numpy as np\n\ndef validate_and_predict_2439(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2440", "text": "def nested_analysis_2440(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2441", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2441(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2442", "text": "import numpy as np\n\ndef normalize_features_2442(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2443", "text": "def compute_stats_2443(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2444", "text": "def analyze_series_2444(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2445", "text": "def safe_divide_2445(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2446", "text": "def validate_2446(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_2446(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_2446(seq):\n    clean = convert_2446(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2447", "text": "def structured_sum_2447(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2448", "text": "def analyze_series_2448(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2449", "text": "def analyze_series_2449(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2450", "text": "def extract_numeric_2450(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_2451", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_2451(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_2452", "text": "def structured_sum_2452(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2453", "text": "def compute_avg_2453(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2454", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2454(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2455", "text": "import numpy as np\n\ndef minmax_norm_2455(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2456", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2456:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2456:\n    tasks: List[Task_2456] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2456(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2457", "text": "import numpy as np\n\ndef validate_and_predict_2457(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2458", "text": "class TextProcessor_2458:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_2459", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2459(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2460", "text": "class Config_2460:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2461", "text": "def validate_payload_2461(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2462", "text": "def compute_sum_2462(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_2463", "text": "def meta_process_2463(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_2464", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2464(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2465", "text": "class ExecutionNode_2465:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2465():\n    import math\n\n    root = ExecutionNode_2465(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2465(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2465(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2466", "text": "import json\n\ndef load_and_filter_2466(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_2467", "text": "def validate_payload_2467(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2468", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2468(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2468(n-1) + fib_2468(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2469", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2469:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2469:\n    tasks: List[Task_2469] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2469(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2470", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2470(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2470(n - 1) + fib_2470(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2471", "text": "class DataNormalizer_2471:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_2472", "text": "class ExecutionNode_2472:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2472():\n    import math\n\n    root = ExecutionNode_2472(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2472(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2472(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2473", "text": "class TextProcessor_2473:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_2474", "text": "def nested_analysis_2474(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2475", "text": "def extract_numeric_2475(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_2476", "text": "import numpy as np\n\ndef validate_and_predict_2476(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2477", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2477:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2477:\n    tasks: List[Task_2477] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2477(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2478", "text": "def count_characters_2478(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2479", "text": "def extract_numeric_2479(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_2480", "text": "def structured_sum_2480(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2481", "text": "def safe_divide_2481(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2482", "text": "def validate_payload_2482(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2483", "text": "def flatten_list_2483(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2484", "text": "def analyze_series_2484(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2485", "text": "def extract_numeric_2485(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_2486", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_2486(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_2487", "text": "def compute_average_2487(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2488", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_2488(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_2489", "text": "def safe_divide_2489(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2490", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2490(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2490(n-1) + fib_2490(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2491", "text": "from typing import Dict, Any\n\ndef validate_payload_2491(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2492", "text": "import statistics\n\ndef stats_2492(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2493", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2493:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2493:\n    tasks: List[Task_2493] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2493(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2494", "text": "import numpy as np\n\ndef minmax_norm_2494(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2495", "text": "import numpy as np\n\ndef validate_and_predict_2495(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2496", "text": "def validate_2496(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_2496(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_2496(seq):\n    clean = convert_2496(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2497", "text": "def flatten_list_2497(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2498", "text": "from typing import Dict, Any\n\ndef validate_payload_2498(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2499", "text": "def flatten_list_2499(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2500", "text": "import numpy as np\n\ndef validate_and_predict_2500(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2501", "text": "def safe_reduce_2501(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_2502", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2502(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2503", "text": "def analyze_series_2503(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2504", "text": "def validate_payload_2504(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2505", "text": "def count_tokens_2505(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2506", "text": "def count_tokens_2506(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2507", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2507(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2507(n - 1) + fib_2507(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2508", "text": "def compute_avg_2508(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2509", "text": "from collections import Counter\n\ndef word_freq_2509(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_2510", "text": "class Config_2510:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2511", "text": "def validate_payload_2511(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2512", "text": "def validate_payload_2512(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2513", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2513(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2513(n-1) + fib_2513(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2514", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2514(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2515", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2515(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2515(n-1) + fib_2515(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2516", "text": "def compute_avg_2516(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2517", "text": "class Config_2517:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2518", "text": "def safe_divide_2518(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2519", "text": "def count_tokens_2519(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2520", "text": "def safe_division_2520(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2521", "text": "import statistics\n\ndef stats_2521(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2522", "text": "def compute_stats_2522(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2523", "text": "def flatten_list_2523(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2524", "text": "from collections import Counter\n\ndef word_freq_2524(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_2525", "text": "def structured_sum_2525(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2526", "text": "def validate_2526(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_2526(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_2526(seq):\n    clean = convert_2526(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2527", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_2527():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2528", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2528:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2528:\n    tasks: List[Task_2528] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2528(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2529", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2529(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2529(n - 1) + fib_2529(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2530", "text": "def compute_sum_2530(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_2531", "text": "def validate_payload_2531(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2532", "text": "def validate_2532(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_2532(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_2532(seq):\n    clean = convert_2532(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2533", "text": "import numpy as np\n\ndef normalize_features_2533(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2534", "text": "import json\n\ndef load_and_filter_2534(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_2535", "text": "def validate_payload_2535(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2536", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2536:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2536:\n    tasks: List[Task_2536] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2536(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2537", "text": "import json\n\ndef load_and_filter_2537(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_2538", "text": "from typing import Dict, Any\n\ndef validate_payload_2538(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2539", "text": "def count_characters_2539(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2540", "text": "def compute_avg_2540(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2541", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_2541(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_2542", "text": "def pipeline_process_2542(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2543", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2543:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2543:\n    tasks: List[Task_2543] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2543(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2544", "text": "import statistics\n\ndef stats_2544(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2545", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_2545():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2546", "text": "def compute_avg_2546(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2547", "text": "def validate_payload_2547(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2548", "text": "def structured_sum_2548(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2549", "text": "from typing import Dict, Any\n\ndef validate_payload_2549(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2550", "text": "from typing import Dict, Any\n\ndef validate_payload_2550(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2551", "text": "import statistics\n\ndef stats_2551(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2552", "text": "class TextProcessor_2552:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_2553", "text": "def compute_avg_2553(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2554", "text": "def count_characters_2554(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2555", "text": "def structured_sum_2555(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2556", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2556(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2556(n - 1) + fib_2556(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2557", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_2557(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_2558", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2558:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2558:\n    tasks: List[Task_2558] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2558(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2559", "text": "def compute_sum_2559(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_2560", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_2560(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_2561", "text": "def generate_report_2561(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2562", "text": "def validate_payload_2562(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2563", "text": "import numpy as np\n\ndef normalize_features_2563(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2564", "text": "def structured_sum_2564(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2565", "text": "def validate_payload_2565(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2566", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_2566(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_2567", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_2567(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_2568", "text": "from typing import Dict, Any\n\ndef validate_payload_2568(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2569", "text": "import re\n\ndef clean_texts_2569(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2570", "text": "def safe_divide_2570(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2571", "text": "from collections import Counter\n\ndef word_freq_2571(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_2572", "text": "def compute_average_2572(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2573", "text": "import re\n\ndef clean_texts_2573(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2574", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2574(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2574(n - 1) + fib_2574(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2575", "text": "def safe_reduce_2575(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_2576", "text": "def count_characters_2576(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2577", "text": "def compute_stats_2577(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2578", "text": "def compute_sum_2578(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_2579", "text": "import numpy as np\n\ndef normalize_features_2579(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2580", "text": "def validate_2580(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_2580(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_2580(seq):\n    clean = convert_2580(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2581", "text": "def analyze_series_2581(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2582", "text": "def nested_analysis_2582(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2583", "text": "def is_prime_2583(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2584", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2584:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2584:\n    tasks: List[Task_2584] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2584(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2585", "text": "class DataNormalizer_2585:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_2586", "text": "def safe_division_2586(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2587", "text": "import statistics\n\ndef stats_2587(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2588", "text": "def compute_sum_2588(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_2589", "text": "from collections import Counter\n\ndef word_freq_2589(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_2590", "text": "def safe_divide_2590(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2591", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_2591():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2592", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2592(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2593", "text": "import json\n\ndef load_and_filter_2593(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_2594", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2594(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2594(n-1) + fib_2594(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2595", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2595(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2596", "text": "def is_prime_2596(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2597", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2597(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2597(n-1) + fib_2597(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2598", "text": "def flatten_list_2598(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2599", "text": "def safe_division_2599(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2600", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2600(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2600(n-1) + fib_2600(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2601", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2601(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2602", "text": "def compute_stats_2602(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2603", "text": "class TextProcessor_2603:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_2604", "text": "def safe_division_2604(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2605", "text": "def extract_numeric_2605(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_2606", "text": "def pipeline_process_2606(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2607", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2607(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2608", "text": "def safe_divide_2608(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2609", "text": "def flatten_list_2609(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2610", "text": "import re\n\ndef clean_texts_2610(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2611", "text": "def analyze_series_2611(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2612", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2612(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2613", "text": "class Config_2613:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2614", "text": "class Config_2614:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2615", "text": "import json\n\ndef load_and_filter_2615(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_2616", "text": "def structured_sum_2616(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2617", "text": "from typing import Dict, Any\n\ndef validate_payload_2617(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2618", "text": "def safe_reduce_2618(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_2619", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2619:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2619:\n    tasks: List[Task_2619] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2619(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2620", "text": "import statistics\n\ndef stats_2620(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2621", "text": "class Config_2621:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2622", "text": "import statistics\n\ndef stats_2622(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2623", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_2623(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_2624", "text": "def count_characters_2624(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2625", "text": "def flatten_list_2625(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2626", "text": "def count_tokens_2626(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2627", "text": "import statistics\n\ndef stats_2627(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2628", "text": "def compute_average_2628(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2629", "text": "def compute_stats_2629(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2630", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2630(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2630(n - 1) + fib_2630(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2631", "text": "def validate_payload_2631(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2632", "text": "def validate_payload_2632(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2633", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2633(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2634", "text": "def pipeline_process_2634(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2635", "text": "class TextProcessor_2635:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_2636", "text": "import numpy as np\n\ndef minmax_norm_2636(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2637", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2637(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2638", "text": "def compute_average_2638(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2639", "text": "import numpy as np\n\ndef normalize_features_2639(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2640", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2640(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2641", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2641:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2641:\n    tasks: List[Task_2641] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2641(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2642", "text": "def compute_average_2642(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2643", "text": "class ExecutionNode_2643:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2643():\n    import math\n\n    root = ExecutionNode_2643(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2643(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2643(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2644", "text": "def compute_stats_2644(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2645", "text": "class Config_2645:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2646", "text": "def compute_avg_2646(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2647", "text": "def safe_divide_2647(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2648", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_2648(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_2649", "text": "def compute_stats_2649(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2650", "text": "import numpy as np\n\ndef normalize_features_2650(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2651", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2651(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2652", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2652(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2653", "text": "class Config_2653:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2654", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2654(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2654(n - 1) + fib_2654(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2655", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2655(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2656", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2656(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2657", "text": "def safe_divide_2657(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2658", "text": "class DataNormalizer_2658:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_2659", "text": "class TextProcessor_2659:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_2660", "text": "def validate_payload_2660(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2661", "text": "import json\n\ndef load_and_filter_2661(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_2662", "text": "def validate_payload_2662(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2663", "text": "def structured_sum_2663(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2664", "text": "def compute_avg_2664(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2665", "text": "def pipeline_process_2665(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2666", "text": "def is_prime_2666(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2667", "text": "def count_characters_2667(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2668", "text": "def count_characters_2668(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2669", "text": "import numpy as np\n\ndef normalize_features_2669(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2670", "text": "def safe_division_2670(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2671", "text": "def compute_sum_2671(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_2672", "text": "import numpy as np\n\ndef normalize_features_2672(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2673", "text": "def compute_sum_2673(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_2674", "text": "def validate_payload_2674(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2675", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2675(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2675(n-1) + fib_2675(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2676", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2676(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2677", "text": "import statistics\n\ndef stats_2677(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2678", "text": "import numpy as np\n\ndef normalize_features_2678(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2679", "text": "def structured_sum_2679(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2680", "text": "class TextProcessor_2680:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_2681", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2681(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2682", "text": "def count_characters_2682(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2683", "text": "def compute_avg_2683(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2684", "text": "import statistics\n\ndef stats_2684(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2685", "text": "from collections import Counter\n\ndef word_freq_2685(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_2686", "text": "import json\n\ndef load_and_filter_2686(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_2687", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2687:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2687:\n    tasks: List[Task_2687] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2687(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2688", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2688(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2689", "text": "def count_tokens_2689(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2690", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2690(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2691", "text": "def safe_division_2691(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2692", "text": "def is_prime_2692(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2693", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2693(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2693(n - 1) + fib_2693(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2694", "text": "def flatten_list_2694(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2695", "text": "import numpy as np\n\ndef validate_and_predict_2695(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2696", "text": "from typing import Dict, Any\n\ndef validate_payload_2696(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2697", "text": "def safe_divide_2697(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2698", "text": "def nested_analysis_2698(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2699", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2699:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2699:\n    tasks: List[Task_2699] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2699(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2700", "text": "def compute_average_2700(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2701", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2701(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2702", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2702(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2703", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2703(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2703(n - 1) + fib_2703(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2704", "text": "import statistics\n\ndef stats_2704(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2705", "text": "class TextProcessor_2705:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_2706", "text": "def nested_analysis_2706(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2707", "text": "def validate_payload_2707(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2708", "text": "import numpy as np\n\ndef validate_and_predict_2708(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2709", "text": "import re\n\ndef clean_texts_2709(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2710", "text": "def compute_avg_2710(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2711", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2711:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2711:\n    tasks: List[Task_2711] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2711(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2712", "text": "def compute_average_2712(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2713", "text": "class Config_2713:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2714", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_2714(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_2715", "text": "def compute_avg_2715(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2716", "text": "import statistics\n\ndef stats_2716(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2717", "text": "import json\n\ndef load_and_filter_2717(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_2718", "text": "def compute_sum_2718(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_2719", "text": "def flatten_list_2719(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2720", "text": "def validate_2720(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_2720(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_2720(seq):\n    clean = convert_2720(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2721", "text": "def safe_division_2721(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2722", "text": "from typing import Dict, Any\n\ndef validate_payload_2722(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2723", "text": "def compute_sum_2723(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_2724", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_2724(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_2725", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_2725():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2726", "text": "class Config_2726:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2727", "text": "def nested_analysis_2727(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2728", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2728(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2729", "text": "class Processor_2729:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_2730", "text": "class DataNormalizer_2730:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_2731", "text": "def is_prime_2731(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2732", "text": "def compute_avg_2732(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2733", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_2733():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2734", "text": "def count_characters_2734(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2735", "text": "def count_characters_2735(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2736", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2736(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2736(n-1) + fib_2736(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2737", "text": "import numpy as np\n\ndef validate_and_predict_2737(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2738", "text": "def count_characters_2738(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2739", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2739(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2740", "text": "def structured_sum_2740(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2741", "text": "import re\n\ndef clean_texts_2741(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2742", "text": "def compute_average_2742(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2743", "text": "def analyze_series_2743(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2744", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_2744(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_2745", "text": "from typing import Dict, Any\n\ndef validate_payload_2745(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2746", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2746(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2746(n-1) + fib_2746(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2747", "text": "import numpy as np\n\ndef validate_and_predict_2747(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2748", "text": "def compute_sum_2748(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_2749", "text": "from typing import Dict, Any\n\ndef validate_payload_2749(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2750", "text": "def validate_2750(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_2750(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_2750(seq):\n    clean = convert_2750(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2751", "text": "class Processor_2751:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_2752", "text": "class ExecutionNode_2752:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2752():\n    import math\n\n    root = ExecutionNode_2752(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2752(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2752(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2753", "text": "def compute_avg_2753(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2754", "text": "def safe_reduce_2754(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_2755", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2755(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2756", "text": "def validate_2756(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_2756(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_2756(seq):\n    clean = convert_2756(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2757", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2757(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2758", "text": "def validate_payload_2758(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2759", "text": "def analyze_series_2759(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2760", "text": "class ExecutionNode_2760:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2760():\n    import math\n\n    root = ExecutionNode_2760(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2760(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2760(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2761", "text": "def compute_average_2761(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2762", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2762(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2763", "text": "def nested_analysis_2763(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2764", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2764(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2765", "text": "class Processor_2765:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_2766", "text": "def validate_payload_2766(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2767", "text": "class ExecutionNode_2767:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2767():\n    import math\n\n    root = ExecutionNode_2767(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2767(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2767(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2768", "text": "class Processor_2768:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_2769", "text": "def compute_stats_2769(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2770", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2770(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2771", "text": "def analyze_series_2771(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2772", "text": "def safe_divide_2772(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2773", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2773(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2774", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2774(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2775", "text": "from typing import Dict, Any\n\ndef validate_payload_2775(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2776", "text": "class DataNormalizer_2776:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_2777", "text": "class Config_2777:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2778", "text": "import numpy as np\n\ndef minmax_norm_2778(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2779", "text": "def compute_stats_2779(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2780", "text": "def compute_average_2780(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2781", "text": "def extract_numeric_2781(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_2782", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2782(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2783", "text": "def validate_payload_2783(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2784", "text": "def pipeline_process_2784(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2785", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_2785(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_2786", "text": "class DataNormalizer_2786:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_2787", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_2787():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2788", "text": "def extract_numeric_2788(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_2789", "text": "import statistics\n\ndef stats_2789(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2790", "text": "def nested_analysis_2790(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2791", "text": "def safe_reduce_2791(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_2792", "text": "def safe_division_2792(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2793", "text": "def pipeline_process_2793(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2794", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_2794(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_2795", "text": "class ExecutionNode_2795:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2795():\n    import math\n\n    root = ExecutionNode_2795(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2795(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2795(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2796", "text": "def compute_avg_2796(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2797", "text": "def safe_divide_2797(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2798", "text": "def count_tokens_2798(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2799", "text": "def compute_average_2799(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2800", "text": "class Config_2800:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2801", "text": "def extract_numeric_2801(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_2802", "text": "import json\n\ndef load_and_filter_2802(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_2803", "text": "class TextProcessor_2803:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_2804", "text": "def flatten_list_2804(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2805", "text": "from collections import Counter\n\ndef word_freq_2805(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_2806", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_2806(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_2807", "text": "def analyze_series_2807(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2808", "text": "def safe_division_2808(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2809", "text": "def compute_avg_2809(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2810", "text": "def compute_sum_2810(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_2811", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2811:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2811:\n    tasks: List[Task_2811] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2811(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2812", "text": "def generate_report_2812(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2813", "text": "class Config_2813:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2814", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2814(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2815", "text": "def safe_division_2815(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2816", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2816:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2816:\n    tasks: List[Task_2816] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2816(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2817", "text": "def count_tokens_2817(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2818", "text": "def is_prime_2818(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2819", "text": "class ExecutionNode_2819:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2819():\n    import math\n\n    root = ExecutionNode_2819(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2819(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2819(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2820", "text": "import re\n\ndef clean_texts_2820(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2821", "text": "import numpy as np\n\ndef minmax_norm_2821(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2822", "text": "def count_tokens_2822(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2823", "text": "import numpy as np\n\ndef normalize_features_2823(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2824", "text": "def validate_2824(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_2824(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_2824(seq):\n    clean = convert_2824(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2825", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2825(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2825(n - 1) + fib_2825(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2826", "text": "def count_characters_2826(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2827", "text": "def is_prime_2827(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2828", "text": "def compute_average_2828(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2829", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2829(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2829(n - 1) + fib_2829(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2830", "text": "def compute_average_2830(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2831", "text": "class DataNormalizer_2831:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_2832", "text": "def extract_numeric_2832(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_2833", "text": "class ExecutionNode_2833:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2833():\n    import math\n\n    root = ExecutionNode_2833(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2833(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2833(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2834", "text": "def flatten_list_2834(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2835", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_2835(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_2836", "text": "def compute_stats_2836(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2837", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2837(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2837(n-1) + fib_2837(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2838", "text": "def count_characters_2838(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2839", "text": "def generate_report_2839(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2840", "text": "def count_characters_2840(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2841", "text": "def analyze_series_2841(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2842", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2842(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2843", "text": "def pipeline_process_2843(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2844", "text": "class Config_2844:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2845", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2845(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2846", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2846(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2847", "text": "def validate_payload_2847(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2848", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_2848():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2849", "text": "import numpy as np\n\ndef validate_and_predict_2849(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2850", "text": "def compute_stats_2850(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2851", "text": "def analyze_series_2851(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2852", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2852(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2853", "text": "def safe_reduce_2853(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_2854", "text": "def compute_avg_2854(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2855", "text": "class DataNormalizer_2855:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_2856", "text": "def generate_report_2856(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2857", "text": "def safe_division_2857(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2858", "text": "def validate_2858(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_2858(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_2858(seq):\n    clean = convert_2858(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2859", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2859(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2860", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2860(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2861", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2861(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2862", "text": "def generate_report_2862(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2863", "text": "def safe_divide_2863(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2864", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2864:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2864:\n    tasks: List[Task_2864] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2864(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2865", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2865(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2866", "text": "def structured_sum_2866(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2867", "text": "def nested_analysis_2867(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2868", "text": "def structured_sum_2868(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2869", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_2869():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2870", "text": "def flatten_list_2870(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2871", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2871(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2871(n - 1) + fib_2871(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2872", "text": "class TextProcessor_2872:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_2873", "text": "def extract_numeric_2873(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_2874", "text": "def meta_process_2874(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_2875", "text": "def safe_division_2875(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2876", "text": "import statistics\n\ndef stats_2876(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2877", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2877:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2877:\n    tasks: List[Task_2877] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2877(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2878", "text": "def compute_avg_2878(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2879", "text": "import json\n\ndef load_and_filter_2879(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_2880", "text": "def validate_payload_2880(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2881", "text": "def validate_2881(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_2881(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_2881(seq):\n    clean = convert_2881(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2882", "text": "def analyze_series_2882(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2883", "text": "def compute_avg_2883(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_2884", "text": "def nested_analysis_2884(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2885", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2885(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2885(n - 1) + fib_2885(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2886", "text": "import numpy as np\n\ndef validate_and_predict_2886(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2887", "text": "def safe_reduce_2887(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_2888", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2888(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2889", "text": "def compute_sum_2889(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_2890", "text": "class Config_2890:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2891", "text": "def safe_reduce_2891(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_2892", "text": "def extract_numeric_2892(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_2893", "text": "def count_tokens_2893(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2894", "text": "def generate_report_2894(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2895", "text": "def pipeline_process_2895(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2896", "text": "import json\n\ndef load_and_filter_2896(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_2897", "text": "class Processor_2897:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_2898", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2898(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2899", "text": "def safe_division_2899(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2900", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_2900():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2901", "text": "def validate_payload_2901(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2902", "text": "def extract_numeric_2902(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_2903", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2903(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2904", "text": "class ExecutionNode_2904:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2904():\n    import math\n\n    root = ExecutionNode_2904(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2904(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2904(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2905", "text": "def safe_reduce_2905(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_2906", "text": "def structured_sum_2906(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2907", "text": "def safe_divide_2907(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2908", "text": "def safe_division_2908(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2909", "text": "import statistics\n\ndef stats_2909(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2910", "text": "def safe_divide_2910(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_2911", "text": "import numpy as np\n\ndef minmax_norm_2911(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2912", "text": "class DataNormalizer_2912:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_2913", "text": "def generate_report_2913(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2914", "text": "class DataNormalizer_2914:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_2915", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2915(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2915(n - 1) + fib_2915(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2916", "text": "def extract_numeric_2916(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_2917", "text": "def is_prime_2917(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2918", "text": "def compute_average_2918(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2919", "text": "def safe_reduce_2919(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_2920", "text": "def pipeline_process_2920(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2921", "text": "def validate_payload_2921(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2922", "text": "def validate_2922(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_2922(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_2922(seq):\n    clean = convert_2922(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2923", "text": "def compute_stats_2923(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2924", "text": "def validate_payload_2924(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2925", "text": "def compute_average_2925(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2926", "text": "def count_characters_2926(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2927", "text": "def validate_payload_2927(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2928", "text": "import numpy as np\n\ndef minmax_norm_2928(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2929", "text": "def safe_division_2929(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2930", "text": "from collections import Counter\n\ndef word_freq_2930(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_2931", "text": "def generate_report_2931(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2932", "text": "class Config_2932:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2933", "text": "def is_prime_2933(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2934", "text": "def structured_sum_2934(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2935", "text": "class ExecutionNode_2935:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2935():\n    import math\n\n    root = ExecutionNode_2935(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2935(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2935(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2936", "text": "def compute_sum_2936(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_2937", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2937(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2937(n - 1) + fib_2937(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2938", "text": "def compute_sum_2938(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_2939", "text": "from collections import Counter\n\ndef word_freq_2939(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_2940", "text": "import re\n\ndef clean_texts_2940(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2941", "text": "def flatten_list_2941(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2942", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_2942(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_2942(n - 1) + fib_2942(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_2943", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2943(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2944", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_2944:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_2944:\n    tasks: List[Task_2944] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_2944(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_2945", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2945(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2946", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_2946():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2947", "text": "def analyze_series_2947(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2948", "text": "def compute_sum_2948(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_2949", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2949(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2949(n-1) + fib_2949(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2950", "text": "def count_characters_2950(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2951", "text": "import numpy as np\n\ndef normalize_features_2951(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2952", "text": "def count_tokens_2952(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2953", "text": "def validate_payload_2953(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2954", "text": "class ExecutionNode_2954:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2954():\n    import math\n\n    root = ExecutionNode_2954(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2954(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2954(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2955", "text": "def validate_payload_2955(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2956", "text": "class Config_2956:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_2957", "text": "def nested_analysis_2957(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2958", "text": "def extract_numeric_2958(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_2959", "text": "def count_tokens_2959(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_2960", "text": "def pipeline_process_2960(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2961", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_2961(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_2962", "text": "def validate_payload_2962(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2963", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_2963(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2964", "text": "def analyze_series_2964(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2965", "text": "import numpy as np\n\ndef minmax_norm_2965(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_2966", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2966(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2967", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_2967(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_2968", "text": "from typing import Dict, Any\n\ndef validate_payload_2968(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_2969", "text": "def meta_process_2969(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_2970", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2970(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2970(n-1) + fib_2970(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2971", "text": "import numpy as np\n\ndef validate_and_predict_2971(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_2972", "text": "def compute_average_2972(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2973", "text": "def structured_sum_2973(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2974", "text": "class ExecutionNode_2974:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2974():\n    import math\n\n    root = ExecutionNode_2974(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2974(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2974(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2975", "text": "def structured_sum_2975(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_2976", "text": "import re\n\ndef clean_texts_2976(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2977", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_2977():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2978", "text": "def compute_average_2978(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2979", "text": "class TextProcessor_2979:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_2980", "text": "class ExecutionNode_2980:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_2980():\n    import math\n\n    root = ExecutionNode_2980(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_2980(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_2980(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_2981", "text": "def compute_average_2981(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_2982", "text": "from collections import Counter\n\ndef word_freq_2982(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_2983", "text": "def safe_division_2983(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_2984", "text": "def safe_reduce_2984(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_2985", "text": "from collections import Counter\n\ndef word_freq_2985(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_2986", "text": "def validate_payload_2986(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2987", "text": "def meta_process_2987(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_2988", "text": "def generate_report_2988(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2989", "text": "def safe_reduce_2989(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_2990", "text": "def meta_process_2990(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_2991", "text": "def safe_reduce_2991(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_2992", "text": "def validate_payload_2992(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_2993", "text": "class Processor_2993:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_2994", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_2994(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_2994(n-1) + fib_2994(n-2)", "label": "1", "lang": "python"}
{"id": "AI_2995", "text": "def generate_report_2995(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_2996", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_2996():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_2997", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_2997(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_2998", "text": "def count_characters_2998(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_2999", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_2999():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3000", "text": "import re\n\ndef clean_texts_3000(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3001", "text": "import numpy as np\n\ndef validate_and_predict_3001(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3002", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3002:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3002:\n    tasks: List[Task_3002] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3002(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3003", "text": "def safe_divide_3003(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3004", "text": "def is_prime_3004(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3005", "text": "import re\n\ndef clean_texts_3005(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3006", "text": "def count_tokens_3006(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_3007", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3007(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3007(n-1) + fib_3007(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3008", "text": "def is_prime_3008(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3009", "text": "import re\n\ndef clean_texts_3009(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3010", "text": "class TextProcessor_3010:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3011", "text": "def extract_numeric_3011(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3012", "text": "def pipeline_process_3012(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3013", "text": "def pipeline_process_3013(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3014", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3014(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3014(n-1) + fib_3014(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3015", "text": "def pipeline_process_3015(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3016", "text": "def flatten_list_3016(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3017", "text": "def compute_sum_3017(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3018", "text": "def compute_average_3018(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3019", "text": "import numpy as np\n\ndef validate_and_predict_3019(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3020", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_3020(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_3021", "text": "def generate_report_3021(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3022", "text": "from typing import Dict, Any\n\ndef validate_payload_3022(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3023", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3023(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3024", "text": "class DataNormalizer_3024:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3025", "text": "def safe_division_3025(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3026", "text": "def safe_reduce_3026(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_3027", "text": "def pipeline_process_3027(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3028", "text": "import numpy as np\n\ndef validate_and_predict_3028(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3029", "text": "import numpy as np\n\ndef minmax_norm_3029(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3030", "text": "class Config_3030:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3031", "text": "def analyze_series_3031(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3032", "text": "def structured_sum_3032(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3033", "text": "def structured_sum_3033(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3034", "text": "def analyze_series_3034(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3035", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3035(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3035(n-1) + fib_3035(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3036", "text": "def validate_payload_3036(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3037", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3037:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3037:\n    tasks: List[Task_3037] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3037(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3038", "text": "from collections import Counter\n\ndef word_freq_3038(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_3039", "text": "def pipeline_process_3039(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3040", "text": "import numpy as np\n\ndef normalize_features_3040(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3041", "text": "def structured_sum_3041(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3042", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_3042(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3043", "text": "def count_tokens_3043(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_3044", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3044(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3045", "text": "def meta_process_3045(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3046", "text": "def validate_3046(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_3046(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_3046(seq):\n    clean = convert_3046(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3047", "text": "import re\n\ndef clean_texts_3047(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3048", "text": "from collections import Counter\n\ndef word_freq_3048(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_3049", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3049:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3049:\n    tasks: List[Task_3049] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3049(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3050", "text": "def meta_process_3050(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3051", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3051(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3052", "text": "import json\n\ndef load_and_filter_3052(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_3053", "text": "def compute_avg_3053(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3054", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3054(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3055", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3055(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3056", "text": "from collections import Counter\n\ndef word_freq_3056(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_3057", "text": "from collections import Counter\n\ndef word_freq_3057(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_3058", "text": "def compute_avg_3058(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3059", "text": "class ExecutionNode_3059:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_3059():\n    import math\n\n    root = ExecutionNode_3059(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_3059(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_3059(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_3060", "text": "def meta_process_3060(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3061", "text": "class ExecutionNode_3061:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_3061():\n    import math\n\n    root = ExecutionNode_3061(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_3061(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_3061(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_3062", "text": "def structured_sum_3062(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3063", "text": "def compute_sum_3063(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3064", "text": "from collections import Counter\n\ndef word_freq_3064(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_3065", "text": "import numpy as np\n\ndef normalize_features_3065(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3066", "text": "def count_characters_3066(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_3067", "text": "class DataNormalizer_3067:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3068", "text": "class Processor_3068:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_3069", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3069(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3070", "text": "from collections import Counter\n\ndef word_freq_3070(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_3071", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3071(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3072", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3072(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3073", "text": "def generate_report_3073(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3074", "text": "def is_prime_3074(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3075", "text": "class TextProcessor_3075:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3076", "text": "def analyze_series_3076(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3077", "text": "class TextProcessor_3077:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3078", "text": "class ExecutionNode_3078:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_3078():\n    import math\n\n    root = ExecutionNode_3078(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_3078(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_3078(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_3079", "text": "def validate_3079(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_3079(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_3079(seq):\n    clean = convert_3079(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3080", "text": "def compute_stats_3080(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3081", "text": "class Processor_3081:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_3082", "text": "import numpy as np\n\ndef minmax_norm_3082(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3083", "text": "class Processor_3083:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_3084", "text": "def pipeline_process_3084(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3085", "text": "def meta_process_3085(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3086", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3086(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3087", "text": "class Config_3087:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3088", "text": "def safe_division_3088(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3089", "text": "def safe_divide_3089(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3090", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3090(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3090(n - 1) + fib_3090(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3091", "text": "import numpy as np\n\ndef minmax_norm_3091(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3092", "text": "def validate_payload_3092(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_3093", "text": "import re\n\ndef clean_texts_3093(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3094", "text": "def safe_divide_3094(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3095", "text": "class TextProcessor_3095:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3096", "text": "def meta_process_3096(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3097", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3097(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3098", "text": "import numpy as np\n\ndef normalize_features_3098(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3099", "text": "class DataNormalizer_3099:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3100", "text": "import numpy as np\n\ndef normalize_features_3100(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3101", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3101:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3101:\n    tasks: List[Task_3101] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3101(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3102", "text": "def nested_analysis_3102(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3103", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_3103():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3104", "text": "def meta_process_3104(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3105", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_3105(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_3106", "text": "from typing import Dict, Any\n\ndef validate_payload_3106(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3107", "text": "class ExecutionNode_3107:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_3107():\n    import math\n\n    root = ExecutionNode_3107(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_3107(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_3107(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_3108", "text": "def generate_report_3108(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3109", "text": "def analyze_series_3109(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3110", "text": "class TextProcessor_3110:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3111", "text": "def safe_divide_3111(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3112", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3112(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3112(n - 1) + fib_3112(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3113", "text": "def validate_3113(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_3113(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_3113(seq):\n    clean = convert_3113(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3114", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3114(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3115", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3115(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3116", "text": "def validate_payload_3116(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_3117", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3117(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3118", "text": "def safe_divide_3118(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3119", "text": "def flatten_list_3119(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3120", "text": "def safe_division_3120(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3121", "text": "class Processor_3121:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_3122", "text": "def is_prime_3122(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3123", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3123(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3124", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_3124(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3125", "text": "def compute_sum_3125(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3126", "text": "from typing import Dict, Any\n\ndef validate_payload_3126(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3127", "text": "def safe_division_3127(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3128", "text": "def compute_average_3128(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3129", "text": "def validate_payload_3129(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3130", "text": "def analyze_series_3130(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3131", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_3131(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_3132", "text": "def count_characters_3132(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_3133", "text": "from collections import Counter\n\ndef word_freq_3133(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_3134", "text": "class ExecutionNode_3134:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_3134():\n    import math\n\n    root = ExecutionNode_3134(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_3134(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_3134(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_3135", "text": "def safe_division_3135(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3136", "text": "def validate_payload_3136(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3137", "text": "import numpy as np\n\ndef validate_and_predict_3137(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3138", "text": "def compute_stats_3138(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3139", "text": "def count_tokens_3139(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_3140", "text": "import statistics\n\ndef stats_3140(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3141", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3141(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3142", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3142(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3143", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3143(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3144", "text": "def compute_average_3144(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3145", "text": "def nested_analysis_3145(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3146", "text": "class Config_3146:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3147", "text": "def flatten_list_3147(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3148", "text": "def is_prime_3148(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3149", "text": "def meta_process_3149(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3150", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3150(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3150(n - 1) + fib_3150(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3151", "text": "import re\n\ndef clean_texts_3151(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3152", "text": "def compute_avg_3152(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3153", "text": "def pipeline_process_3153(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3154", "text": "class Config_3154:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3155", "text": "def safe_division_3155(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3156", "text": "def compute_avg_3156(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3157", "text": "class Config_3157:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3158", "text": "def compute_avg_3158(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3159", "text": "def safe_reduce_3159(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_3160", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3160(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3160(n - 1) + fib_3160(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3161", "text": "def nested_analysis_3161(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3162", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_3162(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3163", "text": "import re\n\ndef clean_texts_3163(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3164", "text": "def generate_report_3164(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3165", "text": "def compute_sum_3165(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3166", "text": "def flatten_list_3166(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3167", "text": "def safe_reduce_3167(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_3168", "text": "class Processor_3168:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_3169", "text": "def validate_payload_3169(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3170", "text": "def safe_division_3170(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3171", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3171(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3171(n-1) + fib_3171(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3172", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3172:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3172:\n    tasks: List[Task_3172] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3172(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3173", "text": "def generate_report_3173(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3174", "text": "def pipeline_process_3174(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3175", "text": "def safe_division_3175(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3176", "text": "import numpy as np\n\ndef minmax_norm_3176(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3177", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3177(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3178", "text": "import statistics\n\ndef stats_3178(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3179", "text": "def compute_sum_3179(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3180", "text": "class Processor_3180:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_3181", "text": "import numpy as np\n\ndef minmax_norm_3181(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3182", "text": "class DataNormalizer_3182:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3183", "text": "import statistics\n\ndef stats_3183(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3184", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3184(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3185", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_3185(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_3186", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3186:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3186:\n    tasks: List[Task_3186] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3186(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3187", "text": "def safe_divide_3187(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3188", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3188(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3188(n - 1) + fib_3188(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3189", "text": "def safe_divide_3189(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3190", "text": "def compute_avg_3190(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3191", "text": "def flatten_list_3191(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3192", "text": "class TextProcessor_3192:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3193", "text": "def structured_sum_3193(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3194", "text": "def validate_payload_3194(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3195", "text": "def structured_sum_3195(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3196", "text": "def extract_numeric_3196(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3197", "text": "def validate_payload_3197(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3198", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3198(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3199", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3199:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3199:\n    tasks: List[Task_3199] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3199(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3200", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_3200(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3201", "text": "import numpy as np\n\ndef normalize_features_3201(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3202", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3202(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3202(n - 1) + fib_3202(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3203", "text": "class Processor_3203:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_3204", "text": "class Processor_3204:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_3205", "text": "def compute_average_3205(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3206", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_3206():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3207", "text": "def safe_division_3207(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3208", "text": "def extract_numeric_3208(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3209", "text": "from typing import Dict, Any\n\ndef validate_payload_3209(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3210", "text": "def validate_payload_3210(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3211", "text": "class ExecutionNode_3211:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_3211():\n    import math\n\n    root = ExecutionNode_3211(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_3211(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_3211(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_3212", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3212(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3212(n-1) + fib_3212(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3213", "text": "def analyze_series_3213(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3214", "text": "def count_characters_3214(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_3215", "text": "def compute_average_3215(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3216", "text": "def meta_process_3216(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3217", "text": "def compute_average_3217(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3218", "text": "def compute_sum_3218(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3219", "text": "class TextProcessor_3219:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3220", "text": "class Config_3220:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3221", "text": "class Config_3221:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3222", "text": "import numpy as np\n\ndef minmax_norm_3222(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3223", "text": "def validate_payload_3223(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_3224", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3224(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3225", "text": "def flatten_list_3225(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3226", "text": "class DataNormalizer_3226:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3227", "text": "def structured_sum_3227(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3228", "text": "def generate_report_3228(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3229", "text": "def nested_analysis_3229(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3230", "text": "def validate_payload_3230(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_3231", "text": "import numpy as np\n\ndef minmax_norm_3231(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3232", "text": "import numpy as np\n\ndef validate_and_predict_3232(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3233", "text": "def safe_divide_3233(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3234", "text": "class Config_3234:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3235", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3235(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3236", "text": "import json\n\ndef load_and_filter_3236(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_3237", "text": "def is_prime_3237(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3238", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3238(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3238(n - 1) + fib_3238(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3239", "text": "import json\n\ndef load_and_filter_3239(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_3240", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3240(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3241", "text": "def count_characters_3241(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_3242", "text": "def flatten_list_3242(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3243", "text": "def validate_payload_3243(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_3244", "text": "def safe_division_3244(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3245", "text": "def pipeline_process_3245(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3246", "text": "import numpy as np\n\ndef validate_and_predict_3246(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3247", "text": "import re\n\ndef clean_texts_3247(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3248", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3248(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3249", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3249(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3249(n-1) + fib_3249(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3250", "text": "def safe_reduce_3250(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_3251", "text": "def pipeline_process_3251(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3252", "text": "def analyze_series_3252(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3253", "text": "def is_prime_3253(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3254", "text": "def safe_division_3254(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3255", "text": "import statistics\n\ndef stats_3255(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3256", "text": "class ExecutionNode_3256:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_3256():\n    import math\n\n    root = ExecutionNode_3256(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_3256(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_3256(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_3257", "text": "def compute_sum_3257(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3258", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3258(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3258(n - 1) + fib_3258(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3259", "text": "class Config_3259:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3260", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_3260(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_3261", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3261(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3261(n-1) + fib_3261(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3262", "text": "class Config_3262:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3263", "text": "def validate_payload_3263(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3264", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_3264():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3265", "text": "def generate_report_3265(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3266", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_3266(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3267", "text": "import re\n\ndef clean_texts_3267(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3268", "text": "def count_tokens_3268(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_3269", "text": "def count_tokens_3269(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_3270", "text": "def count_tokens_3270(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_3271", "text": "def count_characters_3271(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_3272", "text": "def compute_stats_3272(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3273", "text": "import numpy as np\n\ndef normalize_features_3273(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3274", "text": "def compute_sum_3274(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3275", "text": "def structured_sum_3275(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3276", "text": "def extract_numeric_3276(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3277", "text": "def is_prime_3277(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3278", "text": "def validate_3278(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_3278(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_3278(seq):\n    clean = convert_3278(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3279", "text": "def validate_payload_3279(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_3280", "text": "class TextProcessor_3280:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3281", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3281(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3281(n-1) + fib_3281(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3282", "text": "def compute_avg_3282(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3283", "text": "def compute_sum_3283(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3284", "text": "def safe_divide_3284(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3285", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3285:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3285:\n    tasks: List[Task_3285] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3285(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3286", "text": "def compute_sum_3286(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3287", "text": "class TextProcessor_3287:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3288", "text": "def meta_process_3288(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3289", "text": "from collections import Counter\n\ndef word_freq_3289(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_3290", "text": "def generate_report_3290(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3291", "text": "import json\n\ndef load_and_filter_3291(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_3292", "text": "import numpy as np\n\ndef normalize_features_3292(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3293", "text": "def nested_analysis_3293(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3294", "text": "class TextProcessor_3294:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3295", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3295(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3296", "text": "from typing import Dict, Any\n\ndef validate_payload_3296(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3297", "text": "import numpy as np\n\ndef minmax_norm_3297(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3298", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3298(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3298(n - 1) + fib_3298(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3299", "text": "def validate_payload_3299(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_3300", "text": "def validate_payload_3300(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3301", "text": "def safe_division_3301(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3302", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3302(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3302(n - 1) + fib_3302(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3303", "text": "def compute_avg_3303(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3304", "text": "import re\n\ndef clean_texts_3304(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3305", "text": "def is_prime_3305(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3306", "text": "def flatten_list_3306(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3307", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3307(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3307(n-1) + fib_3307(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3308", "text": "def validate_payload_3308(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_3309", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3309:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3309:\n    tasks: List[Task_3309] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3309(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3310", "text": "class Processor_3310:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_3311", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3311(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3311(n - 1) + fib_3311(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3312", "text": "def nested_analysis_3312(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3313", "text": "def structured_sum_3313(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3314", "text": "def safe_divide_3314(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3315", "text": "def count_tokens_3315(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_3316", "text": "def structured_sum_3316(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3317", "text": "def validate_3317(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_3317(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_3317(seq):\n    clean = convert_3317(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3318", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_3318(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3319", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3319(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3319(n-1) + fib_3319(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3320", "text": "def safe_divide_3320(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3321", "text": "def analyze_series_3321(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3322", "text": "from collections import Counter\n\ndef word_freq_3322(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_3323", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_3323():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3324", "text": "from typing import Dict, Any\n\ndef validate_payload_3324(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3325", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3325(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3325(n-1) + fib_3325(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3326", "text": "from collections import Counter\n\ndef word_freq_3326(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_3327", "text": "import json\n\ndef load_and_filter_3327(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_3328", "text": "def count_characters_3328(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_3329", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3329:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3329:\n    tasks: List[Task_3329] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3329(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3330", "text": "import numpy as np\n\ndef normalize_features_3330(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3331", "text": "import re\n\ndef clean_texts_3331(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3332", "text": "import numpy as np\n\ndef minmax_norm_3332(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3333", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3333:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3333:\n    tasks: List[Task_3333] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3333(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3334", "text": "import numpy as np\n\ndef normalize_features_3334(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3335", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3335(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3336", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3336(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3337", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3337(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3338", "text": "def compute_average_3338(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3339", "text": "import numpy as np\n\ndef minmax_norm_3339(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3340", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3340(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3341", "text": "import numpy as np\n\ndef minmax_norm_3341(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3342", "text": "def safe_division_3342(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3343", "text": "def safe_divide_3343(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3344", "text": "class DataNormalizer_3344:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3345", "text": "class Config_3345:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3346", "text": "def pipeline_process_3346(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3347", "text": "def extract_numeric_3347(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3348", "text": "def extract_numeric_3348(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3349", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_3349(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_3350", "text": "def validate_payload_3350(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3351", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_3351():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3352", "text": "def safe_reduce_3352(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_3353", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_3353(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3354", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_3354():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3355", "text": "from collections import Counter\n\ndef word_freq_3355(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_3356", "text": "def flatten_list_3356(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3357", "text": "def validate_3357(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_3357(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_3357(seq):\n    clean = convert_3357(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3358", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3358:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3358:\n    tasks: List[Task_3358] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3358(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3359", "text": "import statistics\n\ndef stats_3359(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3360", "text": "import json\n\ndef load_and_filter_3360(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_3361", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_3361(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_3362", "text": "def safe_division_3362(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3363", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_3363():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3364", "text": "def structured_sum_3364(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3365", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3365(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3366", "text": "def compute_avg_3366(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3367", "text": "def compute_stats_3367(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3368", "text": "import json\n\ndef load_and_filter_3368(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_3369", "text": "def flatten_list_3369(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3370", "text": "import numpy as np\n\ndef normalize_features_3370(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3371", "text": "from typing import Dict, Any\n\ndef validate_payload_3371(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3372", "text": "class Processor_3372:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_3373", "text": "def pipeline_process_3373(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3374", "text": "def flatten_list_3374(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3375", "text": "class TextProcessor_3375:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3376", "text": "def validate_payload_3376(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3377", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3377(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3378", "text": "def extract_numeric_3378(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3379", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_3379(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_3380", "text": "def flatten_list_3380(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3381", "text": "class DataNormalizer_3381:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3382", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3382(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3383", "text": "def extract_numeric_3383(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3384", "text": "class DataNormalizer_3384:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3385", "text": "class DataNormalizer_3385:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3386", "text": "def count_tokens_3386(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_3387", "text": "def generate_report_3387(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3388", "text": "def generate_report_3388(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3389", "text": "def pipeline_process_3389(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3390", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3390(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3391", "text": "def extract_numeric_3391(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3392", "text": "from collections import Counter\n\ndef word_freq_3392(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_3393", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_3393(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3394", "text": "class ExecutionNode_3394:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_3394():\n    import math\n\n    root = ExecutionNode_3394(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_3394(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_3394(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_3395", "text": "def compute_avg_3395(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3396", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_3396():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3397", "text": "def compute_average_3397(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3398", "text": "def safe_divide_3398(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3399", "text": "def safe_reduce_3399(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_3400", "text": "def extract_numeric_3400(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3401", "text": "def safe_division_3401(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3402", "text": "def extract_numeric_3402(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3403", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3403(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3403(n-1) + fib_3403(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3404", "text": "from typing import Dict, Any\n\ndef validate_payload_3404(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3405", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_3405():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3406", "text": "import statistics\n\ndef stats_3406(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3407", "text": "class Config_3407:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3408", "text": "class DataNormalizer_3408:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3409", "text": "import re\n\ndef clean_texts_3409(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3410", "text": "def structured_sum_3410(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3411", "text": "from collections import Counter\n\ndef word_freq_3411(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_3412", "text": "import numpy as np\n\ndef validate_and_predict_3412(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3413", "text": "def extract_numeric_3413(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3414", "text": "class ExecutionNode_3414:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_3414():\n    import math\n\n    root = ExecutionNode_3414(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_3414(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_3414(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_3415", "text": "class DataNormalizer_3415:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3416", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_3416():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3417", "text": "import re\n\ndef clean_texts_3417(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3418", "text": "def safe_reduce_3418(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_3419", "text": "def count_tokens_3419(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_3420", "text": "def validate_payload_3420(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_3421", "text": "class TextProcessor_3421:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3422", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3422(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3423", "text": "import numpy as np\n\ndef validate_and_predict_3423(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3424", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3424(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3424(n-1) + fib_3424(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3425", "text": "import numpy as np\n\ndef normalize_features_3425(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3426", "text": "from collections import Counter\n\ndef word_freq_3426(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_3427", "text": "def flatten_list_3427(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3428", "text": "from typing import Dict, Any\n\ndef validate_payload_3428(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3429", "text": "import re\n\ndef clean_texts_3429(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3430", "text": "import numpy as np\n\ndef normalize_features_3430(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3431", "text": "class Config_3431:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3432", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_3432():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3433", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3433(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3433(n-1) + fib_3433(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3434", "text": "def compute_stats_3434(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3435", "text": "import json\n\ndef load_and_filter_3435(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_3436", "text": "def analyze_series_3436(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3437", "text": "def compute_sum_3437(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3438", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3438(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3439", "text": "import numpy as np\n\ndef validate_and_predict_3439(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3440", "text": "def structured_sum_3440(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3441", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3441:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3441:\n    tasks: List[Task_3441] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3441(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3442", "text": "def is_prime_3442(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3443", "text": "def compute_avg_3443(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3444", "text": "def compute_average_3444(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3445", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3445(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3446", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3446(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3446(n-1) + fib_3446(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3447", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3447(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3447(n - 1) + fib_3447(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3448", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3448(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3449", "text": "def structured_sum_3449(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3450", "text": "class Config_3450:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3451", "text": "import numpy as np\n\ndef normalize_features_3451(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3452", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3452(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3452(n - 1) + fib_3452(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3453", "text": "def pipeline_process_3453(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3454", "text": "import numpy as np\n\ndef validate_and_predict_3454(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3455", "text": "def is_prime_3455(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3456", "text": "def compute_average_3456(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3457", "text": "class Processor_3457:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_3458", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3458(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3459", "text": "def count_characters_3459(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_3460", "text": "def meta_process_3460(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3461", "text": "import numpy as np\n\ndef normalize_features_3461(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3462", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3462(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3462(n-1) + fib_3462(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3463", "text": "def count_characters_3463(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_3464", "text": "def flatten_list_3464(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3465", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3465(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3465(n - 1) + fib_3465(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3466", "text": "import numpy as np\n\ndef normalize_features_3466(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3467", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_3467(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_3468", "text": "import statistics\n\ndef stats_3468(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3469", "text": "def validate_payload_3469(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3470", "text": "def count_tokens_3470(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_3471", "text": "def safe_reduce_3471(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_3472", "text": "class DataNormalizer_3472:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3473", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3473(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3473(n - 1) + fib_3473(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3474", "text": "def nested_analysis_3474(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3475", "text": "class TextProcessor_3475:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3476", "text": "from typing import Dict, Any\n\ndef validate_payload_3476(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3477", "text": "def compute_avg_3477(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3478", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3478(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3479", "text": "def compute_avg_3479(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3480", "text": "def validate_payload_3480(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3481", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_3481(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_3482", "text": "def pipeline_process_3482(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3483", "text": "def count_characters_3483(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_3484", "text": "from typing import Dict, Any\n\ndef validate_payload_3484(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3485", "text": "def compute_stats_3485(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3486", "text": "import re\n\ndef clean_texts_3486(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3487", "text": "from collections import Counter\n\ndef word_freq_3487(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_3488", "text": "import statistics\n\ndef stats_3488(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3489", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3489(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3489(n-1) + fib_3489(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3490", "text": "def nested_analysis_3490(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3491", "text": "def compute_stats_3491(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3492", "text": "class TextProcessor_3492:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3493", "text": "import json\n\ndef load_and_filter_3493(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_3494", "text": "class DataNormalizer_3494:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3495", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3495(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3496", "text": "import re\n\ndef clean_texts_3496(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3497", "text": "class Processor_3497:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_3498", "text": "def pipeline_process_3498(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3499", "text": "def compute_average_3499(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3500", "text": "def compute_average_3500(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3501", "text": "class Processor_3501:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_3502", "text": "class Config_3502:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3503", "text": "def compute_avg_3503(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3504", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3504(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3505", "text": "def validate_payload_3505(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3506", "text": "def count_tokens_3506(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_3507", "text": "def compute_avg_3507(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3508", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_3508(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3509", "text": "def safe_division_3509(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3510", "text": "import numpy as np\n\ndef normalize_features_3510(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3511", "text": "def validate_3511(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_3511(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_3511(seq):\n    clean = convert_3511(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3512", "text": "def meta_process_3512(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3513", "text": "def generate_report_3513(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3514", "text": "def structured_sum_3514(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3515", "text": "def validate_payload_3515(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3516", "text": "import numpy as np\n\ndef validate_and_predict_3516(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3517", "text": "def flatten_list_3517(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3518", "text": "class ExecutionNode_3518:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_3518():\n    import math\n\n    root = ExecutionNode_3518(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_3518(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_3518(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_3519", "text": "class Processor_3519:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_3520", "text": "class Config_3520:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3521", "text": "class Processor_3521:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_3522", "text": "def compute_average_3522(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3523", "text": "def analyze_series_3523(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3524", "text": "import re\n\ndef clean_texts_3524(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3525", "text": "import statistics\n\ndef stats_3525(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3526", "text": "def pipeline_process_3526(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3527", "text": "def meta_process_3527(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3528", "text": "def count_tokens_3528(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_3529", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3529(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3530", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_3530(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_3531", "text": "def nested_analysis_3531(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3532", "text": "def count_characters_3532(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_3533", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3533(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3534", "text": "def pipeline_process_3534(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3535", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3535(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3536", "text": "def generate_report_3536(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3537", "text": "def validate_payload_3537(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3538", "text": "import re\n\ndef clean_texts_3538(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3539", "text": "from typing import Dict, Any\n\ndef validate_payload_3539(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3540", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_3540(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3541", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3541(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3541(n - 1) + fib_3541(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3542", "text": "class DataNormalizer_3542:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3543", "text": "def flatten_list_3543(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3544", "text": "import re\n\ndef clean_texts_3544(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3545", "text": "class TextProcessor_3545:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3546", "text": "def safe_division_3546(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3547", "text": "def count_tokens_3547(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_3548", "text": "class DataNormalizer_3548:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3549", "text": "def count_tokens_3549(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_3550", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3550:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3550:\n    tasks: List[Task_3550] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3550(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3551", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3551(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3551(n - 1) + fib_3551(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3552", "text": "class Config_3552:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3553", "text": "def is_prime_3553(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3554", "text": "def compute_stats_3554(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3555", "text": "import json\n\ndef load_and_filter_3555(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_3556", "text": "class DataNormalizer_3556:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3557", "text": "import numpy as np\n\ndef minmax_norm_3557(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3558", "text": "def validate_payload_3558(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3559", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3559(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3560", "text": "def extract_numeric_3560(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3561", "text": "class Config_3561:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3562", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3562(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3563", "text": "class DataNormalizer_3563:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3564", "text": "class DataNormalizer_3564:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3565", "text": "import json\n\ndef load_and_filter_3565(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_3566", "text": "def generate_report_3566(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3567", "text": "import numpy as np\n\ndef minmax_norm_3567(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3568", "text": "def compute_sum_3568(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3569", "text": "def safe_reduce_3569(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_3570", "text": "def extract_numeric_3570(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3571", "text": "def validate_payload_3571(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3572", "text": "def structured_sum_3572(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3573", "text": "import json\n\ndef load_and_filter_3573(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_3574", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3574(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3575", "text": "def structured_sum_3575(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3576", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3576(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3577", "text": "def extract_numeric_3577(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3578", "text": "class Config_3578:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3579", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_3579(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_3580", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3580(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3580(n-1) + fib_3580(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3581", "text": "def compute_sum_3581(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3582", "text": "import numpy as np\n\ndef minmax_norm_3582(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3583", "text": "def compute_average_3583(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3584", "text": "def flatten_list_3584(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3585", "text": "def validate_payload_3585(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3586", "text": "def compute_stats_3586(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3587", "text": "def is_prime_3587(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3588", "text": "def compute_avg_3588(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3589", "text": "class TextProcessor_3589:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3590", "text": "def count_characters_3590(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_3591", "text": "class ExecutionNode_3591:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_3591():\n    import math\n\n    root = ExecutionNode_3591(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_3591(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_3591(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_3592", "text": "def validate_3592(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_3592(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_3592(seq):\n    clean = convert_3592(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3593", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3593:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3593:\n    tasks: List[Task_3593] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3593(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3594", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3594:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3594:\n    tasks: List[Task_3594] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3594(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3595", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3595(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3596", "text": "import json\n\ndef load_and_filter_3596(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_3597", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3597(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3597(n-1) + fib_3597(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3598", "text": "def compute_sum_3598(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3599", "text": "import numpy as np\n\ndef validate_and_predict_3599(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3600", "text": "def extract_numeric_3600(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3601", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3601(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3602", "text": "from typing import Dict, Any\n\ndef validate_payload_3602(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3603", "text": "def meta_process_3603(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3604", "text": "import re\n\ndef clean_texts_3604(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3605", "text": "def compute_sum_3605(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3606", "text": "def validate_3606(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_3606(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_3606(seq):\n    clean = convert_3606(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3607", "text": "def count_characters_3607(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_3608", "text": "def count_characters_3608(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_3609", "text": "class Config_3609:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3610", "text": "class TextProcessor_3610:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3611", "text": "def validate_3611(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_3611(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_3611(seq):\n    clean = convert_3611(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3612", "text": "def safe_divide_3612(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3613", "text": "def meta_process_3613(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3614", "text": "def safe_reduce_3614(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_3615", "text": "def safe_reduce_3615(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_3616", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_3616(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_3617", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3617(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3618", "text": "def count_characters_3618(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_3619", "text": "def compute_stats_3619(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3620", "text": "import statistics\n\ndef stats_3620(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3621", "text": "def analyze_series_3621(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3622", "text": "import json\n\ndef load_and_filter_3622(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_3623", "text": "def analyze_series_3623(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3624", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3624(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3625", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3625(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3625(n-1) + fib_3625(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3626", "text": "def compute_stats_3626(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3627", "text": "def pipeline_process_3627(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3628", "text": "def safe_divide_3628(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3629", "text": "import numpy as np\n\ndef validate_and_predict_3629(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3630", "text": "class Processor_3630:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_3631", "text": "def validate_3631(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_3631(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_3631(seq):\n    clean = convert_3631(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3632", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3632:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3632:\n    tasks: List[Task_3632] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3632(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3633", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3633(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3634", "text": "class ExecutionNode_3634:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_3634():\n    import math\n\n    root = ExecutionNode_3634(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_3634(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_3634(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_3635", "text": "def structured_sum_3635(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3636", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3636(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3637", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_3637(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_3638", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3638(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3639", "text": "import numpy as np\n\ndef minmax_norm_3639(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3640", "text": "def pipeline_process_3640(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3641", "text": "import numpy as np\n\ndef normalize_features_3641(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3642", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_3642():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3643", "text": "import numpy as np\n\ndef validate_and_predict_3643(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3644", "text": "from typing import Dict, Any\n\ndef validate_payload_3644(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3645", "text": "def safe_reduce_3645(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_3646", "text": "def generate_report_3646(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3647", "text": "def safe_division_3647(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3648", "text": "import numpy as np\n\ndef normalize_features_3648(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3649", "text": "def safe_division_3649(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3650", "text": "def validate_payload_3650(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_3651", "text": "def safe_divide_3651(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3652", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_3652(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3653", "text": "def flatten_list_3653(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3654", "text": "import numpy as np\n\ndef minmax_norm_3654(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3655", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3655(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3655(n-1) + fib_3655(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3656", "text": "class Config_3656:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3657", "text": "from collections import Counter\n\ndef word_freq_3657(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_3658", "text": "def safe_division_3658(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3659", "text": "def safe_division_3659(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3660", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3660(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3660(n-1) + fib_3660(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3661", "text": "import numpy as np\n\ndef validate_and_predict_3661(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3662", "text": "def compute_average_3662(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3663", "text": "def count_tokens_3663(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_3664", "text": "def compute_sum_3664(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3665", "text": "import numpy as np\n\ndef validate_and_predict_3665(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3666", "text": "def is_prime_3666(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3667", "text": "def safe_division_3667(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3668", "text": "import json\n\ndef load_and_filter_3668(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_3669", "text": "def validate_payload_3669(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3670", "text": "import statistics\n\ndef stats_3670(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3671", "text": "import json\n\ndef load_and_filter_3671(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_3672", "text": "class TextProcessor_3672:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3673", "text": "class DataNormalizer_3673:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3674", "text": "def nested_analysis_3674(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3675", "text": "def generate_report_3675(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3676", "text": "def compute_sum_3676(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3677", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3677(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3678", "text": "import statistics\n\ndef stats_3678(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3679", "text": "def nested_analysis_3679(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3680", "text": "def compute_average_3680(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3681", "text": "def validate_payload_3681(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_3682", "text": "def structured_sum_3682(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3683", "text": "def structured_sum_3683(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3684", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3684(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3684(n - 1) + fib_3684(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3685", "text": "def validate_payload_3685(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3686", "text": "def safe_division_3686(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3687", "text": "import numpy as np\n\ndef validate_and_predict_3687(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3688", "text": "def safe_division_3688(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3689", "text": "def extract_numeric_3689(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3690", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3690(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3690(n - 1) + fib_3690(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3691", "text": "def extract_numeric_3691(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3692", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3692(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3692(n - 1) + fib_3692(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3693", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_3693(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3694", "text": "class Config_3694:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3695", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3695:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3695:\n    tasks: List[Task_3695] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3695(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3696", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3696(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3697", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3697:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3697:\n    tasks: List[Task_3697] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3697(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3698", "text": "def count_characters_3698(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_3699", "text": "def extract_numeric_3699(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3700", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_3700(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_3701", "text": "def count_tokens_3701(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_3702", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3702(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3702(n - 1) + fib_3702(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3703", "text": "def meta_process_3703(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3704", "text": "def nested_analysis_3704(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3705", "text": "def is_prime_3705(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3706", "text": "def compute_avg_3706(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3707", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3707(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3708", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_3708():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3709", "text": "import numpy as np\n\ndef normalize_features_3709(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3710", "text": "from typing import Dict, Any\n\ndef validate_payload_3710(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3711", "text": "def count_characters_3711(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_3712", "text": "from typing import Dict, Any\n\ndef validate_payload_3712(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3713", "text": "def count_tokens_3713(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_3714", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3714(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3715", "text": "def flatten_list_3715(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3716", "text": "def analyze_series_3716(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3717", "text": "def is_prime_3717(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3718", "text": "def count_characters_3718(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_3719", "text": "class Config_3719:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3720", "text": "def compute_sum_3720(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3721", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_3721():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3722", "text": "class DataNormalizer_3722:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3723", "text": "class DataNormalizer_3723:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3724", "text": "def compute_sum_3724(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3725", "text": "import re\n\ndef clean_texts_3725(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3726", "text": "import json\n\ndef load_and_filter_3726(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_3727", "text": "from typing import Dict, Any\n\ndef validate_payload_3727(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3728", "text": "def validate_payload_3728(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_3729", "text": "def compute_average_3729(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3730", "text": "def structured_sum_3730(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3731", "text": "def compute_stats_3731(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3732", "text": "def compute_sum_3732(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3733", "text": "class ExecutionNode_3733:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_3733():\n    import math\n\n    root = ExecutionNode_3733(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_3733(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_3733(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_3734", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_3734(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_3735", "text": "class DataNormalizer_3735:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3736", "text": "def nested_analysis_3736(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3737", "text": "def compute_avg_3737(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3738", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3738(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3738(n - 1) + fib_3738(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3739", "text": "def safe_division_3739(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3740", "text": "from typing import Dict, Any\n\ndef validate_payload_3740(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3741", "text": "import statistics\n\ndef stats_3741(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3742", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3742(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3743", "text": "from typing import Dict, Any\n\ndef validate_payload_3743(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3744", "text": "def count_characters_3744(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_3745", "text": "def generate_report_3745(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3746", "text": "def is_prime_3746(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3747", "text": "def compute_average_3747(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3748", "text": "def safe_division_3748(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3749", "text": "def structured_sum_3749(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3750", "text": "def extract_numeric_3750(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3751", "text": "def meta_process_3751(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3752", "text": "def count_characters_3752(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_3753", "text": "def structured_sum_3753(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3754", "text": "def validate_3754(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_3754(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_3754(seq):\n    clean = convert_3754(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3755", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3755(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3756", "text": "def compute_avg_3756(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3757", "text": "def is_prime_3757(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3758", "text": "def structured_sum_3758(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3759", "text": "def flatten_list_3759(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3760", "text": "def safe_division_3760(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3761", "text": "def compute_sum_3761(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3762", "text": "def validate_3762(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_3762(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_3762(seq):\n    clean = convert_3762(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3763", "text": "import numpy as np\n\ndef validate_and_predict_3763(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3764", "text": "class TextProcessor_3764:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3765", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3765(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3766", "text": "import statistics\n\ndef stats_3766(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3767", "text": "def compute_avg_3767(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3768", "text": "import numpy as np\n\ndef validate_and_predict_3768(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3769", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_3769(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3770", "text": "def safe_divide_3770(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3771", "text": "def compute_average_3771(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3772", "text": "def compute_average_3772(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3773", "text": "def safe_divide_3773(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3774", "text": "class ExecutionNode_3774:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_3774():\n    import math\n\n    root = ExecutionNode_3774(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_3774(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_3774(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_3775", "text": "def compute_average_3775(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3776", "text": "import numpy as np\n\ndef validate_and_predict_3776(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3777", "text": "import numpy as np\n\ndef validate_and_predict_3777(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3778", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3778(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3779", "text": "def flatten_list_3779(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3780", "text": "def flatten_list_3780(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3781", "text": "def structured_sum_3781(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3782", "text": "def safe_divide_3782(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3783", "text": "def safe_divide_3783(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3784", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3784:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3784:\n    tasks: List[Task_3784] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3784(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3785", "text": "class DataNormalizer_3785:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3786", "text": "def safe_division_3786(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3787", "text": "class TextProcessor_3787:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3788", "text": "from typing import Dict, Any\n\ndef validate_payload_3788(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3789", "text": "def pipeline_process_3789(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3790", "text": "def safe_reduce_3790(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_3791", "text": "def generate_report_3791(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3792", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3792:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3792:\n    tasks: List[Task_3792] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3792(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3793", "text": "def validate_payload_3793(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3794", "text": "def safe_reduce_3794(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_3795", "text": "class TextProcessor_3795:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3796", "text": "def compute_average_3796(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3797", "text": "def compute_average_3797(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3798", "text": "def validate_payload_3798(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3799", "text": "class TextProcessor_3799:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3800", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3800(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3800(n-1) + fib_3800(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3801", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3801(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3802", "text": "def analyze_series_3802(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3803", "text": "class TextProcessor_3803:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3804", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_3804(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3805", "text": "import numpy as np\n\ndef normalize_features_3805(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3806", "text": "def compute_avg_3806(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3807", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_3807():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3808", "text": "def compute_avg_3808(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3809", "text": "def validate_payload_3809(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3810", "text": "def compute_average_3810(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3811", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3811(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3811(n - 1) + fib_3811(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3812", "text": "def meta_process_3812(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3813", "text": "def meta_process_3813(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3814", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3814(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3815", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3815(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3816", "text": "from collections import Counter\n\ndef word_freq_3816(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_3817", "text": "import numpy as np\n\ndef validate_and_predict_3817(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3818", "text": "def safe_division_3818(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3819", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3819(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3820", "text": "def safe_division_3820(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3821", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3821(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3822", "text": "def compute_average_3822(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3823", "text": "def validate_payload_3823(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3824", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3824(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3824(n - 1) + fib_3824(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3825", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3825(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3826", "text": "def safe_divide_3826(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3827", "text": "def validate_3827(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_3827(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_3827(seq):\n    clean = convert_3827(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3828", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_3828(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_3829", "text": "import numpy as np\n\ndef validate_and_predict_3829(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3830", "text": "def extract_numeric_3830(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3831", "text": "def safe_divide_3831(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3832", "text": "def nested_analysis_3832(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3833", "text": "class Processor_3833:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_3834", "text": "def count_tokens_3834(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_3835", "text": "def validate_payload_3835(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3836", "text": "import statistics\n\ndef stats_3836(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3837", "text": "from typing import Dict, Any\n\ndef validate_payload_3837(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3838", "text": "def validate_payload_3838(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_3839", "text": "def validate_payload_3839(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_3840", "text": "def is_prime_3840(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3841", "text": "def safe_division_3841(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3842", "text": "class ExecutionNode_3842:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_3842():\n    import math\n\n    root = ExecutionNode_3842(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_3842(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_3842(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_3843", "text": "def count_characters_3843(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_3844", "text": "import statistics\n\ndef stats_3844(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3845", "text": "import statistics\n\ndef stats_3845(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3846", "text": "def structured_sum_3846(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3847", "text": "import json\n\ndef load_and_filter_3847(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_3848", "text": "def nested_analysis_3848(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3849", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3849(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3850", "text": "def safe_reduce_3850(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_3851", "text": "def extract_numeric_3851(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3852", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3852:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3852:\n    tasks: List[Task_3852] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3852(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3853", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3853:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3853:\n    tasks: List[Task_3853] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3853(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3854", "text": "def structured_sum_3854(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3855", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3855(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3856", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_3856(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3857", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_3857():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3858", "text": "class TextProcessor_3858:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3859", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_3859(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_3860", "text": "class Processor_3860:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_3861", "text": "def extract_numeric_3861(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3862", "text": "def validate_payload_3862(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3863", "text": "import numpy as np\n\ndef minmax_norm_3863(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3864", "text": "import numpy as np\n\ndef normalize_features_3864(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3865", "text": "class TextProcessor_3865:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3866", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_3866(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3867", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3867(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3868", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3868(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3869", "text": "def safe_reduce_3869(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_3870", "text": "import statistics\n\ndef stats_3870(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3871", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3871(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3871(n-1) + fib_3871(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3872", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_3872(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_3873", "text": "import numpy as np\n\ndef normalize_features_3873(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3874", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3874(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3874(n - 1) + fib_3874(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3875", "text": "def compute_average_3875(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3876", "text": "def safe_division_3876(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3877", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_3877(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_3877(n-1) + fib_3877(n-2)", "label": "1", "lang": "python"}
{"id": "AI_3878", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3878(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3879", "text": "import numpy as np\n\ndef normalize_features_3879(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3880", "text": "def safe_divide_3880(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3881", "text": "class TextProcessor_3881:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3882", "text": "def analyze_series_3882(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3883", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3883(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3884", "text": "import statistics\n\ndef stats_3884(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3885", "text": "def validate_3885(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_3885(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_3885(seq):\n    clean = convert_3885(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3886", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3886(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3887", "text": "def analyze_series_3887(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3888", "text": "def extract_numeric_3888(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3889", "text": "def meta_process_3889(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3890", "text": "class ExecutionNode_3890:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_3890():\n    import math\n\n    root = ExecutionNode_3890(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_3890(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_3890(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_3891", "text": "import statistics\n\ndef stats_3891(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3892", "text": "def validate_3892(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_3892(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_3892(seq):\n    clean = convert_3892(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3893", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3893(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3894", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3894(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3895", "text": "def structured_sum_3895(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3896", "text": "def compute_sum_3896(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3897", "text": "def flatten_list_3897(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3898", "text": "import numpy as np\n\ndef minmax_norm_3898(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3899", "text": "def is_prime_3899(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3900", "text": "class Config_3900:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_3901", "text": "def pipeline_process_3901(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3902", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_3902(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3903", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3903(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3904", "text": "from typing import Dict, Any\n\ndef validate_payload_3904(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3905", "text": "def count_tokens_3905(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_3906", "text": "def compute_sum_3906(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3907", "text": "def validate_payload_3907(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_3908", "text": "def validate_payload_3908(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_3909", "text": "class Processor_3909:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_3910", "text": "def analyze_series_3910(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3911", "text": "def extract_numeric_3911(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3912", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_3912(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3913", "text": "import re\n\ndef clean_texts_3913(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3914", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_3914(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_3915", "text": "class DataNormalizer_3915:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3916", "text": "import numpy as np\n\ndef validate_and_predict_3916(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3917", "text": "def nested_analysis_3917(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3918", "text": "def flatten_list_3918(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3919", "text": "def structured_sum_3919(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3920", "text": "def compute_sum_3920(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3921", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3921(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3922", "text": "import numpy as np\n\ndef minmax_norm_3922(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3923", "text": "def compute_stats_3923(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3924", "text": "def structured_sum_3924(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3925", "text": "def compute_avg_3925(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3926", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3926:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3926:\n    tasks: List[Task_3926] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3926(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3927", "text": "from collections import Counter\n\ndef word_freq_3927(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_3928", "text": "def flatten_list_3928(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3929", "text": "def safe_division_3929(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3930", "text": "def analyze_series_3930(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3931", "text": "def compute_stats_3931(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3932", "text": "class TextProcessor_3932:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3933", "text": "import numpy as np\n\ndef validate_and_predict_3933(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_3934", "text": "from typing import Dict, Any\n\ndef validate_payload_3934(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3935", "text": "def meta_process_3935(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3936", "text": "def compute_stats_3936(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3937", "text": "def flatten_list_3937(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3938", "text": "def safe_division_3938(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3939", "text": "def compute_average_3939(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3940", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3940(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3941", "text": "import statistics\n\ndef stats_3941(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3942", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3942(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3942(n - 1) + fib_3942(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3943", "text": "def safe_division_3943(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3944", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_3944():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3945", "text": "import numpy as np\n\ndef normalize_features_3945(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3946", "text": "def safe_divide_3946(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3947", "text": "def count_characters_3947(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_3948", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_3948:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_3948:\n    tasks: List[Task_3948] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_3948(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_3949", "text": "def safe_division_3949(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3950", "text": "def validate_3950(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_3950(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_3950(seq):\n    clean = convert_3950(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3951", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_3951():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3952", "text": "class DataNormalizer_3952:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3953", "text": "def compute_average_3953(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_3954", "text": "def meta_process_3954(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3955", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3955(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3956", "text": "def extract_numeric_3956(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_3957", "text": "class DataNormalizer_3957:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_3958", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_3958(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_3959", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3959(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3960", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_3960(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3961", "text": "def meta_process_3961(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_3962", "text": "def safe_divide_3962(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_3963", "text": "from typing import Dict, Any\n\ndef validate_payload_3963(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3964", "text": "import numpy as np\n\ndef normalize_features_3964(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3965", "text": "def compute_stats_3965(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3966", "text": "def safe_division_3966(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3967", "text": "def flatten_list_3967(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3968", "text": "def count_tokens_3968(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_3969", "text": "def compute_sum_3969(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3970", "text": "def compute_stats_3970(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3971", "text": "def validate_payload_3971(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3972", "text": "from typing import Dict, Any\n\ndef validate_payload_3972(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3973", "text": "import numpy as np\n\ndef normalize_features_3973(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3974", "text": "import numpy as np\n\ndef minmax_norm_3974(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_3975", "text": "def validate_3975(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_3975(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_3975(seq):\n    clean = convert_3975(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3976", "text": "class TextProcessor_3976:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3977", "text": "def structured_sum_3977(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3978", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_3978(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_3979", "text": "def structured_sum_3979(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3980", "text": "def flatten_list_3980(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_3981", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_3981():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3982", "text": "import statistics\n\ndef stats_3982(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3983", "text": "def validate_payload_3983(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3984", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_3984(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_3985", "text": "def structured_sum_3985(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3986", "text": "def structured_sum_3986(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_3987", "text": "def safe_reduce_3987(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_3988", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_3988(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_3988(n - 1) + fib_3988(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_3989", "text": "def compute_avg_3989(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_3990", "text": "class TextProcessor_3990:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3991", "text": "import statistics\n\ndef stats_3991(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_3992", "text": "def compute_sum_3992(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_3993", "text": "def count_tokens_3993(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_3994", "text": "def safe_division_3994(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_3995", "text": "def safe_reduce_3995(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_3996", "text": "def validate_payload_3996(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_3997", "text": "class TextProcessor_3997:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_3998", "text": "from collections import Counter\n\ndef word_freq_3998(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_3999", "text": "def compute_average_3999(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4000", "text": "def meta_process_4000(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4001", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4001(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4002", "text": "def compute_stats_4002(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4003", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4003:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4003:\n    tasks: List[Task_4003] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4003(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4004", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4004(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4005", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4005():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4006", "text": "class DataNormalizer_4006:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4007", "text": "def compute_sum_4007(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4008", "text": "import numpy as np\n\ndef normalize_features_4008(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4009", "text": "from collections import Counter\n\ndef word_freq_4009(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_4010", "text": "def pipeline_process_4010(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4011", "text": "import json\n\ndef load_and_filter_4011(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_4012", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4012():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4013", "text": "def generate_report_4013(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4014", "text": "def count_characters_4014(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_4015", "text": "def pipeline_process_4015(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4016", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_4016(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_4016(n - 1) + fib_4016(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_4017", "text": "def meta_process_4017(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4018", "text": "def compute_sum_4018(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4019", "text": "import re\n\ndef clean_texts_4019(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4020", "text": "def safe_division_4020(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4021", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_4021(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_4021(n - 1) + fib_4021(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_4022", "text": "def count_tokens_4022(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4023", "text": "def compute_sum_4023(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4024", "text": "def validate_payload_4024(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_4025", "text": "import re\n\ndef clean_texts_4025(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4026", "text": "def structured_sum_4026(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4027", "text": "class DataNormalizer_4027:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4028", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_4028(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_4028(n - 1) + fib_4028(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_4029", "text": "def compute_stats_4029(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4030", "text": "def validate_payload_4030(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4031", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4031:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4031:\n    tasks: List[Task_4031] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4031(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4032", "text": "import numpy as np\n\ndef normalize_features_4032(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4033", "text": "def nested_analysis_4033(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4034", "text": "def structured_sum_4034(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4035", "text": "def compute_avg_4035(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_4036", "text": "class Config_4036:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4037", "text": "def compute_sum_4037(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4038", "text": "def safe_division_4038(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4039", "text": "import re\n\ndef clean_texts_4039(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4040", "text": "def meta_process_4040(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4041", "text": "class Config_4041:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4042", "text": "import numpy as np\n\ndef minmax_norm_4042(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4043", "text": "from typing import Dict, Any\n\ndef validate_payload_4043(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4044", "text": "class Config_4044:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4045", "text": "def compute_average_4045(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4046", "text": "def pipeline_process_4046(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4047", "text": "def count_characters_4047(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_4048", "text": "class Processor_4048:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4049", "text": "def safe_reduce_4049(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4050", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4050:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4050:\n    tasks: List[Task_4050] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4050(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4051", "text": "class DataNormalizer_4051:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4052", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4052():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4053", "text": "def nested_analysis_4053(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4054", "text": "class Config_4054:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4055", "text": "import numpy as np\n\ndef minmax_norm_4055(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4056", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_4056(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_4057", "text": "def nested_analysis_4057(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4058", "text": "def generate_report_4058(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4059", "text": "def compute_average_4059(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4060", "text": "class TextProcessor_4060:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4061", "text": "import numpy as np\n\ndef minmax_norm_4061(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4062", "text": "class TextProcessor_4062:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4063", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4063(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4064", "text": "def generate_report_4064(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4065", "text": "import numpy as np\n\ndef minmax_norm_4065(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4066", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4066(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4067", "text": "class Processor_4067:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4068", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4068():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4069", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_4069(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_4069(n - 1) + fib_4069(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_4070", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4070():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4071", "text": "class TextProcessor_4071:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4072", "text": "def safe_divide_4072(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_4073", "text": "def validate_4073(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4073(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4073(seq):\n    clean = convert_4073(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4074", "text": "def extract_numeric_4074(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_4075", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4075(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4076", "text": "class TextProcessor_4076:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4077", "text": "def count_tokens_4077(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4078", "text": "def generate_report_4078(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4079", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_4079(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_4080", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4080(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4081", "text": "def safe_reduce_4081(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4082", "text": "def safe_reduce_4082(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4083", "text": "def safe_reduce_4083(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4084", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4084(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4085", "text": "def meta_process_4085(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4086", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_4086(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_4087", "text": "def generate_report_4087(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4088", "text": "def structured_sum_4088(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4089", "text": "import statistics\n\ndef stats_4089(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4090", "text": "def compute_average_4090(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4091", "text": "class DataNormalizer_4091:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4092", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4092(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4093", "text": "class DataNormalizer_4093:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4094", "text": "def generate_report_4094(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4095", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_4095(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_4095(n - 1) + fib_4095(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_4096", "text": "class DataNormalizer_4096:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4097", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4097:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4097:\n    tasks: List[Task_4097] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4097(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4098", "text": "def validate_payload_4098(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4099", "text": "import numpy as np\n\ndef minmax_norm_4099(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4100", "text": "import numpy as np\n\ndef minmax_norm_4100(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4101", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4101(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4102", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4102(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4103", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4103(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4104", "text": "import json\n\ndef load_and_filter_4104(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_4105", "text": "def is_prime_4105(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4106", "text": "def count_tokens_4106(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4107", "text": "class DataNormalizer_4107:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4108", "text": "def safe_divide_4108(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_4109", "text": "def compute_sum_4109(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4110", "text": "def is_prime_4110(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4111", "text": "from typing import Dict, Any\n\ndef validate_payload_4111(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4112", "text": "def meta_process_4112(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4113", "text": "def is_prime_4113(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4114", "text": "def validate_4114(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4114(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4114(seq):\n    clean = convert_4114(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4115", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4115():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4116", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4116(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4116(n-1) + fib_4116(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4117", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4117:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4117:\n    tasks: List[Task_4117] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4117(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4118", "text": "import re\n\ndef clean_texts_4118(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4119", "text": "def is_prime_4119(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4120", "text": "from collections import Counter\n\ndef word_freq_4120(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_4121", "text": "import json\n\ndef load_and_filter_4121(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_4122", "text": "import numpy as np\n\ndef normalize_features_4122(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4123", "text": "def safe_division_4123(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4124", "text": "def validate_4124(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4124(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4124(seq):\n    clean = convert_4124(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4125", "text": "def pipeline_process_4125(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4126", "text": "import json\n\ndef load_and_filter_4126(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_4127", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_4127(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_4127(n - 1) + fib_4127(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_4128", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4128(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4129", "text": "class Config_4129:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4130", "text": "def safe_division_4130(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4131", "text": "def compute_avg_4131(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_4132", "text": "class TextProcessor_4132:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4133", "text": "import numpy as np\n\ndef normalize_features_4133(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4134", "text": "def validate_4134(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4134(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4134(seq):\n    clean = convert_4134(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4135", "text": "def count_tokens_4135(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4136", "text": "def count_tokens_4136(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4137", "text": "import json\n\ndef load_and_filter_4137(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_4138", "text": "def is_prime_4138(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4139", "text": "def safe_divide_4139(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_4140", "text": "import re\n\ndef clean_texts_4140(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4141", "text": "import statistics\n\ndef stats_4141(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4142", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4142(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4142(n-1) + fib_4142(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4143", "text": "def safe_divide_4143(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_4144", "text": "def compute_avg_4144(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_4145", "text": "def extract_numeric_4145(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_4146", "text": "def nested_analysis_4146(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4147", "text": "class Config_4147:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4148", "text": "import statistics\n\ndef stats_4148(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4149", "text": "from collections import Counter\n\ndef word_freq_4149(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_4150", "text": "def extract_numeric_4150(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_4151", "text": "def pipeline_process_4151(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4152", "text": "def generate_report_4152(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4153", "text": "def flatten_list_4153(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4154", "text": "def structured_sum_4154(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4155", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4155:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4155:\n    tasks: List[Task_4155] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4155(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4156", "text": "def safe_division_4156(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4157", "text": "def count_characters_4157(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_4158", "text": "def validate_payload_4158(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_4159", "text": "def safe_reduce_4159(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4160", "text": "import numpy as np\n\ndef validate_and_predict_4160(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4161", "text": "class Config_4161:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4162", "text": "def safe_reduce_4162(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4163", "text": "def pipeline_process_4163(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4164", "text": "def validate_4164(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4164(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4164(seq):\n    clean = convert_4164(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4165", "text": "class Processor_4165:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4166", "text": "def flatten_list_4166(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4167", "text": "import json\n\ndef load_and_filter_4167(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_4168", "text": "import numpy as np\n\ndef normalize_features_4168(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4169", "text": "class Processor_4169:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4170", "text": "class TextProcessor_4170:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4171", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4171(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4172", "text": "def validate_payload_4172(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4173", "text": "def compute_sum_4173(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4174", "text": "import re\n\ndef clean_texts_4174(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4175", "text": "import statistics\n\ndef stats_4175(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4176", "text": "def safe_divide_4176(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_4177", "text": "def validate_payload_4177(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4178", "text": "class TextProcessor_4178:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4179", "text": "def safe_division_4179(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4180", "text": "def validate_payload_4180(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4181", "text": "def extract_numeric_4181(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_4182", "text": "import json\n\ndef load_and_filter_4182(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_4183", "text": "def count_tokens_4183(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4184", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4184(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4184(n-1) + fib_4184(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4185", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4185(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4186", "text": "class TextProcessor_4186:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4187", "text": "def safe_division_4187(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4188", "text": "class Processor_4188:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4189", "text": "def compute_stats_4189(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4190", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4190(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4191", "text": "def count_tokens_4191(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4192", "text": "from typing import Dict, Any\n\ndef validate_payload_4192(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4193", "text": "def flatten_list_4193(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4194", "text": "def count_tokens_4194(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4195", "text": "class TextProcessor_4195:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4196", "text": "def nested_analysis_4196(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4197", "text": "def compute_average_4197(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4198", "text": "class Config_4198:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4199", "text": "def safe_division_4199(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4200", "text": "from collections import Counter\n\ndef word_freq_4200(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_4201", "text": "def validate_4201(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4201(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4201(seq):\n    clean = convert_4201(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4202", "text": "def extract_numeric_4202(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_4203", "text": "import json\n\ndef load_and_filter_4203(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_4204", "text": "def validate_4204(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4204(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4204(seq):\n    clean = convert_4204(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4205", "text": "def count_characters_4205(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_4206", "text": "def compute_average_4206(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4207", "text": "def nested_analysis_4207(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4208", "text": "def nested_analysis_4208(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4209", "text": "def count_tokens_4209(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4210", "text": "def validate_payload_4210(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_4211", "text": "def compute_sum_4211(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4212", "text": "def extract_numeric_4212(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_4213", "text": "from typing import Dict, Any\n\ndef validate_payload_4213(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4214", "text": "import numpy as np\n\ndef normalize_features_4214(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4215", "text": "import json\n\ndef load_and_filter_4215(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_4216", "text": "def structured_sum_4216(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4217", "text": "class Config_4217:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4218", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4218(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4219", "text": "def pipeline_process_4219(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4220", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4220(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4221", "text": "import numpy as np\n\ndef minmax_norm_4221(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4222", "text": "def safe_reduce_4222(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4223", "text": "def analyze_series_4223(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4224", "text": "import numpy as np\n\ndef normalize_features_4224(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4225", "text": "def pipeline_process_4225(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4226", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_4226(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_4227", "text": "def safe_reduce_4227(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4228", "text": "def nested_analysis_4228(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4229", "text": "import statistics\n\ndef stats_4229(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4230", "text": "def count_tokens_4230(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4231", "text": "class DataNormalizer_4231:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4232", "text": "import numpy as np\n\ndef normalize_features_4232(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4233", "text": "def compute_average_4233(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4234", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4234(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4235", "text": "def safe_divide_4235(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_4236", "text": "def compute_sum_4236(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4237", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_4237(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_4238", "text": "def generate_report_4238(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4239", "text": "def safe_division_4239(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4240", "text": "def flatten_list_4240(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4241", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4241:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4241:\n    tasks: List[Task_4241] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4241(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4242", "text": "def validate_4242(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4242(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4242(seq):\n    clean = convert_4242(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4243", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4243(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4244", "text": "import numpy as np\n\ndef minmax_norm_4244(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4245", "text": "def generate_report_4245(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4246", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4246(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4246(n-1) + fib_4246(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4247", "text": "import numpy as np\n\ndef validate_and_predict_4247(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4248", "text": "import re\n\ndef clean_texts_4248(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4249", "text": "def pipeline_process_4249(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4250", "text": "def compute_sum_4250(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4251", "text": "class DataNormalizer_4251:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4252", "text": "def safe_reduce_4252(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4253", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4253():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4254", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4254(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4255", "text": "def pipeline_process_4255(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4256", "text": "class Processor_4256:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4257", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_4257(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_4257(n - 1) + fib_4257(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_4258", "text": "class DataNormalizer_4258:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4259", "text": "import numpy as np\n\ndef minmax_norm_4259(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4260", "text": "def meta_process_4260(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4261", "text": "import numpy as np\n\ndef minmax_norm_4261(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4262", "text": "class Processor_4262:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4263", "text": "class Processor_4263:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4264", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4264():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4265", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_4265(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_4266", "text": "def safe_division_4266(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4267", "text": "def structured_sum_4267(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4268", "text": "def structured_sum_4268(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4269", "text": "def analyze_series_4269(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4270", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_4270(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_4270(n - 1) + fib_4270(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_4271", "text": "def safe_division_4271(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4272", "text": "import json\n\ndef load_and_filter_4272(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_4273", "text": "def compute_sum_4273(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4274", "text": "def safe_division_4274(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4275", "text": "import statistics\n\ndef stats_4275(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4276", "text": "import re\n\ndef clean_texts_4276(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4277", "text": "def compute_stats_4277(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4278", "text": "import json\n\ndef load_and_filter_4278(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_4279", "text": "def count_tokens_4279(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4280", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_4280(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_4281", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4281:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4281:\n    tasks: List[Task_4281] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4281(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4282", "text": "def structured_sum_4282(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4283", "text": "def compute_stats_4283(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4284", "text": "def pipeline_process_4284(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4285", "text": "def safe_division_4285(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4286", "text": "class Processor_4286:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4287", "text": "import numpy as np\n\ndef validate_and_predict_4287(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4288", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4288(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4289", "text": "def validate_payload_4289(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4290", "text": "def compute_average_4290(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4291", "text": "def compute_stats_4291(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4292", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4292():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4293", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4293:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4293:\n    tasks: List[Task_4293] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4293(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4294", "text": "def safe_reduce_4294(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4295", "text": "def flatten_list_4295(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4296", "text": "import numpy as np\n\ndef minmax_norm_4296(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4297", "text": "def compute_average_4297(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4298", "text": "def count_characters_4298(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_4299", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4299():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4300", "text": "import numpy as np\n\ndef normalize_features_4300(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4301", "text": "import re\n\ndef clean_texts_4301(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4302", "text": "def is_prime_4302(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4303", "text": "import numpy as np\n\ndef minmax_norm_4303(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4304", "text": "class Processor_4304:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4305", "text": "def structured_sum_4305(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4306", "text": "class Processor_4306:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4307", "text": "def pipeline_process_4307(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4308", "text": "def structured_sum_4308(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4309", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4309(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4309(n-1) + fib_4309(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4310", "text": "import statistics\n\ndef stats_4310(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4311", "text": "def count_characters_4311(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_4312", "text": "class DataNormalizer_4312:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4313", "text": "class Config_4313:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4314", "text": "def compute_average_4314(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4315", "text": "def validate_payload_4315(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_4316", "text": "def nested_analysis_4316(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4317", "text": "def validate_payload_4317(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4318", "text": "import re\n\ndef clean_texts_4318(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4319", "text": "def validate_payload_4319(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4320", "text": "def flatten_list_4320(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4321", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4321(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4321(n-1) + fib_4321(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4322", "text": "def extract_numeric_4322(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_4323", "text": "def flatten_list_4323(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4324", "text": "from collections import Counter\n\ndef word_freq_4324(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_4325", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4325(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4326", "text": "def meta_process_4326(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4327", "text": "def structured_sum_4327(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4328", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_4328(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_4329", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4329(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4329(n-1) + fib_4329(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4330", "text": "def safe_divide_4330(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_4331", "text": "def nested_analysis_4331(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4332", "text": "class TextProcessor_4332:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4333", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4333(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4334", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4334(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4335", "text": "def count_characters_4335(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_4336", "text": "def safe_reduce_4336(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4337", "text": "import numpy as np\n\ndef minmax_norm_4337(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4338", "text": "class TextProcessor_4338:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4339", "text": "import json\n\ndef load_and_filter_4339(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_4340", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4340(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4340(n-1) + fib_4340(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4341", "text": "def compute_sum_4341(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4342", "text": "def validate_payload_4342(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4343", "text": "def pipeline_process_4343(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4344", "text": "class TextProcessor_4344:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4345", "text": "class DataNormalizer_4345:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4346", "text": "def meta_process_4346(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4347", "text": "class TextProcessor_4347:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4348", "text": "class Processor_4348:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4349", "text": "def compute_average_4349(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4350", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4350:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4350:\n    tasks: List[Task_4350] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4350(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4351", "text": "def safe_reduce_4351(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4352", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4352(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4353", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4353(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4354", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4354():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4355", "text": "def safe_reduce_4355(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4356", "text": "def compute_avg_4356(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_4357", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4357(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4358", "text": "class DataNormalizer_4358:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4359", "text": "import numpy as np\n\ndef normalize_features_4359(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4360", "text": "def pipeline_process_4360(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4361", "text": "def safe_division_4361(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4362", "text": "def compute_sum_4362(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4363", "text": "def analyze_series_4363(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4364", "text": "import numpy as np\n\ndef validate_and_predict_4364(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4365", "text": "def validate_payload_4365(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_4366", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4366():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4367", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4367():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4368", "text": "import statistics\n\ndef stats_4368(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4369", "text": "from collections import Counter\n\ndef word_freq_4369(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_4370", "text": "from typing import Dict, Any\n\ndef validate_payload_4370(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4371", "text": "def flatten_list_4371(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4372", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4372():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4373", "text": "def analyze_series_4373(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4374", "text": "def validate_payload_4374(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_4375", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4375:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4375:\n    tasks: List[Task_4375] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4375(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4376", "text": "import numpy as np\n\ndef validate_and_predict_4376(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4377", "text": "def safe_division_4377(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4378", "text": "def compute_avg_4378(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_4379", "text": "def analyze_series_4379(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4380", "text": "class DataNormalizer_4380:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4381", "text": "def analyze_series_4381(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4382", "text": "class Processor_4382:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4383", "text": "def extract_numeric_4383(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_4384", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4384(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4385", "text": "class DataNormalizer_4385:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4386", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_4386(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_4387", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4387(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4388", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4388(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4389", "text": "def is_prime_4389(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4390", "text": "def compute_average_4390(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4391", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4391(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4392", "text": "def compute_stats_4392(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4393", "text": "def pipeline_process_4393(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4394", "text": "def structured_sum_4394(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4395", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4395(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4396", "text": "class Processor_4396:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4397", "text": "from typing import Dict, Any\n\ndef validate_payload_4397(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4398", "text": "class TextProcessor_4398:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4399", "text": "def safe_division_4399(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4400", "text": "class ExecutionNode_4400:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_4400():\n    import math\n\n    root = ExecutionNode_4400(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_4400(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_4400(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_4401", "text": "def meta_process_4401(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4402", "text": "def validate_payload_4402(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4403", "text": "import json\n\ndef load_and_filter_4403(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_4404", "text": "def count_tokens_4404(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4405", "text": "def safe_divide_4405(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_4406", "text": "import statistics\n\ndef stats_4406(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4407", "text": "class Config_4407:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4408", "text": "def meta_process_4408(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4409", "text": "import statistics\n\ndef stats_4409(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4410", "text": "def validate_payload_4410(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4411", "text": "class TextProcessor_4411:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4412", "text": "def validate_payload_4412(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4413", "text": "def analyze_series_4413(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4414", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4414(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4415", "text": "class Processor_4415:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4416", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4416(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4417", "text": "import statistics\n\ndef stats_4417(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4418", "text": "import numpy as np\n\ndef validate_and_predict_4418(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4419", "text": "def compute_average_4419(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4420", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4420(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4421", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4421:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4421:\n    tasks: List[Task_4421] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4421(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4422", "text": "def validate_4422(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4422(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4422(seq):\n    clean = convert_4422(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4423", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4423(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4424", "text": "def is_prime_4424(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4425", "text": "def safe_reduce_4425(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4426", "text": "import re\n\ndef clean_texts_4426(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4427", "text": "import re\n\ndef clean_texts_4427(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4428", "text": "def compute_stats_4428(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4429", "text": "def is_prime_4429(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4430", "text": "def pipeline_process_4430(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4431", "text": "def structured_sum_4431(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4432", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4432:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4432:\n    tasks: List[Task_4432] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4432(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4433", "text": "def compute_avg_4433(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_4434", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_4434(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_4435", "text": "def compute_average_4435(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4436", "text": "import json\n\ndef load_and_filter_4436(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_4437", "text": "def flatten_list_4437(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4438", "text": "import numpy as np\n\ndef normalize_features_4438(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4439", "text": "import numpy as np\n\ndef minmax_norm_4439(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4440", "text": "def pipeline_process_4440(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4441", "text": "def validate_payload_4441(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_4442", "text": "def compute_average_4442(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4443", "text": "def extract_numeric_4443(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_4444", "text": "def compute_avg_4444(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_4445", "text": "def count_tokens_4445(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4446", "text": "class Processor_4446:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4447", "text": "import statistics\n\ndef stats_4447(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4448", "text": "def extract_numeric_4448(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_4449", "text": "class DataNormalizer_4449:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4450", "text": "def count_characters_4450(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_4451", "text": "def validate_4451(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4451(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4451(seq):\n    clean = convert_4451(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4452", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4452(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4453", "text": "def flatten_list_4453(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4454", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_4454(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_4455", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4455():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4456", "text": "def count_characters_4456(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_4457", "text": "import json\n\ndef load_and_filter_4457(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_4458", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4458(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4459", "text": "from collections import Counter\n\ndef word_freq_4459(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_4460", "text": "import re\n\ndef clean_texts_4460(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4461", "text": "import json\n\ndef load_and_filter_4461(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_4462", "text": "def meta_process_4462(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4463", "text": "from typing import Dict, Any\n\ndef validate_payload_4463(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4464", "text": "def validate_4464(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4464(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4464(seq):\n    clean = convert_4464(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4465", "text": "def is_prime_4465(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4466", "text": "def safe_division_4466(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4467", "text": "import re\n\ndef clean_texts_4467(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4468", "text": "class Processor_4468:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4469", "text": "def safe_division_4469(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4470", "text": "def compute_average_4470(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4471", "text": "def validate_payload_4471(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4472", "text": "def validate_payload_4472(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4473", "text": "def nested_analysis_4473(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4474", "text": "def compute_avg_4474(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_4475", "text": "class Processor_4475:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4476", "text": "def count_tokens_4476(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4477", "text": "import re\n\ndef clean_texts_4477(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4478", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4478():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4479", "text": "def safe_reduce_4479(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4480", "text": "def validate_payload_4480(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_4481", "text": "class Processor_4481:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4482", "text": "def is_prime_4482(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4483", "text": "def count_characters_4483(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_4484", "text": "def validate_payload_4484(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_4485", "text": "def is_prime_4485(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4486", "text": "def analyze_series_4486(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4487", "text": "def is_prime_4487(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4488", "text": "def extract_numeric_4488(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_4489", "text": "class TextProcessor_4489:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4490", "text": "def safe_division_4490(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4491", "text": "class Processor_4491:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4492", "text": "from collections import Counter\n\ndef word_freq_4492(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_4493", "text": "from typing import Dict, Any\n\ndef validate_payload_4493(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4494", "text": "def generate_report_4494(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4495", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4495():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4496", "text": "import numpy as np\n\ndef validate_and_predict_4496(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4497", "text": "class TextProcessor_4497:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4498", "text": "class Processor_4498:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4499", "text": "def validate_payload_4499(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_4500", "text": "import re\n\ndef clean_texts_4500(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4501", "text": "def compute_stats_4501(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4502", "text": "def compute_sum_4502(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4503", "text": "from typing import Dict, Any\n\ndef validate_payload_4503(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4504", "text": "def compute_avg_4504(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_4505", "text": "def compute_average_4505(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4506", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_4506(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_4506(n - 1) + fib_4506(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_4507", "text": "import numpy as np\n\ndef validate_and_predict_4507(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4508", "text": "def analyze_series_4508(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4509", "text": "def pipeline_process_4509(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4510", "text": "def is_prime_4510(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4511", "text": "def nested_analysis_4511(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4512", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4512(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4513", "text": "def compute_stats_4513(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4514", "text": "class DataNormalizer_4514:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4515", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4515():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4516", "text": "def extract_numeric_4516(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_4517", "text": "import json\n\ndef load_and_filter_4517(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_4518", "text": "def count_characters_4518(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_4519", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4519:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4519:\n    tasks: List[Task_4519] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4519(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4520", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_4520(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_4521", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4521():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4522", "text": "class Config_4522:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4523", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4523(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4524", "text": "import numpy as np\n\ndef minmax_norm_4524(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4525", "text": "class TextProcessor_4525:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4526", "text": "def generate_report_4526(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4527", "text": "class Config_4527:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4528", "text": "from collections import Counter\n\ndef word_freq_4528(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_4529", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4529(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4530", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_4530(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_4531", "text": "def compute_avg_4531(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_4532", "text": "import numpy as np\n\ndef validate_and_predict_4532(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4533", "text": "import numpy as np\n\ndef normalize_features_4533(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4534", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4534(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4535", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4535(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4535(n-1) + fib_4535(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4536", "text": "def count_characters_4536(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_4537", "text": "class DataNormalizer_4537:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4538", "text": "def validate_payload_4538(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4539", "text": "class Config_4539:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4540", "text": "def count_characters_4540(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_4541", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_4541(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_4542", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4542():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4543", "text": "def count_characters_4543(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_4544", "text": "import numpy as np\n\ndef normalize_features_4544(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4545", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_4545(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_4545(n - 1) + fib_4545(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_4546", "text": "class ExecutionNode_4546:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_4546():\n    import math\n\n    root = ExecutionNode_4546(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_4546(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_4546(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_4547", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_4547(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_4548", "text": "from collections import Counter\n\ndef word_freq_4548(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_4549", "text": "def meta_process_4549(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4550", "text": "import json\n\ndef load_and_filter_4550(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_4551", "text": "import numpy as np\n\ndef validate_and_predict_4551(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4552", "text": "def validate_4552(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4552(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4552(seq):\n    clean = convert_4552(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4553", "text": "def pipeline_process_4553(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4554", "text": "def safe_division_4554(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4555", "text": "class DataNormalizer_4555:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4556", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4556():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4557", "text": "def structured_sum_4557(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4558", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4558(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4558(n-1) + fib_4558(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4559", "text": "def extract_numeric_4559(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_4560", "text": "def compute_sum_4560(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4561", "text": "def validate_payload_4561(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_4562", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4562():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4563", "text": "from typing import Dict, Any\n\ndef validate_payload_4563(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4564", "text": "def compute_avg_4564(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_4565", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4565(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4565(n-1) + fib_4565(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4566", "text": "def validate_payload_4566(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4567", "text": "def structured_sum_4567(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4568", "text": "def count_characters_4568(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_4569", "text": "def structured_sum_4569(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4570", "text": "def flatten_list_4570(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4571", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4571(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4571(n-1) + fib_4571(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4572", "text": "def meta_process_4572(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4573", "text": "def pipeline_process_4573(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4574", "text": "class DataNormalizer_4574:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4575", "text": "def safe_division_4575(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4576", "text": "import numpy as np\n\ndef minmax_norm_4576(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4577", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_4577(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_4578", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4578(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4579", "text": "def safe_division_4579(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4580", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_4580(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_4581", "text": "def analyze_series_4581(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4582", "text": "def is_prime_4582(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4583", "text": "class Config_4583:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4584", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4584(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4585", "text": "def analyze_series_4585(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4586", "text": "class TextProcessor_4586:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4587", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4587(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4588", "text": "def flatten_list_4588(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4589", "text": "def count_tokens_4589(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4590", "text": "def is_prime_4590(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4591", "text": "class Processor_4591:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4592", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4592:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4592:\n    tasks: List[Task_4592] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4592(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4593", "text": "def compute_average_4593(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4594", "text": "def safe_reduce_4594(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4595", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4595(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4596", "text": "def compute_stats_4596(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4597", "text": "def extract_numeric_4597(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_4598", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4598(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4599", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4599(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4599(n-1) + fib_4599(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4600", "text": "import numpy as np\n\ndef validate_and_predict_4600(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4601", "text": "def safe_division_4601(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4602", "text": "class Processor_4602:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4603", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_4603(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_4604", "text": "from collections import Counter\n\ndef word_freq_4604(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_4605", "text": "def pipeline_process_4605(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4606", "text": "class Config_4606:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4607", "text": "def compute_average_4607(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4608", "text": "def safe_division_4608(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4609", "text": "def is_prime_4609(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4610", "text": "def validate_payload_4610(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_4611", "text": "def count_tokens_4611(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4612", "text": "def validate_4612(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4612(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4612(seq):\n    clean = convert_4612(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4613", "text": "def generate_report_4613(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4614", "text": "class Processor_4614:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4615", "text": "def compute_sum_4615(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4616", "text": "def compute_avg_4616(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_4617", "text": "def pipeline_process_4617(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4618", "text": "def compute_average_4618(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4619", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_4619(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_4619(n - 1) + fib_4619(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_4620", "text": "def compute_avg_4620(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_4621", "text": "def safe_division_4621(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4622", "text": "class TextProcessor_4622:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4623", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4623():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4624", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4624(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4625", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_4625(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_4625(n - 1) + fib_4625(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_4626", "text": "def safe_reduce_4626(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4627", "text": "import numpy as np\n\ndef normalize_features_4627(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4628", "text": "class Config_4628:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4629", "text": "def validate_4629(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4629(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4629(seq):\n    clean = convert_4629(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4630", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4630():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4631", "text": "def structured_sum_4631(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4632", "text": "def compute_sum_4632(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4633", "text": "from typing import Dict, Any\n\ndef validate_payload_4633(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4634", "text": "class ExecutionNode_4634:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_4634():\n    import math\n\n    root = ExecutionNode_4634(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_4634(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_4634(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_4635", "text": "def validate_payload_4635(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4636", "text": "import numpy as np\n\ndef normalize_features_4636(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4637", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4637():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4638", "text": "class Config_4638:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4639", "text": "import numpy as np\n\ndef minmax_norm_4639(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4640", "text": "def generate_report_4640(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4641", "text": "def meta_process_4641(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4642", "text": "def analyze_series_4642(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4643", "text": "class Config_4643:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4644", "text": "def validate_payload_4644(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_4645", "text": "def pipeline_process_4645(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4646", "text": "def validate_4646(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4646(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4646(seq):\n    clean = convert_4646(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4647", "text": "import numpy as np\n\ndef validate_and_predict_4647(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4648", "text": "def validate_4648(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4648(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4648(seq):\n    clean = convert_4648(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4649", "text": "class Processor_4649:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4650", "text": "def compute_stats_4650(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4651", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4651(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4652", "text": "def safe_division_4652(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4653", "text": "class ExecutionNode_4653:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_4653():\n    import math\n\n    root = ExecutionNode_4653(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_4653(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_4653(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_4654", "text": "def extract_numeric_4654(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_4655", "text": "def validate_payload_4655(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_4656", "text": "from collections import Counter\n\ndef word_freq_4656(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_4657", "text": "def safe_division_4657(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4658", "text": "def compute_avg_4658(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_4659", "text": "def count_tokens_4659(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4660", "text": "def compute_stats_4660(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4661", "text": "import numpy as np\n\ndef validate_and_predict_4661(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4662", "text": "def compute_sum_4662(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4663", "text": "class ExecutionNode_4663:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_4663():\n    import math\n\n    root = ExecutionNode_4663(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_4663(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_4663(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_4664", "text": "def pipeline_process_4664(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4665", "text": "import statistics\n\ndef stats_4665(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4666", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4666(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4667", "text": "def structured_sum_4667(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4668", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4668():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4669", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4669(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4670", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4670(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4671", "text": "def safe_division_4671(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4672", "text": "import numpy as np\n\ndef validate_and_predict_4672(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4673", "text": "def safe_division_4673(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4674", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4674(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4675", "text": "def flatten_list_4675(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4676", "text": "def compute_sum_4676(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4677", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_4677(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_4678", "text": "import numpy as np\n\ndef validate_and_predict_4678(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4679", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_4679(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_4680", "text": "class Processor_4680:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4681", "text": "def is_prime_4681(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4682", "text": "from collections import Counter\n\ndef word_freq_4682(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_4683", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4683(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4683(n-1) + fib_4683(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4684", "text": "def validate_4684(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4684(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4684(seq):\n    clean = convert_4684(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4685", "text": "import numpy as np\n\ndef validate_and_predict_4685(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4686", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4686(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4687", "text": "def compute_sum_4687(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4688", "text": "def validate_4688(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4688(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4688(seq):\n    clean = convert_4688(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4689", "text": "import numpy as np\n\ndef validate_and_predict_4689(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4690", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4690:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4690:\n    tasks: List[Task_4690] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4690(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4691", "text": "from typing import Dict, Any\n\ndef validate_payload_4691(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4692", "text": "def count_tokens_4692(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4693", "text": "class Config_4693:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4694", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4694(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4694(n-1) + fib_4694(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4695", "text": "class ExecutionNode_4695:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_4695():\n    import math\n\n    root = ExecutionNode_4695(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_4695(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_4695(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_4696", "text": "import numpy as np\n\ndef validate_and_predict_4696(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4697", "text": "class ExecutionNode_4697:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_4697():\n    import math\n\n    root = ExecutionNode_4697(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_4697(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_4697(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_4698", "text": "import re\n\ndef clean_texts_4698(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4699", "text": "def structured_sum_4699(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4700", "text": "def analyze_series_4700(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4701", "text": "def validate_payload_4701(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_4702", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_4702(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_4703", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_4703(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_4704", "text": "from collections import Counter\n\ndef word_freq_4704(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_4705", "text": "class TextProcessor_4705:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4706", "text": "def safe_division_4706(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4707", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4707(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4707(n-1) + fib_4707(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4708", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4708(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4709", "text": "import statistics\n\ndef stats_4709(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4710", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_4710(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_4710(n - 1) + fib_4710(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_4711", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4711():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4712", "text": "def validate_payload_4712(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4713", "text": "import numpy as np\n\ndef validate_and_predict_4713(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4714", "text": "import numpy as np\n\ndef normalize_features_4714(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4715", "text": "def count_tokens_4715(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4716", "text": "import numpy as np\n\ndef normalize_features_4716(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4717", "text": "class DataNormalizer_4717:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4718", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4718(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4719", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4719(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4720", "text": "def count_characters_4720(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_4721", "text": "def safe_reduce_4721(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4722", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_4722(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_4722(n - 1) + fib_4722(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_4723", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4723(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4724", "text": "def pipeline_process_4724(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4725", "text": "import numpy as np\n\ndef normalize_features_4725(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4726", "text": "def validate_4726(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4726(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4726(seq):\n    clean = convert_4726(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4727", "text": "def validate_payload_4727(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_4728", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4728(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4728(n-1) + fib_4728(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4729", "text": "def compute_sum_4729(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4730", "text": "def compute_average_4730(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4731", "text": "def safe_division_4731(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4732", "text": "import statistics\n\ndef stats_4732(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4733", "text": "def compute_stats_4733(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4734", "text": "from typing import Dict, Any\n\ndef validate_payload_4734(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4735", "text": "class Config_4735:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4736", "text": "def safe_reduce_4736(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4737", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_4737(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_4737(n - 1) + fib_4737(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_4738", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4738():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4739", "text": "class ExecutionNode_4739:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_4739():\n    import math\n\n    root = ExecutionNode_4739(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_4739(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_4739(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_4740", "text": "def validate_payload_4740(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_4741", "text": "import statistics\n\ndef stats_4741(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4742", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4742:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4742:\n    tasks: List[Task_4742] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4742(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4743", "text": "from collections import Counter\n\ndef word_freq_4743(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_4744", "text": "def compute_sum_4744(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4745", "text": "def compute_sum_4745(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4746", "text": "import re\n\ndef clean_texts_4746(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4747", "text": "class Config_4747:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4748", "text": "def flatten_list_4748(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4749", "text": "def is_prime_4749(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4750", "text": "import re\n\ndef clean_texts_4750(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4751", "text": "class DataNormalizer_4751:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4752", "text": "def meta_process_4752(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4753", "text": "import numpy as np\n\ndef minmax_norm_4753(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4754", "text": "def meta_process_4754(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4755", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4755:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4755:\n    tasks: List[Task_4755] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4755(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4756", "text": "def safe_division_4756(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4757", "text": "def validate_payload_4757(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4758", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4758(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4759", "text": "def count_tokens_4759(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4760", "text": "def safe_divide_4760(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_4761", "text": "import numpy as np\n\ndef minmax_norm_4761(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4762", "text": "def safe_divide_4762(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_4763", "text": "def validate_4763(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4763(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4763(seq):\n    clean = convert_4763(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4764", "text": "def analyze_series_4764(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4765", "text": "def compute_stats_4765(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4766", "text": "def safe_reduce_4766(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4767", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4767(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4768", "text": "def flatten_list_4768(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4769", "text": "def nested_analysis_4769(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4770", "text": "def count_characters_4770(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_4771", "text": "from typing import Dict, Any\n\ndef validate_payload_4771(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4772", "text": "def compute_stats_4772(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4773", "text": "import numpy as np\n\ndef minmax_norm_4773(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4774", "text": "def structured_sum_4774(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4775", "text": "def nested_analysis_4775(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4776", "text": "def compute_average_4776(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4777", "text": "class DataNormalizer_4777:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4778", "text": "def validate_4778(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4778(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4778(seq):\n    clean = convert_4778(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4779", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4779(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4779(n-1) + fib_4779(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4780", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4780(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4780(n-1) + fib_4780(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4781", "text": "import statistics\n\ndef stats_4781(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4782", "text": "def compute_sum_4782(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4783", "text": "def compute_stats_4783(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4784", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_4784(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_4785", "text": "class Processor_4785:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4786", "text": "def validate_payload_4786(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4787", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4787:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4787:\n    tasks: List[Task_4787] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4787(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4788", "text": "import numpy as np\n\ndef normalize_features_4788(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4789", "text": "class Processor_4789:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4790", "text": "import numpy as np\n\ndef validate_and_predict_4790(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4791", "text": "def validate_payload_4791(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_4792", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_4792(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_4793", "text": "def is_prime_4793(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4794", "text": "def validate_payload_4794(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_4795", "text": "import numpy as np\n\ndef minmax_norm_4795(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4796", "text": "def structured_sum_4796(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4797", "text": "def safe_division_4797(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4798", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_4798(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_4798(n - 1) + fib_4798(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_4799", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_4799(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_4800", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4800(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4800(n-1) + fib_4800(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4801", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4801(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4801(n-1) + fib_4801(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4802", "text": "def is_prime_4802(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4803", "text": "import numpy as np\n\ndef normalize_features_4803(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4804", "text": "import numpy as np\n\ndef normalize_features_4804(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4805", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_4805(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_4805(n - 1) + fib_4805(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_4806", "text": "class TextProcessor_4806:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4807", "text": "def analyze_series_4807(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4808", "text": "def generate_report_4808(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4809", "text": "def meta_process_4809(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4810", "text": "class TextProcessor_4810:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4811", "text": "class Config_4811:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4812", "text": "def safe_divide_4812(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_4813", "text": "def generate_report_4813(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4814", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_4814(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_4815", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4815(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4816", "text": "def analyze_series_4816(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4817", "text": "def compute_sum_4817(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4818", "text": "def extract_numeric_4818(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_4819", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4819(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4819(n-1) + fib_4819(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4820", "text": "class DataNormalizer_4820:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4821", "text": "def structured_sum_4821(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4822", "text": "def flatten_list_4822(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4823", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_4823(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_4823(n - 1) + fib_4823(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_4824", "text": "class Config_4824:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4825", "text": "class Config_4825:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4826", "text": "def safe_division_4826(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4827", "text": "def meta_process_4827(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4828", "text": "def safe_reduce_4828(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4829", "text": "class Config_4829:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4830", "text": "def validate_4830(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4830(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4830(seq):\n    clean = convert_4830(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4831", "text": "from typing import Dict, Any\n\ndef validate_payload_4831(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4832", "text": "def count_characters_4832(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_4833", "text": "def validate_payload_4833(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4834", "text": "class Config_4834:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4835", "text": "class Processor_4835:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4836", "text": "def validate_payload_4836(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4837", "text": "import numpy as np\n\ndef minmax_norm_4837(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4838", "text": "def compute_avg_4838(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_4839", "text": "import numpy as np\n\ndef normalize_features_4839(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4840", "text": "import re\n\ndef clean_texts_4840(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4841", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4841(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4842", "text": "def analyze_series_4842(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4843", "text": "def is_prime_4843(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4844", "text": "def analyze_series_4844(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4845", "text": "import numpy as np\n\ndef minmax_norm_4845(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4846", "text": "from typing import Dict, Any\n\ndef validate_payload_4846(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4847", "text": "def compute_average_4847(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4848", "text": "def analyze_series_4848(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4849", "text": "class TextProcessor_4849:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4850", "text": "def safe_division_4850(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4851", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4851():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4852", "text": "def validate_4852(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4852(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4852(seq):\n    clean = convert_4852(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4853", "text": "def count_tokens_4853(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4854", "text": "def is_prime_4854(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4855", "text": "def structured_sum_4855(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4856", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4856:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4856:\n    tasks: List[Task_4856] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4856(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4857", "text": "def safe_division_4857(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4858", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_4858(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_4859", "text": "def pipeline_process_4859(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4860", "text": "def compute_average_4860(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4861", "text": "import re\n\ndef clean_texts_4861(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4862", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4862(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4863", "text": "def structured_sum_4863(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4864", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4864:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4864:\n    tasks: List[Task_4864] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4864(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4865", "text": "def nested_analysis_4865(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4866", "text": "def count_characters_4866(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_4867", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4867(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4868", "text": "import numpy as np\n\ndef minmax_norm_4868(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4869", "text": "def flatten_list_4869(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4870", "text": "def safe_division_4870(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4871", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4871(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4872", "text": "from collections import Counter\n\ndef word_freq_4872(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_4873", "text": "class Processor_4873:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4874", "text": "def compute_stats_4874(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4875", "text": "def pipeline_process_4875(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4876", "text": "def meta_process_4876(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4877", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_4877(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_4877(n - 1) + fib_4877(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_4878", "text": "class DataNormalizer_4878:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4879", "text": "def flatten_list_4879(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4880", "text": "import statistics\n\ndef stats_4880(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4881", "text": "def count_characters_4881(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_4882", "text": "def validate_payload_4882(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4883", "text": "def generate_report_4883(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4884", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_4884(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_4885", "text": "def compute_sum_4885(values: list[Any]) -> int:\n    \"\"\"\n    Computes the numeric sum with defensive checks.\n    Includes validation, filtering and deterministic output.\n    \"\"\"\n    if values is None:\n        raise ValueError(\"Input cannot be None\")\n\n    clean = []\n    for item in values:\n        try:\n            if isinstance(item, (int, float)):\n                clean.append(float(item))\n        except:\n            continue\n    return sum(clean)", "label": "1", "lang": "python"}
{"id": "AI_4886", "text": "import numpy as np\n\ndef minmax_norm_4886(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4887", "text": "def validate_payload_4887(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4888", "text": "import numpy as np\n\ndef normalize_features_4888(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4889", "text": "def validate_payload_4889(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4890", "text": "def count_tokens_4890(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4891", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4891:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4891:\n    tasks: List[Task_4891] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4891(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4892", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4892(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4893", "text": "import numpy as np\n\ndef minmax_norm_4893(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4894", "text": "def validate_payload_4894(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4895", "text": "def count_tokens_4895(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4896", "text": "class DataNormalizer_4896:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4897", "text": "def safe_reduce_4897(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4898", "text": "class ExecutionNode_4898:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_4898():\n    import math\n\n    root = ExecutionNode_4898(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_4898(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_4898(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_4899", "text": "from typing import Dict, Any\n\ndef validate_payload_4899(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4900", "text": "class ExecutionNode_4900:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_4900():\n    import math\n\n    root = ExecutionNode_4900(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_4900(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_4900(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_4901", "text": "from collections import Counter\n\ndef word_freq_4901(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_4902", "text": "from typing import List, Callable, TypeVar\n\nT = TypeVar(\"T\")\n\ndef filter_items_4902(items: List[T], cond: Callable[[T], bool]) -> List[T]:\n    \"\"\"\n    Generic filter implementation with explicit functional typing.\n    \"\"\"\n    out = []\n    for it in items:\n        if cond(it):\n            out.append(it)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4903", "text": "def validate_4903(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4903(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4903(seq):\n    clean = convert_4903(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4904", "text": "import numpy as np\n\ndef validate_and_predict_4904(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4905", "text": "def compute_avg_4905(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_4906", "text": "def pipeline_process_4906(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4907", "text": "class Processor_4907:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4908", "text": "def flatten_list_4908(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4909", "text": "import statistics\n\ndef stats_4909(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4910", "text": "def structured_sum_4910(values):\n    \"\"\"Computes sum with basic input validation.\"\"\"\n    if values is None:\n        return 0\n    return sum(v for v in values if isinstance(v, (int, float)))", "label": "1", "lang": "python"}
{"id": "AI_4911", "text": "from typing import Dict, Any\n\ndef validate_payload_4911(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4912", "text": "class TextProcessor_4912:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4913", "text": "def extract_numeric_4913(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_4914", "text": "def safe_division_4914(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4915", "text": "def generate_report_4915(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4916", "text": "def compute_avg_4916(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_4917", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4917(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4918", "text": "def is_prime_4918(number: int) -> bool:\n    \"\"\"\n    Determines primality using structured validation and \n    early-termination optimization for downstream consistency.\n    \"\"\"\n    if not isinstance(number, int):\n        raise TypeError(\"number must be int\")\n\n    if number < 2:\n        return False\n\n    limit = int(number ** 0.5)\n    for divisor in range(2, limit + 1):\n        if number % divisor == 0:\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4919", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_4919(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_4920", "text": "class ExecutionNode_4920:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_4920():\n    import math\n\n    root = ExecutionNode_4920(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_4920(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_4920(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_4921", "text": "def safe_divide_4921(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_4922", "text": "class Processor_4922:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4923", "text": "def safe_division_4923(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4924", "text": "class DataNormalizer_4924:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4925", "text": "class ExecutionNode_4925:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_4925():\n    import math\n\n    root = ExecutionNode_4925(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_4925(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_4925(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_4926", "text": "from sklearn.cluster import KMeans\nimport numpy as np\n\ndef cluster_points_4926():\n    \"\"\"Clusters sample points using KMeans (AI-style).\"\"\" \n    X = np.array([[1,2], [1.5,1.8], [5,8], [8,8], [1,0.6], [9,11]])\n    model = KMeans(n_clusters=2, random_state=42, n_init=10)\n    model.fit(X)\n    return {\n        \"labels\": model.labels_.tolist(),\n        \"centers\": model.cluster_centers_.tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4927", "text": "def pipeline_process_4927(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4928", "text": "def meta_process_4928(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4929", "text": "def meta_process_4929(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4930", "text": "class DataNormalizer_4930:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4931", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_4931(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_4931(n - 1) + fib_4931(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_4932", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4932(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4932(n-1) + fib_4932(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4933", "text": "def pipeline_process_4933(data):\n    \"\"\"\n    Runs a multi-stage pipeline:\n    - validation\n    - flatten\n    - filter numeric\n    - compute stats\n    \"\"\"\n    if not isinstance(data, (list, tuple)):\n        raise TypeError(\"Pipeline expects a list or tuple\")\n\n    def flatten(x):\n        for item in x:\n            if isinstance(item, (list, tuple)):\n                yield from flatten(item)\n            else:\n                yield item\n\n    flat = list(flatten(data))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n\n    if not nums:\n        return {}\n\n    return {\n        \"mean\": sum(nums)/len(nums),\n        \"min\": min(nums),\n        \"max\": max(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4934", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_4934(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_4935", "text": "def generate_report_4935(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4936", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4936(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4937", "text": "from functools import lru_cache\n\n@lru_cache(maxsize=None)\ndef fib_4937(n: int) -> int:\n    \"\"\"Memoized fibonacci implementation.\"\"\"\n    if n < 0:\n        raise ValueError(\"n must be non-negative\")\n    if n < 2:\n        return n\n    return fib_4937(n-1) + fib_4937(n-2)", "label": "1", "lang": "python"}
{"id": "AI_4938", "text": "import json\n\ndef load_and_filter_4938(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_4939", "text": "class TextProcessor_4939:\n    \"\"\"\n    AI-style text processing class with utility methods.\n    \"\"\"\n\n    @staticmethod\n    def count_words(text: str) -> int:\n        return len(text.split())\n\n    @staticmethod\n    def to_title_case(text: str) -> str:\n        return text.title()", "label": "1", "lang": "python"}
{"id": "AI_4940", "text": "from dataclasses import dataclass, field\nfrom typing import List\n\n@dataclass\nclass Task_4940:\n    title: str\n    done: bool = False\n\n@dataclass\nclass TaskManager_4940:\n    tasks: List[Task_4940] = field(default_factory=list)\n\n    def add(self, title: str):\n        self.tasks.append(Task_4940(title))\n\n    def mark(self, idx: int):\n        if 0 <= idx < len(self.tasks):\n            self.tasks[idx].done = True\n        else:\n            raise IndexError(\"Invalid index\")", "label": "1", "lang": "python"}
{"id": "AI_4941", "text": "class ExecutionNode_4941:\n    \"\"\"Autogenerated AI-style execution graph node.\"\"\"\n\n    def __init__(self, name, fn):\n        self.name = name\n        self.fn = fn\n        self.result = None\n        self.children = []\n\n    def add_child(self, node):\n        self.children.append(node)\n\n    def run(self, data):\n        self.result = self.fn(data)\n        for child in self.children:\n            child.run(self.result)\n        return self.result\n\n\ndef build_graph_4941():\n    import math\n\n    root = ExecutionNode_4941(\"root\", lambda x: [v for v in x if isinstance(v, (int, float))])\n    norm = ExecutionNode_4941(\"normalize\", lambda seq: [v / max(seq) for v in seq] if seq else [])\n    stats = ExecutionNode_4941(\"stats\", lambda seq: {\n        \"min\": min(seq) if seq else None,\n        \"max\": max(seq) if seq else None,\n        \"mean\": sum(seq)/len(seq) if seq else None,\n    })\n\n    root.add_child(norm)\n    norm.add_child(stats)\n    return root", "label": "1", "lang": "python"}
{"id": "AI_4942", "text": "import numpy as np\n\ndef validate_and_predict_4942(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4943", "text": "def validate_4943(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4943(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4943(seq):\n    clean = convert_4943(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4944", "text": "def generate_report_4944(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4945", "text": "def validate_payload_4945(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4946", "text": "def compute_stats_4946(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4947", "text": "import statistics\n\ndef stats_4947(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4948", "text": "def meta_process_4948(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4949", "text": "def compute_stats_4949(items):\n    \"\"\"Returns aggregated statistics with min, max, mean.\"\"\"\n    nums = [x for x in items if isinstance(x, (int, float))]\n    if not nums:\n        return {}\n    return {\n        \"min\": min(nums),\n        \"max\": max(nums),\n        \"mean\": sum(nums)/len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4950", "text": "def validate_payload_4950(obj):\n    \"\"\"Ensures payload matches expected structure.\"\"\"\n    if not isinstance(obj, dict):\n        raise TypeError(\"Expected dict\")\n    return {\"keys\": list(obj.keys())}", "label": "1", "lang": "python"}
{"id": "AI_4951", "text": "def safe_division_4951(a, b):\n    \"\"\"\n    Performs division with structured exception handling \n    and deterministic fallback behavior.\n    \"\"\"\n    try:\n        return float(a) / float(b)\n    except ZeroDivisionError:\n        return 0.0\n    except Exception:\n        return 0.0", "label": "1", "lang": "python"}
{"id": "AI_4952", "text": "class Processor_4952:\n    \"\"\"\n    Processor with artificial configuration structure.\n    \"\"\"\n\n    def __init__(self, config: dict):\n        self.config = config or {}\n\n    def run(self, payload):\n        mode = self.config.get(\"mode\", \"safe\")\n        if mode == \"verbose\":\n            print(\"Verbose mode active\")\n\n        if not isinstance(payload, list):\n            raise ValueError(\"Payload must be a list\")\n\n        nums = [x for x in payload if isinstance(x, (int, float))]\n        return {\n            \"count\": len(nums),\n            \"sum\": sum(nums),\n            \"avg\": sum(nums)/len(nums) if nums else 0\n        }", "label": "1", "lang": "python"}
{"id": "AI_4953", "text": "def count_tokens_4953(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4954", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_4954(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_4955", "text": "class Config_4955:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4956", "text": "def safe_reduce_4956(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4957", "text": "import numpy as np\n\ndef normalize_features_4957(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4958", "text": "class DataNormalizer_4958:\n    \"\"\"\n    Provides normalization utilities for numeric sequences.\n    Auto-detects invalid values and applies min-max scaling.\n    \"\"\"\n\n    def __init__(self):\n        self._cache = {}\n\n    def _ensure_numeric(self, seq):\n        clean = []\n        for x in seq:\n            if isinstance(x, (int, float)):\n                clean.append(x)\n        return clean\n\n    def normalize(self, seq):\n        nums = self._ensure_numeric(seq)\n        if not nums:\n            return []\n        mn, mx = min(nums), max(nums)\n        span = mx - mn if mx != mn else 1\n        return [(x - mn) / span for x in nums]", "label": "1", "lang": "python"}
{"id": "AI_4959", "text": "def safe_divide_4959(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_4960", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4960(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4961", "text": "def compute_avg_4961(values):\n    \"\"\"\n    Compute arithmetic mean of a numeric list with\n    strict type checking and defensive validation.\n    \"\"\"\n    if not isinstance(values, list):\n        raise TypeError(\"values must be a list\")\n    if not values:\n        return 0.0\n\n    total = 0.0\n    for v in values:\n        total += v\n    return total / len(values)", "label": "1", "lang": "python"}
{"id": "AI_4962", "text": "import numpy as np\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef normalize_features_4962(values):\n    \"\"\"Normalize numeric features into [0,1] range for ML pipelines.\"\"\"\n    arr = np.array(values, dtype=float).reshape(-1,1)\n    scaler = MinMaxScaler()\n    transformed = scaler.fit_transform(arr)\n    return transformed.flatten().tolist()", "label": "1", "lang": "python"}
{"id": "AI_4963", "text": "class Config_4963:\n    \"\"\"Simple configuration holder for ML pipelines.\"\"\" \n    def __init__(self, lr: float, epochs: int, batch: int):\n        self.lr = lr\n        self.epochs = epochs\n        self.batch = batch\n\n    def as_dict(self):\n        return {\"lr\": self.lr, \"epochs\": self.epochs, \"batch\": self.batch}", "label": "1", "lang": "python"}
{"id": "AI_4964", "text": "def safe_divide_4964(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_4965", "text": "def extract_numeric_4965(payload):\n    \"\"\"Filters numeric values from mixed payload.\"\"\"\n    clean = []\n    for x in payload:\n        if isinstance(x, (int, float)):\n            clean.append(x)\n    return clean", "label": "1", "lang": "python"}
{"id": "AI_4966", "text": "import numpy as np\n\ndef minmax_norm_4966(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4967", "text": "import numpy as np\n\ndef minmax_norm_4967(values):\n    \"\"\"AI-style numeric min-max normalization utility.\"\"\"\n    arr = np.asarray(values, dtype=float)\n    mn = arr.min()\n    mx = arr.max()\n    return ((arr - mn) / (mx - mn + 1e-9)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4968", "text": "def count_characters_4968(text: str):\n    \"\"\"\n    Counts character frequencies using deterministic structure and \n    defensive type validation.\n    \"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n\n    counts = {}\n    for ch in text:\n        counts[ch] = counts.get(ch, 0) + 1\n    return counts", "label": "1", "lang": "python"}
{"id": "AI_4969", "text": "def count_tokens_4969(text):\n    \"\"\"Counts tokens by splitting on whitespace.\"\"\"\n    if not isinstance(text, str):\n        return 0\n    return len(text.split())", "label": "1", "lang": "python"}
{"id": "AI_4970", "text": "def generate_report_4970(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4971", "text": "import numpy as np\n\ndef validate_and_predict_4971(model, sample):\n    \"\"\"\n    AI-style prediction wrapper with:\n    - capability check\n    - type validation\n    - reshape\n    - structured dictionary output\n    \"\"\"\n\n    if not hasattr(model, \"predict\"):\n        raise ValueError(\"Model does not implement predict().\")\n\n    if not isinstance(sample, (list, tuple)):\n        raise TypeError(\"Sample must be list-like.\")\n\n    arr = np.array(sample).reshape(1, -1)\n    pred = model.predict(arr)[0]\n\n    return {\n        \"input\": arr.tolist(),\n        \"prediction\": float(pred),\n    }", "label": "1", "lang": "python"}
{"id": "AI_4972", "text": "def safe_divide_4972(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_4973", "text": "def validate_payload_4973(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4974", "text": "def meta_process_4974(payload):\n    \"\"\"\n    Automatically generated meta-processing function.\n    Simulates AI-style abstraction using rule maps and internal lambdas.\n    \"\"\"\n\n    RULES = {\n        \"validate\": lambda x: isinstance(x, (list, dict)),\n        \"extract_numbers\": lambda x: [v for v in x if isinstance(v, (int, float))] \n                                     if isinstance(x, list) else [],\n        \"summary\": lambda seq: {\n            \"count\": len(seq),\n            \"min\": min(seq) if seq else None,\n            \"max\": max(seq) if seq else None,\n            \"avg\": sum(seq)/len(seq) if seq else None\n        },\n    }\n\n    if not RULES[\"validate\"](payload):\n        return {\"error\": \"invalid input\"}\n\n    nums = RULES[\"extract_numbers\"](payload)\n    return RULES[\"summary\"](nums)", "label": "1", "lang": "python"}
{"id": "AI_4975", "text": "def analyze_series_4975(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4976", "text": "import re\n\ndef clean_texts_4976(texts):\n    \"\"\"Lowercase + remove special characters + normalize spaces.\"\"\"\n    out = []\n    for t in texts:\n        t = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", t)\n        t = re.sub(r\"\\s+\", \" \", t).strip().lower()\n        out.append(t)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4977", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4977(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4978", "text": "def safe_divide_4978(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_4979", "text": "def safe_divide_4979(a, b):\n    \"\"\"Performs division with structured error handling.\"\"\"\n    try:\n        return a / b\n    except ZeroDivisionError:\n        return None\n    except TypeError:\n        return None", "label": "1", "lang": "python"}
{"id": "AI_4980", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_4980(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_4981", "text": "from collections import Counter\n\ndef word_freq_4981(text: str):\n    \"\"\"Compute lowercase word frequencies from raw string input.\"\"\"\n    if not isinstance(text, str):\n        raise TypeError(\"text must be a string\")\n    words = text.lower().split()\n    return dict(Counter(words))", "label": "1", "lang": "python"}
{"id": "AI_4982", "text": "import statistics\n\ndef stats_4982(values):\n    \"\"\"Return count, mean, median, variance.\"\"\"\n    if not values:\n        raise ValueError(\"empty list\")\n    return {\n        \"count\": len(values),\n        \"mean\": statistics.mean(values),\n        \"median\": statistics.median(values),\n        \"variance\": statistics.pvariance(values)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4983", "text": "def validate_4983(x):\n    if x is None:\n        raise ValueError(\"Missing input\")\n    return x\n\ndef convert_4983(seq):\n    return [float(x) for x in seq if isinstance(x, (int, float))]\n\ndef summarize_4983(seq):\n    clean = convert_4983(seq)\n    return {\n        \"min\": min(clean),\n        \"max\": max(clean),\n        \"mean\": sum(clean)/len(clean)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4984", "text": "from functools import lru_cache\n\n@lru_cache\ndef fib_4984(n: int) -> int:\n    \"\"\"Memoized fibonacci calculation.\"\"\" \n    if n < 2:\n        return n\n    return fib_4984(n - 1) + fib_4984(n - 2)", "label": "1", "lang": "python"}
{"id": "AI_4985", "text": "from sklearn.feature_extraction.text import CountVectorizer\n\ndef build_bow_matrix_4985(texts):\n    \"\"\"Builds a Bag-of-Words matrix from raw texts.\"\"\" \n    vectorizer = CountVectorizer()\n    X = vectorizer.fit_transform(texts)\n    return {\n        \"matrix\": X.toarray().tolist(),\n        \"vocab\": vectorizer.get_feature_names_out().tolist()\n    }", "label": "1", "lang": "python"}
{"id": "AI_4986", "text": "import json\n\ndef load_and_filter_4986(path: str):\n    \"\"\"Load a JSON list and return only active items.\"\"\"\n    with open(path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n    return [x for x in data if x.get(\"is_active\")]", "label": "1", "lang": "python"}
{"id": "AI_4987", "text": "def safe_reduce_4987(items):\n    \"\"\"\n    Redundant multi-layer safe reducer.\n    \"\"\"\n    if items is None:\n        raise ValueError(\"Items cannot be None\")\n\n    total = 0\n    for x in items:\n        try:\n            try:\n                total += float(x)\n            except TypeError:\n                continue\n        except:\n            pass\n    return total", "label": "1", "lang": "python"}
{"id": "AI_4988", "text": "from typing import Dict, Any\n\ndef validate_payload_4988(payload: Dict[str, Any]) -> bool:\n    \"\"\"Lightweight structured payload validator.\"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n    for key, t in required.items():\n        val = payload.get(key)\n        if not isinstance(val, t):\n            return False\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4989", "text": "def compute_average_4989(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4990", "text": "def flatten_list_4990(seq):\n    \"\"\"Flattens nested lists one level deep.\"\"\"\n    out = []\n    for item in seq:\n        if isinstance(item, list):\n            out.extend(item)\n        else:\n            out.append(item)\n    return out", "label": "1", "lang": "python"}
{"id": "AI_4991", "text": "import numpy as np\n\ndef normalize_features_4991(values):\n    \"\"\"\n    Applies stable min-max normalization with epsilon smoothing\n    for consistent downstream preprocessing.\n    \"\"\"\n    arr = np.array(values, dtype=float)\n    mn, mx = float(arr.min()), float(arr.max())\n    eps = 1e-9\n    return ((arr - mn) / (mx - mn + eps)).tolist()", "label": "1", "lang": "python"}
{"id": "AI_4992", "text": "import numpy as np\nfrom sklearn.linear_model import LinearRegression\n\ndef mini_linear_reg_4992(X, y, new_sample):\n    \"\"\"Train a small LinearRegression model and return prediction.\"\"\"\n    model = LinearRegression()\n    model.fit(X, y)\n    pred = model.predict([new_sample])[0]\n    return float(pred)", "label": "1", "lang": "python"}
{"id": "AI_4993", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_4993(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_4994", "text": "def validate_payload_4994(payload):\n    \"\"\"\n    Validates structured payload with explicit type enforcement \n    for downstream reliability.\n    \"\"\"\n    required = {\"id\": int, \"name\": str, \"score\": float}\n\n    if not isinstance(payload, dict):\n        return False\n\n    for key, typ in required.items():\n        if key not in payload or not isinstance(payload[key], typ):\n            return False\n\n    return True", "label": "1", "lang": "python"}
{"id": "AI_4995", "text": "def nested_analysis_4995(tree):\n    \"\"\"\n    Performs unnecessarily nested traversal (AI-style).\n    \"\"\"\n\n    def visit(node):\n        if isinstance(node, dict):\n            for v in node.values():\n                yield from visit(v)\n        elif isinstance(node, list):\n            for v in node:\n                yield from visit(v)\n        else:\n            yield node\n\n    flat = list(visit(tree))\n    nums = [x for x in flat if isinstance(x, (int, float))]\n    return {\n        \"total\": sum(nums),\n        \"len\": len(nums)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4996", "text": "def analyze_series_4996(data):\n    \"\"\"\n    Over-commented numeric analysis function.\n    \"\"\"\n    if not isinstance(data, list):\n        raise TypeError(\"Expected list\")\n\n    numeric = []\n    for x in data:\n        if isinstance(x, (int, float)):\n            numeric.append(x)\n\n    return {\n        \"min\": min(numeric),\n        \"max\": max(numeric),\n        \"range\": max(numeric)-min(numeric)\n    }", "label": "1", "lang": "python"}
{"id": "AI_4997", "text": "import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_mlp_model_4997(input_dim: int):\n    \"\"\"Constructs a simple Keras MLP model.\"\"\" \n    model = Sequential([\n        Dense(32, activation=\"relu\", input_shape=(input_dim,)),\n        Dense(16, activation=\"relu\"),\n        Dense(1, activation=\"sigmoid\"),\n    ])\n    model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n    return model", "label": "1", "lang": "python"}
{"id": "AI_4998", "text": "def compute_average_4998(values):\n    \"\"\"\n    Computes arithmetic mean with input normalization and \n    predictable output structure.\n    \"\"\"\n    if not isinstance(values, (list, tuple)):\n        raise TypeError(\"values must be list-like\")\n\n    nums = [float(v) for v in values if isinstance(v, (int, float))]\n    if not nums:\n        return {\"count\": 0, \"avg\": 0.0}\n\n    return {\"count\": len(nums), \"avg\": sum(nums) / len(nums)}", "label": "1", "lang": "python"}
{"id": "AI_4999", "text": "def generate_report_4999(data):\n    \"\"\"\n    Structured statistical report generator following\n    deterministic aggregation semantics.\n    \"\"\"\n    if not data:\n        return {\"count\": 0, \"max\": None, \"min\": None, \"average\": 0}\n\n    return {\n        \"count\": len(data),\n        \"max\": max(data),\n        \"min\": min(data),\n        \"average\": sum(data) / len(data)\n    }", "label": "1", "lang": "python"}
